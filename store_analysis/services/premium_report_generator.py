#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ğŸ’ Premium Report Generator Service
ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Liara AI

Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù¾Ú©ÛŒØ¬:
- preliminary: openai/gpt-4o-mini (ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ - Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ø±Ø²Ø§Ù†)
- basic: google/gemini-2.5-flash (ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø¨ÙˆØ¨ - Ø³Ø±ÛŒØ¹ Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯)
- professional: openai/gpt-5-mini (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª)

Ù¾Ù„ØªÙØ±Ù…: Liara AI (https://ai.liara.ir)
"""

import json
import logging
import os
from datetime import datetime
from decimal import Decimal
from typing import Any, Dict, List, Optional

from django.utils import timezone

from .liara_ai_client import LiaraAIClient, LiaraAIError

logger = logging.getLogger(__name__)


class PremiumReportGenerator:
    """Ø³Ø±ÙˆÛŒØ³ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Liara"""

    def __init__(self) -> None:
        self.service_name = "Premium Analysis Report"
        self.ai_client = LiaraAIClient()
        # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ú©ÛŒØ¬ - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯Ù‡
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡: Ø§Ø² GPT-4o-mini Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù¾Ù„Ù†â€ŒÙ‡Ø§ (Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ø±Ø²Ø§Ù†)
        # ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø¨ÙˆØ¨ (basic): Ø§Ø² Gemini 2.5 Flash Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ùˆ Ú©Ø§Ø±Ø§ÛŒÛŒ
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (professional): Ø§Ø² GPT-5-mini Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª
        # Enterprise Ù†Ø¯Ø§Ø±ÛŒÙ… - Ø­Ø°Ù Ø´Ø¯Ù‡
        self.model_map = {
            'preliminary': 'openai/gpt-4o-mini',           # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ - Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù¾Ù„Ù†â€ŒÙ‡Ø§
            'basic': 'google/gemini-2.5-flash',            # ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ø¨ÙˆØ¨ - Ø³Ø±ÛŒØ¹ Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯
            'professional': 'openai/gpt-5-mini',           # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - Ø¨Ù‡ØªØ±ÛŒÙ† Ú©ÛŒÙÛŒØª
            # 'enterprise': Ø­Ø°Ù Ø´Ø¯Ù‡ - Enterprise Ù†Ø¯Ø§Ø±ÛŒÙ…
        }
        logger.info(
            "ğŸš€ PremiumReportGenerator Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯ (Liara ÙØ¹Ø§Ù„=%s)",
            self.ai_client.enabled,
        )
    
    def generate_premium_report(
        self,
        analysis,
        images_data: List[Dict] = None,
        video_data: Dict = None,
        sales_data: Dict = None
    ) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Liara AI"""

        try:
            analysis_id = getattr(analysis, 'id', 'unknown')
            package_type = getattr(analysis, 'package_type', 'basic') or 'basic'
            
            logger.info("ğŸ’ Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s (package_type=%s)", analysis_id, package_type)
            complete_data = self._gather_complete_data(analysis, images_data, video_data, sales_data)

            report = self._generate_report_locally(analysis, complete_data)
            model_used: Optional[str] = None
            ai_status = 'disabled'

            if self.ai_client.enabled:
                logger.info("âœ… Liara AI ÙØ¹Ø§Ù„ Ø§Ø³Øª - Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI")
                try:
                    model_used = self._select_model(analysis)
                    if model_used:
                        model_display = model_used.split('/')[-1] if '/' in model_used else model_used
                        logger.info(
                            "ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…Ø¯Ù„ %s Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s (package_type=%s)", 
                            model_display, analysis_id, package_type
                        )
                        enrichment = self._generate_report_with_ai(
                            analysis=analysis,
                            complete_data=complete_data,
                            base_report=report,
                            model=model_used,
                        )
                        if enrichment:
                            report = self._merge_ai_enrichment(report, enrichment)
                            report.setdefault('metadata', {})['ai_engine'] = 'Liara AI'
                            report['metadata']['liara_model_used'] = model_used
                            report['metadata']['model_provider'] = model_used.split('/')[0] if '/' in model_used else 'unknown'
                            report['metadata']['model_name'] = model_used.split('/')[-1] if '/' in model_used else model_used
                            ai_status = f'Liara AI ({model_display})'
                            logger.info(
                                "âœ… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§ Liara AI ØºÙ†ÛŒ Ø´Ø¯ - Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: %s (provider=%s)",
                                model_display,
                                model_used.split('/')[0] if '/' in model_used else 'unknown'
                            )
                        else:
                            ai_status = 'Liara AI (empty response)'
                            logger.warning("âš ï¸ Enrichment Ø§Ø² Liara AI Ø®Ø§Ù„ÛŒ Ø¨Ø±Ú¯Ø´ØªØŒ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´ rule-based Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
                            report.setdefault('metadata', {})['ai_engine'] = 'rule_based_fallback'
                            report['metadata']['ai_warning'] = 'Liara AI returned empty enrichment'
                    else:
                        ai_status = 'model selection failed'
                        logger.warning("âš ï¸ Ù…Ø¯Ù„ AI Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯ (package_type=%s)", package_type)
                        report.setdefault('metadata', {})['ai_engine'] = 'rule_based_fallback'
                except LiaraAIError as exc:
                    ai_status = f'Liara AI error: {str(exc)[:50]}'
                    logger.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Liara AI: %s - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´ rule-based", exc)
                    # Ú¯Ø²Ø§Ø±Ø´ rule-based Ù‚Ø¨Ù„Ø§Ù‹ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ ÙÙ‚Ø· metadata Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†
                    report.setdefault('metadata', {})['ai_error'] = str(exc)
                    report['metadata']['ai_engine'] = 'rule_based_fallback'
                except Exception as exc:  # pragma: no cover - Ø®Ø·Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ†Ø´Ø¯Ù‡
                    ai_status = f'unexpected error: {type(exc).__name__}'
                    logger.error("âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Liara AI: %s", exc, exc_info=True)
                    report.setdefault('metadata', {})['ai_error'] = f"Unexpected error: {str(exc)}"
                    report['metadata']['ai_engine'] = 'rule_based_fallback'
            else:
                ai_status = 'Liara AI disabled'
                logger.info("â„¹ï¸ Liara AI ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´ rule-based (LIARA_AI_API_KEY ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡)")

            quality_checklist = self._generate_quality_checklist(report, complete_data)
            report['quality_checklist'] = quality_checklist
            report['quality_summary'] = quality_checklist.get('summary', {})

            # Ù„Ø§Ú¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„
            logger.info(
                "âœ… Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s - AI Status: %s | Model: %s | Package: %s",
                analysis_id,
                ai_status,
                model_used or 'rule-based (no AI)',
                package_type
            )
            
            return report

        except Exception as exc:
            logger.error("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s: %s", getattr(analysis, 'id', 'unknown'), exc, exc_info=True)
            logger.error("âŒ Stack trace: %s", exc_info=True)
            fallback_report = self._generate_fallback_report(analysis)
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§ Ø¨Ù‡ metadata Ø¨Ø±Ø§ÛŒ debugging
            fallback_report['metadata']['error_details'] = str(exc)
            fallback_report['metadata']['error_type'] = type(exc).__name__
            return fallback_report
    
    def _generate_report_locally(self, analysis, complete_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ù†Ø³Ø®Ù‡ Ø¯Ø§Ø®Ù„ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ AI"""
        
        logger.info(f"ğŸ“ Generating local report for analysis {getattr(analysis, 'id', 'unknown')}")
        logger.info(f"ğŸ“Š Complete data keys: {list(complete_data.keys()) if complete_data else 'None'}")
        
        try:
            cover_page = self._generate_cover_page(analysis, complete_data)
            executive_summary = self._generate_executive_summary(complete_data)
            technical_analysis = self._generate_technical_analysis(complete_data)
            sales_analysis = self._generate_sales_analysis(complete_data)
            behavior_analysis = self._generate_behavior_analysis(complete_data)
            action_plan = self._generate_action_plan(complete_data)
            kpi_dashboard = self._generate_kpi_dashboard(complete_data)
            appendix = self._generate_appendix(complete_data)
            subscription_hook = self._generate_subscription_hook(complete_data)
            warnings = self._generate_data_warnings(complete_data)
            
            local_report = {
                'cover_page': cover_page,
                'executive_summary': executive_summary,
                'technical_analysis': technical_analysis,
                'sales_analysis': sales_analysis,
                'behavior_analysis': behavior_analysis,
                'action_plan': action_plan,
                'kpi_dashboard': kpi_dashboard,
                'appendix': appendix,
                'subscription_hook': subscription_hook,
                'warnings': warnings,
                'metadata': {
                    'generated_at': timezone.now().isoformat(),
                    'version': '1.0.0',
                    'report_type': 'premium',
                    'ai_engine': 'rule_based_fallback',
                    'total_pages': self._calculate_total_pages(),
                },
            }
            
            logger.info(f"âœ… Local report generated with {len(local_report)} sections")
            logger.info(f"ğŸ“‹ Report sections: {list(local_report.keys())}")
            
            return local_report
        except Exception as e:
            logger.error(f"âŒ Error generating local report: {e}", exc_info=True)
            # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ø­Ø¯Ø§Ù‚Ù„ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            return {
                'cover_page': {'store_name': getattr(analysis, 'store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡'), 'layout_score': 60},
                'executive_summary': {'paragraphs': ['Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø§Ø³Øª...']},
                'metadata': {
                    'generated_at': timezone.now().isoformat(),
                    'version': '1.0.0-error',
                    'report_type': 'premium',
                    'ai_engine': 'error_fallback',
                    'error': str(e)
                }
            }

    def _select_model(self, analysis) -> Optional[str]:
        """Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ AI Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù¾Ú©ÛŒØ¬"""
        package_type = getattr(analysis, 'package_type', 'basic') or 'basic'
        package_type = package_type.lower()
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ø§Ø² map
        selected_model = self.model_map.get(package_type, self.model_map['basic'])
        
        # Ù„Ø§Ú¯ ÙˆØ§Ø¶Ø­ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡
        model_name = selected_model.split('/')[-1] if '/' in selected_model else selected_model
        provider = selected_model.split('/')[0] if '/' in selected_model else 'unknown'
        
        logger.info(
            "ğŸ¯ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ AI: package_type=%s â†’ model=%s (provider=%s, full_path=%s)",
            package_type,
            model_name,
            provider,
            selected_model
        )
        
        return selected_model

    def _generate_report_with_ai(
        self,
        *,
        analysis,
        complete_data: Dict[str, Any],
        base_report: Dict[str, Any],
        model: str,
    ) -> Optional[Dict[str, Any]]:
        analysis_data = {}
        if hasattr(analysis, 'get_analysis_data'):
            try:
                analysis_data = analysis.get_analysis_data() or {}
            except Exception as exc:  # pragma: no cover
                logger.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: %s", exc)

        system_prompt = (
            "ØªÙˆ ÛŒÚ© ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø§Ø±Ø´Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡Ø³ØªÛŒ. Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ ÙÙ‚Ø· JSON Ù…Ø¹ØªØ¨Ø± Ø¨Ø§Ø´Ø¯. "
            "Ø³Ø§Ø®ØªØ§Ø± JSON Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯: executive_summary, technical_analysis, "
            "sales_analysis, behavior_analysis, action_plan, kpi_dashboard, warnings. "
            "Ù‡Ø± Ø¨Ø®Ø´ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ùˆ Ø§Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ù‚Ø¹â€ŒØ¨ÛŒÙ†Ø§Ù†Ù‡ Ø¨Ø§Ø´Ø¯. ØªÙ…Ø§Ù… Ù…ØªÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ùˆ Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†."
        )

        schema_hint = {
            "executive_summary": {
                "paragraphs": ["Ù…ØªÙ†"],
                "key_metrics": {
                    "current_sales": "...",
                    "projected_sales": "...",
                    "customer_conversion_rate": "...",
                    "expected_roi": "...",
                    "payback_period": "...",
                },
                "expected_roi": "...",
                "payback_period": "...",
            },
            "technical_analysis": {
                "entry_analysis": {
                    "description": "...",
                    "recommendations": ["..."],
                    "note": "..."
                },
                "hot_zones": [{"zone": "...", "importance": "...", "current_traffic": "...", "recommendation": "..."}],
                "cold_zones": [{"zone": "...", "issue": "...", "recommendation": "..."}],
                "path_optimization": "...",
            },
            "sales_analysis": {
                "narrative": "...",
                "before_after": {
                    "current_layout_revenue": "...",
                    "projected_layout_revenue": "...",
                    "improvement": "..."
                },
                "insights": ["..."],
                "data_source_note": "..."
            },
            "behavior_analysis": {
                "video": {
                    "status": "...",
                    "details": ["..."]
                },
                "movement": {
                    "primary_path_usage": "...",
                    "secondary_path_usage": "...",
                    "unused_areas": "...",
                    "recommendation": "..."
                },
                "interaction_points": [{"point": "...", "interaction_rate": "...", "recommendation": "..."}],
                "ux": {
                    "overall_score": "...",
                    "navigation": "...",
                    "findability": "...",
                    "recommendations": ["..."]
                },
                "note": "..."
            },
            "action_plan": {
                "urgent": [{"action": "...", "effect_on_sales": "...", "time_to_execute": "...", "cost_display": "...", "roi_months": "..."}],
                "medium_term": [{"action": "...", "effect_on_sales": "...", "time_to_execute": "...", "cost_display": "...", "roi_months": "..."}],
                "long_term": [{"action": "...", "effect_on_sales": "...", "time_to_execute": "...", "cost_display": "...", "roi_months": "..."}]
            },
            "kpi_dashboard": {
                "conversion_rate": {"current": "...", "target": "...", "improvement": "..."},
                "visit_to_purchase": {"current": "...", "target": "...", "improvement": "..."},
                "average_stop_per_section": {"current": "...", "target": "...", "improvement": "..."},
                "space_productivity": {"current": "...", "target": "...", "improvement": "..."},
                "visual_satisfaction": {"current": "...", "target": "...", "improvement": "..."}
            },
            "warnings": ["..."]
        }

        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ prompt Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§Ù‡Ø§ÛŒ API
        analysis_data_str = json.dumps(analysis_data, ensure_ascii=False, default=str)
        base_summary_str = json.dumps(base_report.get('executive_summary', {}), ensure_ascii=False, default=str)
        schema_str = json.dumps(schema_hint, ensure_ascii=False)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø·ÙˆÙ„ Ú©Ù„ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
        total_length = len(analysis_data_str) + len(base_summary_str) + len(schema_str)
        max_prompt_length = 12000  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ‚Ø±ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Liara AI
        
        if total_length > max_prompt_length:
            # Ú©Ø§Ù‡Ø´ Ø·ÙˆÙ„ analysis_data_str
            reduction_factor = max_prompt_length / total_length * 0.9  # 90% Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
            analysis_data_str = analysis_data_str[:int(len(analysis_data_str) * reduction_factor)]
            base_summary_str = base_summary_str[:int(len(base_summary_str) * reduction_factor)]
            logger.warning(f"âš ï¸ Prompt length reduced from {total_length} to {len(analysis_data_str) + len(base_summary_str) + len(schema_str)}")
        
        user_prompt = (
            f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡: Ù†Ø§Ù…={getattr(analysis, 'store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}ØŒ Ù†ÙˆØ¹={getattr(analysis, 'store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')}ØŒ "
            f"Ù…ØªØ±Ø§Ú˜={getattr(analysis, 'store_size', 'Ù†Ø§Ù…Ø´Ø®Øµ')}ØŒ "
            f"ÙˆØ¶Ø¹ÛŒØª Ø¨Ø³ØªÙ‡={getattr(analysis, 'package_type', 'basic')}\n"
            f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ÛŒ: {analysis_data_str}\n"
            f"Ø®Ù„Ø§ØµÙ‡ Ù‚Ø¨Ù„ÛŒ: {base_summary_str}\n"
            f"Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ schema Ø²ÛŒØ± JSON Ø¯Ù‚ÛŒÙ‚ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†: {schema_str}"
        )

        # Ù„Ø§Ú¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ Ùˆ Ø¯Ø±Ø®ÙˆØ§Ø³Øª
        model_display = model.split('/')[-1] if '/' in model else model
        provider = model.split('/')[0] if '/' in model else 'unknown'
        logger.info(
            "ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Liara AI - Model: %s (Provider: %s) | Prompt Length: %d chars | Analysis ID: %s",
            model_display,
            provider,
            len(user_prompt),
            getattr(analysis, 'id', 'unknown')
        )

        try:
            response = self.ai_client.chat(
                model=model,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.35,
                max_output_tokens=6000,
            )
            
            logger.info(
                "ğŸ“¥ Ù¾Ø§Ø³Ø® Ø§Ø² Liara AI Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ - Model: %s | Response Length: %d chars",
                model_display,
                len(response.content) if hasattr(response, 'content') else 0
            )
            
            # Ù¾Ø§Ø±Ø³ JSON response
            try:
                enrichment_data = response.json()
                if enrichment_data:
                    logger.info(f"âœ… Enrichment Ø§Ø² Liara AI Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ (keys: {list(enrichment_data.keys())})")
                    return enrichment_data
                else:
                    logger.warning("âš ï¸ Enrichment Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
                    return None
            except LiaraAIError as json_exc:
                logger.warning("âš ï¸ Ù¾Ø§Ø³Ø® Liara Ù‚Ø§Ø¨Ù„ Ù¾Ø§Ø±Ø³ Ù†Ø¨ÙˆØ¯: %s", json_exc)
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ extract Ú©Ø±Ø¯Ù† JSON Ø§Ø² content Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø³ØªÛŒ
                try:
                    import re
                    content = response.content
                    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† JSON Ø¯Ø± content
                    json_match = re.search(r'\{.*\}', content, re.DOTALL)
                    if json_match:
                        enrichment_data = json.loads(json_match.group())
                        logger.info("âœ… JSON Ø§Ø² content Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯")
                        return enrichment_data
                except Exception as extract_exc:
                    logger.warning("âš ï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ø§Ø² content Ù†Ø§Ù…ÙˆÙÙ‚: %s", extract_exc)
                return None
        except LiaraAIError as exc:
            logger.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Liara AI: %s", exc)
            raise  # Re-raise Ø¨Ø±Ø§ÛŒ handling Ø¯Ø± level Ø¨Ø§Ù„Ø§ØªØ±
        except Exception as exc:
            logger.error("âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± _generate_report_with_ai: %s", exc, exc_info=True)
            raise

    def _merge_ai_enrichment(self, report: Dict[str, Any], enrichment: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ø®Ø±ÙˆØ¬ÛŒ AI"""

        executive = enrichment.get('executive_summary', {})
        if executive.get('paragraphs'):
            report['executive_summary']['paragraphs'] = executive['paragraphs']
        if executive.get('expected_roi'):
            report['executive_summary']['expected_roi'] = executive.get('expected_roi')
        if executive.get('payback_period'):
            report['executive_summary']['payback_period'] = executive.get('payback_period')
        if executive.get('key_metrics'):
            report['executive_summary']['key_metrics'].update(executive['key_metrics'])

        tech = enrichment.get('technical_analysis', {})
        if tech.get('entry_analysis'):
            report['technical_analysis']['entry_analysis'].update(tech['entry_analysis'])
        if tech.get('hot_zones') or tech.get('cold_zones'):
            zones = report['technical_analysis'].setdefault('zones_analysis', {})
            if tech.get('hot_zones'):
                zones['hot_zones'] = tech['hot_zones']
            if tech.get('cold_zones'):
                zones['cold_zones'] = tech['cold_zones']
        if tech.get('path_optimization'):
            report['technical_analysis'].setdefault('zones_analysis', {})['movement_path'] = tech['path_optimization']
        # Merge Ú©Ø±Ø¯Ù† shelf_analysis Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if tech.get('shelf_analysis'):
            if 'shelf_analysis' not in report['technical_analysis']:
                report['technical_analysis']['shelf_analysis'] = {}
            report['technical_analysis']['shelf_analysis'].update(tech['shelf_analysis'])
        # Merge Ú©Ø±Ø¯Ù† lighting_analysis Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if tech.get('lighting_analysis'):
            if 'lighting_analysis' not in report['technical_analysis']:
                report['technical_analysis']['lighting_analysis'] = {}
            report['technical_analysis']['lighting_analysis'].update(tech['lighting_analysis'])
        # Merge Ú©Ø±Ø¯Ù† checkout_analysis Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if tech.get('checkout_analysis'):
            if 'checkout_analysis' not in report['technical_analysis']:
                report['technical_analysis']['checkout_analysis'] = {}
            report['technical_analysis']['checkout_analysis'].update(tech['checkout_analysis'])
        # Merge Ú©Ø±Ø¯Ù† unused_spaces Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if tech.get('unused_spaces'):
            if 'unused_spaces' not in report['technical_analysis']:
                report['technical_analysis']['unused_spaces'] = {}
            report['technical_analysis']['unused_spaces'].update(tech['unused_spaces'])

        sales = enrichment.get('sales_analysis', {})
        if sales.get('narrative'):
            report['sales_analysis']['sales_layout_correlation'] = sales['narrative']
        if sales.get('before_after'):
            report['sales_analysis']['before_after_comparison'].update(sales['before_after'])
        if sales.get('insights'):
            insights = sales['insights']
            if isinstance(insights, list):
                report['sales_analysis']['insights'] = ' â€¢ '.join(insights)
            else:
                report['sales_analysis']['insights'] = insights
        if sales.get('data_source_note'):
            report['sales_analysis']['data_source_note'] = sales['data_source_note']

        behavior = enrichment.get('behavior_analysis', {})
        if behavior.get('video'):
            report['behavior_analysis']['video_analysis'] = behavior['video']
        if behavior.get('movement'):
            report['behavior_analysis']['movement_patterns'] = behavior['movement']
        if behavior.get('interaction_points'):
            report['behavior_analysis']['interaction_points'] = behavior['interaction_points']
        if behavior.get('ux'):
            report['behavior_analysis']['ux_analysis'] = behavior['ux']
        if behavior.get('note'):
            report['behavior_analysis']['note'] = behavior['note']

        action_plan = enrichment.get('action_plan', {})
        for key in ('urgent', 'medium_term', 'long_term'):
            if action_plan.get(key):
                report['action_plan'][key] = action_plan[key]

        kpi = enrichment.get('kpi_dashboard', {})
        if kpi:
            for key, value in kpi.items():
                if key in report['kpi_dashboard'] and isinstance(value, dict):
                    report['kpi_dashboard'][key].update(value)
                else:
                    report['kpi_dashboard'][key] = value

        warnings = enrichment.get('warnings')
        if warnings:
            report['warnings'] = warnings

        return report

    def _gather_complete_data(self, analysis, images_data, video_data, sales_data) -> Dict:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„"""
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² safe methods Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯
        # ØªÙˆØ¬Ù‡: Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø± (additional_info, business_goals, marketing_budget)
        # ÙÙ‚Ø· Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ùˆ Ù‡Ø±Ú¯Ø² Ø¨Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        contact_phone = ''
        try:
            if hasattr(analysis, 'safe_contact_phone'):
                contact_phone = analysis.safe_contact_phone or ''
            elif hasattr(analysis, 'contact_phone'):
                contact_phone = getattr(analysis, 'contact_phone', '') or ''
        except (AttributeError, Exception):
            contact_phone = ''
        
        contact_email = ''
        try:
            if hasattr(analysis, 'safe_contact_email'):
                contact_email = analysis.safe_contact_email or ''
            elif hasattr(analysis, 'contact_email'):
                contact_email = getattr(analysis, 'contact_email', '') or ''
        except (AttributeError, Exception):
            contact_email = ''
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² analysis_data Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ù†Ø¯
        analysis_data_dict = {}
        try:
            if hasattr(analysis, 'analysis_data') and analysis.analysis_data:
                analysis_data_dict = analysis.analysis_data if isinstance(analysis.analysis_data, dict) else {}
        except Exception:
            pass
        
        # Ø¯Ø³ØªØ±Ø³ÛŒ safe Ø¨Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ù†Ø¯
        store_address = ''
        try:
            # Ø§ÙˆÙ„ Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            if 'store_address' in analysis_data_dict:
                store_address = analysis_data_dict.get('store_address', '') or ''
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² defer Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®ÙˆØ§Ù†Ø¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ú©Ù„â€ŒØ¯Ø§Ø±
            elif hasattr(analysis, 'store_address'):
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² getattr ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø·Ù…Ø¦Ù† Ù‡Ø³ØªÛŒÙ… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
                try:
                    store_address = getattr(analysis, 'store_address', '') or ''
                except Exception:
                    # Ø§Ú¯Ø± Ø®Ø·Ø§ Ø¯Ø§Ø¯ØŒ Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                    store_address = ''
        except (AttributeError, Exception):
            store_address = ''
        
        additional_info = ''
        try:
            # ÙÙ‚Ø· Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† - Ù‡Ø±Ú¯Ø² Ø¨Ù‡ ÙÛŒÙ„Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ù†
            if 'additional_info' in analysis_data_dict:
                additional_info = analysis_data_dict.get('additional_info', '') or ''
        except (AttributeError, Exception):
            additional_info = ''
        
        business_goals = ''
        try:
            # ÙÙ‚Ø· Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† - Ù‡Ø±Ú¯Ø² Ø¨Ù‡ ÙÛŒÙ„Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ù†
            if 'business_goals' in analysis_data_dict:
                business_goals = analysis_data_dict.get('business_goals', '') or ''
        except (AttributeError, Exception):
            business_goals = ''
        
        marketing_budget = ''
        try:
            # ÙÙ‚Ø· Ø§Ø² analysis_data Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† - Ù‡Ø±Ú¯Ø² Ø¨Ù‡ ÙÛŒÙ„Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ù†
            if 'marketing_budget' in analysis_data_dict:
                marketing_budget = analysis_data_dict.get('marketing_budget', '') or ''
        except (AttributeError, Exception):
            marketing_budget = ''
        
        return {
            'analysis': analysis,
            'store_name': getattr(analysis, 'store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
            'store_type': getattr(analysis, 'store_type', ''),
            'store_size': getattr(analysis, 'store_size', ''),
            'store_address': store_address,
            'contact_phone': contact_phone or '',
            'contact_email': contact_email or '',
            'additional_info': additional_info,
            'business_goals': business_goals,
            'marketing_budget': marketing_budget,
            'images': images_data or [],
            'videos': video_data or {},
            'sales': sales_data or {},
            'has_images': bool(images_data and len(images_data) > 0),
            'has_videos': bool(video_data),
            'has_sales_data': bool(sales_data),
            'completeness_score': self._calculate_completeness(images_data, video_data, sales_data)
        }
    
    def _calculate_completeness(self, images, videos, sales_data) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² ØªÚ©Ù…ÛŒÙ„ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        score = 0.0
        
        if images and len(images) > 0:
            score += 0.3
            if len(images) > 5:
                score += 0.1
        
        if videos:
            score += 0.3
        
        if sales_data:
            score += 0.3
        
        return round(score, 2)
    
    def _generate_cover_page(self, analysis, data) -> Dict:
        """ØµÙØ­Ù‡ Ø§ÙˆÙ„ - Ø±ÙˆÛŒ Ø¬Ù„Ø¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Layout Score
        layout_score = self._calculate_layout_score(data)
        store_name = getattr(analysis, 'store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
        analysis_id = getattr(analysis, 'id', getattr(analysis, 'pk', 0))
        
        return {
            'store_name': store_name,
            'analysis_date': timezone.now().strftime('%Y/%m/%d'),
            'report_version': '1.0.0',
            'layout_score': layout_score,
            'current_score': layout_score,
            'target_score': layout_score + 15,  # Ù‡Ø¯Ù 15 Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±
            'comparison': {
                'current': layout_score,
                'target': layout_score + 15,
                'improvement_potential': f'+{15} Ø§Ù…ØªÛŒØ§Ø²'
            },
            'quick_wins_count': 12,
            'estimated_roi': self._estimate_roi(layout_score),
            'time_to_roi': '8-12 Ù‡ÙØªÙ‡',
            'qr_code_url': f'/store/analysis/{analysis_id}/report/',
            'analyst': 'Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ',
            'human_reviewer': 'Ù…Ù‡Ù†Ø¯Ø³ÛŒÙ† Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
        }
    
    def _calculate_layout_score(self, data) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ù„ÛŒ (Layout Score)"""
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        base_score = 60.0
        
        if data['has_images']:
            base_score += 10
        if data['has_videos']:
            base_score += 10
        if data['has_sales_data']:
            base_score += 10
        
        # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        if data['completeness_score'] > 0.7:
            base_score += 5
        
        return round(min(base_score, 95), 1)  # Ø­Ø¯Ø§Ú©Ø«Ø± 95
    
    def _estimate_roi(self, current_score: float) -> Dict:
        """ØªØ®Ù…ÛŒÙ† ROI Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² ÙØ¹Ù„ÛŒ"""
        # ÙØ±Ù…ÙˆÙ„ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ®Ù…ÛŒÙ†
        improvement_potential = (100 - current_score) / 10
        
        return {
            'potential_sales_increase': f'{improvement_potential * 8:.1f}%',
            'estimated_cost': '20,000,000 ØªÙˆÙ…Ø§Ù†',
            'roi_months': 3.5,
            'lifetime_value': '150,000,000 ØªÙˆÙ…Ø§Ù†'
        }
    
    def _generate_executive_summary(self, data) -> Dict:
        """Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ 3 Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§ÙÛŒ"""
        
        analysis = data['analysis']
        current_score = self._calculate_layout_score(data)
        
        store_name = getattr(analysis, 'store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
        summary_paragraphs = [
            f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ù…ØªÛŒØ§Ø² {current_score} Ø§Ø² 100 Ø±Ø§ Ú©Ø³Ø¨ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª. "
            f"Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ {data['completeness_score'] * 100:.0f}% ØªÚ©Ù…ÛŒÙ„ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ "
            f"Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¨Ù‡Ø¨ÙˆØ¯ {100 - current_score:.1f} Ø§Ù…ØªÛŒØ§Ø²ÛŒ Ø¯Ø± Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.",
            
            f"Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¨Ø§ Ø§Ø¹Ù…Ø§Ù„ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ØŒ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† {8 + (100 - current_score) / 5:.1f}% Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§Ø¨Ø¯. "
            f"Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ 8 ØªØ§ 12 Ù‡ÙØªÙ‡â€ŒØ§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø³Øª Ùˆ "
            f"Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ù…Ø´ØªØ±ÛŒ Ø§Ø² Ø³Ø·Ø­ ÙØ¹Ù„ÛŒ Ø¨Ù‡ {(current_score + 20) / 10:.1f}Ùª Ù‚Ø§Ø¨Ù„ Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø³Øª.",
            
            f"Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ 12 Ø§Ù‚Ø¯Ø§Ù… ÙÙˆØ±ÛŒØŒ 8 Ø±Ø§Ù‡Ú©Ø§Ø± Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª Ùˆ 5 Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ "
            f"Ù…Ø¬Ù…ÙˆØ¹Ø§Ù‹ Ù…Ù†Ø¬Ø± Ø¨Ù‡ ØªÙ‚ÙˆÛŒØª {15 + current_score / 5:.1f}%â€ŒØ§ÛŒ Ø±Ø´Ø¯ Ø³ÙˆØ¯Ø¢ÙˆØ±ÛŒ Ø¯Ø± Ø·ÙˆÙ„ 90 Ø±ÙˆØ² Ù…ÛŒâ€ŒØ´ÙˆØ¯."
        ]
        
        return {
            'paragraphs': summary_paragraphs,
            'key_metrics': {
                'current_sales': '5,000,000 ØªÙˆÙ…Ø§Ù†/Ø±ÙˆØ²',
                'projected_sales': f'{5_000_000 * (1 + (100 - current_score) / 500):.0f} ØªÙˆÙ…Ø§Ù†/Ø±ÙˆØ²',
                'sale_increase_percentage': f'{8 + (100 - current_score) / 5:.1f}%',
                'roi_months': 3.5,
                'customer_conversion_rate': f'{(current_score + 20) / 10:.1f}%'
            },
            'recommendation_intro': f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {getattr(analysis, 'store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')} Ø§Ø² Ù†Ø¸Ø± Ø¬Ø±ÛŒØ§Ù† Ø­Ø±Ú©ØªÛŒ {current_score}% Ù†Ù…Ø±Ù‡ Ø¯Ø§Ø±Ø¯ØŒ "
                                   f"Ø§Ù…Ø§ {'Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§' if current_score < 70 else 'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ'} "
                                   f"Ù…ÙˆØ¬Ø¨ Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ† Ø­Ø¯ÙˆØ¯ {15 - current_score / 7:.1f}% ÙØ±ÙˆØ´ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª."
        }
    
    def _generate_technical_analysis(self, data) -> Dict:
        """Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ - Technical Analysis"""
        
        analysis = data['analysis']
        images_count = len(data['images']) if data['images'] else 0
        
        return {
            'entry_analysis': {
                'description': 'ØªØ­Ù„ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒ',
                'visualization': 'heatmap' if data['has_images'] else 'simulation',
                'recommendations': self._generate_entry_recommendations(data),
                'note': 'âš ï¸ Ù†Ù‚Ø´Ù‡ Ø¯Ù‚ÛŒÙ‚ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØµØ§ÙˆÛŒØ± Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø±Ø¯' if images_count < 3 else 'âœ… ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØµØ§ÙˆÛŒØ±'
            },
            'zones_analysis': {
                'hot_zones': self._identify_hot_zones(data),
                'cold_zones': self._identify_cold_zones(data),
                'movement_path': self._suggest_optimal_path(data)
            },
            'shelf_analysis': {
                'current_layout': 'Ù†Ù…ÙˆØ¯Ø§Ø± Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ¹Ù„ÛŒ',
                'proposed_layout': 'Ù†Ù…ÙˆØ¯Ø§Ø± Ú†ÛŒØ¯Ù…Ø§Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ',
                'density_analysis': self._analyze_product_density(data),
                'customer_visibility': self._analyze_visibility(data)
            },
            'checkout_analysis': {
                'queue_analysis': self._analyze_queues(data),
                'wait_time_optimization': self._optimize_wait_times(data)
            },
            'lighting_analysis': self._build_lighting_analysis(data),
            'unused_spaces': {
                'identified': self._identify_unused_spaces(data),
                'suggestions': self._suggest_unused_space_usage(data)
            }
        }
    
    def _generate_entry_recommendations(self, data) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ"""
        return [
            'ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¯Ø± Ù…Ø±Ú©Ø² Ù†Ù…Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯',
            'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ Ø¯Ø± ÙØ§ØµÙ„Ù‡ 3-5 Ù…ØªØ±ÛŒ Ø§Ø² ÙˆØ±ÙˆØ¯ÛŒ',
            'Ø§Ø² ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ÛŒ Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø¯Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯',
            'ÙØ¶Ø§ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª Ø¨Ø¹Ø¯ Ø§Ø² 10 Ù…ØªØ± Ø§ÙˆÙ„ÛŒÙ† Ù†Ù…Ø§ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯'
        ]
    
    def _identify_hot_zones(self, data) -> List[Dict]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø¯Ø§Øº"""
        return [
            {'zone': 'ÙˆØ±ÙˆØ¯ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'importance': 'Very High', 'current_traffic': 'High', 'recommendation': 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø­Ø§Ø´ÛŒÙ‡ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ø§'},
            {'zone': 'ØµÙ†Ø¯ÙˆÙ‚', 'importance': 'Critical', 'current_traffic': 'Very High', 'recommendation': 'Ù…Ø­ØµÙˆÙ„Ø§Øª impulse Ø®Ø±ÛŒØ¯'},
            {'zone': 'Ù…Ø±Ú©Ø² ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'importance': 'High', 'current_traffic': 'Medium', 'recommendation': 'Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÛŒÚ˜Ù‡'}
        ]
    
    def _identify_cold_zones(self, data) -> List[Dict]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø³Ø±Ø¯"""
        return [
            {'zone': 'Ù¾Ø´Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'issue': 'Ø¯Ø³ØªØ±Ø³ÛŒ Ú©Ù…', 'recommendation': 'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¨ÛŒØ´ØªØ± ÛŒØ§ Ø§Ù†ØªÙ‚Ø§Ù„ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§'},
            {'zone': 'Ø§Ù†Ø¨Ø§Ø± Ù†Ù…Ø§ÛŒ', 'issue': 'ÙØ¶Ø§ÛŒ ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡', 'recommendation': 'ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ¶Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ'}
        ]
    
    def _suggest_optimal_path(self, data) -> str:
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø³ÛŒØ± Ø­Ø±Ú©ØªÛŒ Ø¨Ù‡ÛŒÙ†Ù‡"""
        return 'ÙˆØ±ÙˆØ¯ÛŒ â†’ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ â†’ Ù…Ø±Ú©Ø² ÙØ±ÙˆØ´Ú¯Ø§Ù‡ â†’ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÛŒÚ˜Ù‡ â†’ ØµÙ†Ø¯ÙˆÙ‚ â†’ Ø®Ø±ÙˆØ¬ÛŒ'
    
    def _analyze_product_density(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§Ú©Ù… Ú©Ø§Ù„Ø§"""
        return {
            'current_density': '70%',
            'optimal_density': '80%',
            'recommendation': 'Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù‚Ø§Ø¨Ù„ Ø±ÙˆÛŒØª Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† 14%'
        }
    
    def _analyze_visibility(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ÙØ§ØµÙ„Ù‡ Ø¯ÛŒØ¯ Ù…Ø´ØªØ±ÛŒ"""
        return {
            'average_customer_view_distance': '2.5 Ù…ØªØ±',
            'product_visibility_rate': '68%',
            'recommendation': 'Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø±ØªÙØ§Ø¹ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯ Ø¨Ù‡ØªØ±'
        }
    
    def _analyze_queues(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØµÙâ€ŒÙ‡Ø§"""
        return {
            'average_wait_time': '2.5 Ø¯Ù‚ÛŒÙ‚Ù‡',
            'peak_wait_time': '5 Ø¯Ù‚ÛŒÙ‚Ù‡',
            'recommendations': [
                'Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ Ø¯Ø± Ø³Ø§Ø¹Ø§Øª Ù¾ÛŒÚ©',
                'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØµÙ†Ø¯ÙˆÙ‚ Ø®ÙˆØ¯Ù¾Ø±Ø¯Ø§Ø²',
                'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¶Ø§ÛŒ Ø§Ù†ØªØ¸Ø§Ø±'
            ]
        }
    
    def _optimize_wait_times(self, data) -> List[str]:
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±"""
        return [
            'Ø§ÙØ²Ø§ÛŒØ´ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§: Ú©Ø§Ù‡Ø´ 40% Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±',
            'Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©ÙˆÚ†Ú© Ø¯Ø± ØµÙ: Ø§ÙØ²Ø§ÛŒØ´ 8% ÙØ±ÙˆØ´',
            'Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ø®ÙˆØ§Ù†Ø´ Ø¨Ø§Ø±Ú©Ø¯ Ø¯Ø± Ø¯Ø³Øª Ù…Ø´ØªØ±ÛŒ: Ø³Ø±Ø¹Øª 30% Ø¨ÛŒØ´ØªØ±'
        ]
    
    def _analyze_lighting(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ± Ùˆ Ø±Ù†Ú¯"""
        return {
            'current_lighting_level': 'Ù…Ù†Ø§Ø³Ø¨',
            'lux_measurement': 'Ø­Ø¯ÙˆØ¯ 400-500 lux',
            'recommendations': [
                'Ø§ÙØ²Ø§ÛŒØ´ Ù†ÙˆØ± Ø¯Ø± Ø¨Ø®Ø´ Ú©ÙØ´â€ŒÙ‡Ø§: 20% Ø±ÙˆØ´Ù†â€ŒØªØ±',
                'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ÙˆØ± Ú¯Ø±Ù… Ø¯Ø± Ø±Ø³ØªÙˆØ±Ø§Ù†â€ŒÙ‡Ø§',
                'Ù†ÙˆØ± Ø³Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©ÛŒ'
            ]
        }
    
    def _apply_color_psychology(self, data) -> Dict:
        """Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯"""
        return {
            'current_color_scheme': 'ØªØ­Ù„ÛŒÙ„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯',
            'recommendations': [
                'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ù… Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾ÙˆØ´Ø§Ú©',
                'Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù„Ø§ÛŒÙ… Ø¨Ø±Ø§ÛŒ ÙØ¶Ø§ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª',
                'Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ø±Ù†Ú¯ Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ù†Ù‚Ø§Ø· Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©'
            ]
        }
    
    def _generate_lighting_recommendations(self, data) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ"""
        return [
            'Ø§ÙØ²Ø§ÛŒØ´ Ø´Ø¯Øª Ù†ÙˆØ± Ø¯Ø± Ø¨Ø®Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ú¯Ø±Ø§Ù†â€ŒÙ‚ÛŒÙ…Øª',
            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LEDâ€ŒÙ‡Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…â€ŒÙ¾Ø°ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±ÙˆØ²',
            'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ accent Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙˆÛŒÚ˜Ù‡'
        ]
    
    def _build_lighting_analysis(self, data) -> Dict:
        """Ø³Ø§Ø®Øª Ø³Ø§Ø®ØªØ§Ø± Ú©Ø§Ù…Ù„ lighting_analysis"""
        lighting_data = self._analyze_lighting(data)
        return {
            'current_lighting': lighting_data.get('current_lighting_level', 'Ù…Ù†Ø§Ø³Ø¨'),
            'lux_measurement': lighting_data.get('lux_measurement', 'Ø­Ø¯ÙˆØ¯ 400-500 lux'),
            'color_psychology': self._apply_color_psychology(data),
            'recommendations': self._generate_lighting_recommendations(data)
        }
    
    def _identify_unused_spaces(self, data) -> List[Dict]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ¶Ø§Ù‡Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡"""
        return [
            {'space': 'ÙØ¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ÛŒ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ (2.5 Ù…ØªØ±)', 'waste': '180 Ù…ØªØ±Ù…Ø±Ø¨Ø¹', 'suggestion': 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³Ø¨Ú©'},
            {'space': 'Ú†Ù‡Ø§Ø±Ø±Ø§Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'waste': '15 Ù…ØªØ±Ù…Ø±Ø¨Ø¹', 'suggestion': 'Ø§Ø³ØªÙ†Ø¯ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ'}
        ]
    
    def _suggest_unused_space_usage(self, data) -> List[str]:
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ¶Ø§Ù‡Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡"""
        return [
            'ØªØ¨Ø¯ÛŒÙ„ 30 Ù…ØªØ±Ù…Ø±Ø¨Ø¹ Ø¨Ù‡ ÙØ¶Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ Ù…ÙˆÙ‚Øª',
            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ¶Ø§ÛŒ Ù¾Ø´ØªÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¹Ù…Ø¯Ù‡',
            'Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† ØªØ¨Ù„ÛŒØºØ§Øª Ø¨Ø±Ù†Ø¯ Ø¯Ø± Ù†Ù‚Ø§Ø· Ø®Ø§Ù„ÛŒ'
        ]
    
    def _generate_sales_analysis(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´"""
        
        return {
            'sales_layout_correlation': self._analyze_sales_layout_correlation(data),
            'before_after_comparison': self._generate_before_after_chart(data),
            'insights': self._generate_ai_insights(data),
            'data_source_note': 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ' if not data['has_sales_data'] else 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ÙØ±ÙˆØ´'
        }
    
    def _analyze_sales_layout_correlation(self, data) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ø±ØªØ¨Ø§Ø· Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ ÙØ±ÙˆØ´"""
        if data['has_sales_data']:
            return "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ù…Ø´ØªØ±ÛŒ 73% Ø¨ÛŒØ´ØªØ± ÙØ±ÙˆØ´ Ø¯Ø§Ø±Ù†Ø¯."
        return "Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ù…Ø´ØªØ±ÛŒ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ ØµÙ†Ø¹ØªÛŒ) 65-75% Ø¨ÛŒØ´ØªØ± ÙØ±ÙˆØ´ Ø¯Ø§Ø±Ù†Ø¯."
    
    def _generate_before_after_chart(self, data) -> Dict:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯"""
        return {
            'current_layout_revenue': '4,800,000 ØªÙˆÙ…Ø§Ù†/Ø±ÙˆØ²',
            'projected_layout_revenue': '6,200,000 ØªÙˆÙ…Ø§Ù†/Ø±ÙˆØ²',
            'improvement': '29% Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯',
            'visualization': 'chart_data_available_in_pdf'
        }
    
    def _generate_ai_insights(self, data) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
        return "ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø§ÙØ²Ø§ÛŒØ´ Ø¯ÛŒØ¯Ù¾Ø°ÛŒØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø§ Ø­Ø§Ø´ÛŒÙ‡ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ù…Ø´ØªØ±ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø§Ø´ÛŒÙ‡ Ø³ÙˆØ¯ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ Û±Û·Ùª Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯."
    
    def _generate_behavior_analysis(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ"""
        
        behavior_data = {
            'video_analysis': self._analyze_customer_video(data),
            'movement_patterns': self._analyze_movement_patterns(data),
            'interaction_points': self._analyze_interaction_points(data),
            'ux_analysis': self._analyze_ux_experience(data)
        }
        
        if not data['has_videos']:
            behavior_data['note'] = 'âš ï¸ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ØªØ§ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø´ÙˆØ¯.'
        
        return behavior_data
    
    def _analyze_customer_video(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù…Ø´ØªØ±ÛŒ"""
        if not data['has_videos']:
            return {
                'status': 'pending_video_upload',
                'message': 'Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØŒ Ù„Ø·ÙØ§Ù‹ ÙˆÛŒØ¯ÛŒÙˆ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯'
            }
        
        return {
            'average_customer_path': '6.2 Ø¯Ù‚ÛŒÙ‚Ù‡',
            'pause_points': 8,
            'purchase_decision_points': 3,
            'recommendations': ['Ú©Ø§Ù‡Ø´ Ù…Ø³ÛŒØ± Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† 15% Ø¨Ø±Ø§ÛŒ ØªØ³Ø±ÛŒØ¹ Ø®Ø±ÛŒØ¯']
        }
    
    def _analyze_movement_patterns(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÛŒ Ø­Ø±Ú©ØªÛŒ"""
        return {
            'primary_path_usage': '68%',
            'secondary_path_usage': '22%',
            'unused_areas': '10%',
            'recommendations': ['Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² 40% ÙØ¶Ø§ÛŒ Ú©Ù…â€ŒØ¨Ø§Ø²Ø¯Ù‡']
        }
    
    def _analyze_interaction_points(self, data) -> List[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· ØªØ¹Ø§Ù…Ù„"""
        return [
            {'point': 'ÙˆØ±ÙˆØ¯ÛŒ', 'interaction_rate': '95%', 'recommendation': 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯'},
            {'point': 'ØµÙ†Ø¯ÙˆÙ‚', 'interaction_rate': '100%', 'recommendation': 'Ù…Ø­ØµÙˆÙ„Ø§Øª impulse'},
            {'point': 'Ø®Ø±ÙˆØ¬ÛŒ', 'interaction_rate': '75%', 'recommendation': 'Ú©ØªØ§Ø¨â€ŒÚ†Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù…Ø´ØªØ±ÛŒ'}
        ]
    
    def _analyze_ux_experience(self, data) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ"""
        return {
            'overall_ux_score': '7.2/10',
            'navigation_ease': 'Good',
            'product_findability': 'Medium',
            'recommendations': [
                'Ø§ÙØ²Ø§ÛŒØ´ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§',
                'Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù‚Ø§Ø· Ù…Ø±Ø¬Ø¹ Ø¨ÛŒØ´ØªØ±',
                'Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§Ù‡Ø§'
            ]
        }
    
    def _generate_action_plan(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø§Ø¬Ø±Ø§ÛŒÛŒ"""
        
        actions = {
            'urgent': [
                {
                    'action': 'ØªØºÛŒÛŒØ± Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ',
                    'cost': 5_000_000,
                    'cost_display': '5,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+12%',
                    'time_to_execute': '3 Ø±ÙˆØ²',
                    'priority': 'ÙÙˆØ±ÛŒ',
                    'roi_months': 2.1
                },
                {
                    'action': 'Ù†ØµØ¨ Ù…Ø­ØµÙˆÙ„Ø§Øª impulse Ø¯Ø± ØµÙ†Ø¯ÙˆÙ‚',
                    'cost': 2_000_000,
                    'cost_display': '2,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+5%',
                    'time_to_execute': '1 Ø±ÙˆØ²',
                    'priority': 'ÙÙˆØ±ÛŒ',
                    'roi_months': 1.2
                },
                {
                    'action': 'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒ',
                    'cost': 8_000_000,
                    'cost_display': '8,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+9%',
                    'time_to_execute': '5 Ø±ÙˆØ²',
                    'priority': 'ÙÙˆØ±ÛŒ',
                    'roi_months': 2.8
                }
            ],
            'medium_term': [
                {
                    'action': 'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¬Ø¯ÛŒØ¯',
                    'cost': 15_000_000,
                    'cost_display': '15,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+8%',
                    'time_to_execute': '2 Ù‡ÙØªÙ‡',
                    'priority': 'Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª',
                    'roi_months': 4.2
                },
                {
                    'action': 'Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ø¨Ø®Ø´ Ù¾Ø´ØªÛŒ',
                    'cost': 20_000_000,
                    'cost_display': '20,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+11%',
                    'time_to_execute': '3 Ù‡ÙØªÙ‡',
                    'priority': 'Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª',
                    'roi_months': 5.1
                }
            ],
            'long_term': [
                {
                    'action': 'Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ù„Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                    'cost': 40_000_000,
                    'cost_display': '40,000,000 ØªÙˆÙ…Ø§Ù†',
                    'effect_on_sales': '+25%',
                    'time_to_execute': '2 Ù…Ø§Ù‡',
                    'priority': 'Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª',
                    'roi_months': 8.5
                }
            ]
        }
        
        return actions
    
    def _generate_kpi_dashboard(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ KPI"""
        
        current_score = self._calculate_layout_score(data)
        
        return {
            'conversion_rate': {
                'current': f'{(current_score - 20) / 10:.1f}%',
                'target': f'{(current_score + 10) / 10:.1f}%',
                'improvement': '+1.2%'
            },
            'visit_to_purchase': {
                'current': f'{35 - (100 - current_score) / 5:.1f}%',
                'target': f'{40 - (100 - current_score) / 5:.1f}%',
                'improvement': '+5%'
            },
            'average_stop_per_section': {
                'current': '3.2', 'target': '4.1',
                'improvement': '+28%'
            },
            'space_productivity': {
                'current': f'{280000 - (100 - current_score) * 1000:,.0f} ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±Ù…Ø±Ø¨Ø¹',
                'target': f'{350000 - (100 - current_score) * 1000:,.0f} ØªÙˆÙ…Ø§Ù†/Ù…ØªØ±Ù…Ø±Ø¨Ø¹',
                'improvement': '+25%'
            },
            'visual_satisfaction': {
                'current': '7.5/10',
                'target': '8.8/10',
                'improvement': '+17%'
            },
            'charts_available': 'Yes - Ø¯Ø± Ù†Ø³Ø®Ù‡ PDF ØªØ¹Ø§Ù…Ù„ÛŒ'
        }
    
    def _generate_appendix(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨Ø®Ø´ Ù¾ÛŒÙˆØ³Øªâ€ŒÙ‡Ø§"""
        
        return {
            'original_images': data['images'] if data['images'] else [],
            'sales_raw_data': data['sales'] if data['has_sales_data'] else 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª',
            'data_warnings': self._generate_data_warnings(data),
            'missing_data_request': self._generate_missing_data_request(data)
        }
    
    def _generate_data_warnings(self, data) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡"""
        warnings = []
        
        if not data['has_images']:
            warnings.append('âš ï¸ ØªØµØ§ÙˆÛŒØ± ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Ø¯Ø§Ø±Ø¯.')
        
        if not data['has_videos']:
            warnings.append('âš ï¸ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.')
        
        if not data['has_sales_data']:
            warnings.append('âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.')
        
        if data['completeness_score'] < 0.6:
            warnings.append('âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„â€ŒØªØ±ØŒ Ù„Ø·ÙØ§Ù‹ ØªØµØ§ÙˆÛŒØ±ØŒ ÙˆÛŒØ¯ÛŒÙˆ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.')
        
        if len(warnings) == 0:
            warnings.append('âœ… ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø¯Ù‚ÛŒÙ‚ Ø§Ø³Øª.')
        
        return warnings
    
    def _generate_missing_data_request(self, data) -> List[str]:
        """Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ÛŒ"""
        missing = []
        
        if not data['has_images'] or len(data['images']) < 5:
            missing.append('ğŸ“¸ ØªØµØ§ÙˆÛŒØ± Ø¨ÛŒØ´ØªØ± Ø§Ø² ÙØ±ÙˆØ´Ú¯Ø§Ù‡ (Ø­Ø¯Ø§Ù‚Ù„ 5 ØªØµÙˆÛŒØ±)')
        
        if not data['has_videos']:
            missing.append('ğŸ¥ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒ (30-60 Ø«Ø§Ù†ÛŒÙ‡)')
        
        if not data['has_sales_data']:
            missing.append('ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ (Excel ÛŒØ§ CSV)')
        
        if not missing:
            return ['âœ… Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ú©Ù… Ù†ÛŒØ³Øª']
        
        return ['Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ ØªÚ©Ù…ÛŒÙ„ÛŒØŒ Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:'] + missing
    
    def _generate_subscription_hook(self, data) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨Ø®Ø´ Ø§Ø´ØªØ±Ø§Ú© Ù…Ø§Ù‡Ø§Ù†Ù‡"""
        
        return {
            'hook_phrase': 'Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø±Ø´Ø¯ Ø¯Ø± Ø·ÛŒ 90 Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡',
            'comparison': {
                'before': f"Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†: {self._calculate_layout_score(data)}/100",
                'after_3_months': f"Ø§Ù…ØªÛŒØ§Ø² Ù‡Ø¯Ù: {(self._calculate_layout_score(data) + 15):.1f}/100",
                'progress': '15 Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù‡Ø¨ÙˆØ¯'
            },
            'layout_progress': {
                'current_month': '68%',
                'projected_month_2': '76%',
                'projected_month_3': '84%'
            },
            'sales_growth_chart': 'available_in_premium_version',
            'next_review_recommendation': {
                'message': f"Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ø±Ø´Ø¯ 24Ùª ÙØ¹Ù„ÛŒØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¯Ø± 30 Ø±ÙˆØ² Ø¢ÛŒÙ†Ø¯Ù‡ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.",
                'discount': '30% ØªØ®ÙÛŒÙ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ',
                'cta': 'Ù‡Ù…ÛŒÙ† Ø§Ù„Ø§Ù† Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø±Ø§ Ø±Ø²Ø±Ùˆ Ú©Ù†ÛŒØ¯'
            }
        }
    
    def _calculate_total_pages(self) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª Ú¯Ø²Ø§Ø±Ø´"""
        return 150  # Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ú©Ø§Ù…Ù„

    def _generate_quality_checklist(self, report: Dict, data: Dict) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ú©Ù†ØªØ±Ù„ Ú©ÛŒÙÛŒØª Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´"""

        categories: List[Dict[str, Any]] = []
        total_items = 0
        completed_items = 0

        def add_category(title: str, icon: str) -> Dict[str, Any]:
            category = {
                'title': title,
                'icon': icon,
                'items': []
            }
            categories.append(category)
            return category

        def add_item(category: Dict[str, Any], label: str, condition: bool, success_note: str, fail_note: str) -> None:
            nonlocal total_items, completed_items
            status = bool(condition)
            category['items'].append({
                'label': label,
                'status': status,
                'note': success_note if status else fail_note
            })
            total_items += 1
            if status:
                completed_items += 1

        executive_summary = report.get('executive_summary', {})
        technical_analysis = report.get('technical_analysis', {})
        sales_analysis = report.get('sales_analysis', {})
        behavior_analysis = report.get('behavior_analysis', {})
        action_plan = report.get('action_plan', {})
        kpi_dashboard = report.get('kpi_dashboard', {})
        appendix = report.get('appendix', {})
        subscription_hook = report.get('subscription_hook', {})
        metadata = report.get('metadata', {})
        layout_score = self._calculate_layout_score(data) if data else 0
        estimated_roi = self._estimate_roi(layout_score) if data else {}

        # 1) Execution & Content
        execution_category = add_category('Ø§Ø¬Ø±Ø§ÛŒÛŒ Ùˆ Ù…Ø­ØªÙˆØ§', 'ğŸ“„')
        add_item(
            execution_category,
            'Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø´ÙØ§Ù Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù‚Ø¯Ø§Ù…',
            bool(executive_summary.get('paragraphs') or executive_summary.get('summary')),
            'Ø³Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù ØªØ­Ù„ÛŒÙ„ÛŒ Ùˆ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø±Ø¯.'
        )
        add_item(
            execution_category,
            'ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø²ÙˆÙ†ÛŒÙ†Ú¯',
            bool(technical_analysis),
            'ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· Ø¯Ø§Øº/Ø³Ø±Ø¯ØŒ Ù…Ø³ÛŒØ± Ø­Ø±Ú©ØªÛŒ Ùˆ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù¾ÙˆØ´Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ Ù‡Ù†ÙˆØ² Ú©Ø§Ù…Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            execution_category,
            'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯',
            bool(sales_analysis.get('before_after_comparison')),
            'Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´ ÙØ¹Ù„ÛŒ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.',
            'Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙØ±ÙˆØ´ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'
        )
        add_item(
            execution_category,
            'ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ Ùˆ Ù¾Ø±Ø³ÙˆÙ†Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚',
            bool(behavior_analysis),
            'ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ±ØŒ ØªØ¹Ø§Ù…Ù„ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ù‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ Ø¯Ø±Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            execution_category,
            'Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ù‚Ø¯Ø§Ù… Ø¨Ø§ ROI Ùˆ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ',
            bool(action_plan.get('urgent')),
            '12 Ø§Ù‚Ø¯Ø§Ù… Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯ØªØŒ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª Ùˆ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª Ø¨Ø§ ROI Ù…Ø´Ø®Øµ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø±Ø¯.'
        )
        add_item(
            execution_category,
            'Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ KPI Ø¨Ø§ Ø§Ù‡Ø¯Ø§Ù Ùˆ Ù‡Ø´Ø¯Ø§Ø±',
            bool(kpi_dashboard.get('conversion_rate')),
            'Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ùâ€ŒÚ¯Ø°Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ø¯Ø±ØµØ¯ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ KPI Ù‡Ù†ÙˆØ² Ø¢Ù…Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            execution_category,
            'Ù¾ÛŒÙˆØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªÚ©Ù…ÛŒÙ„',
            bool(appendix),
            'Ù¾ÛŒÙˆØ³Øª Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ùˆ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¨Ø®Ø´ Ù¾ÛŒÙˆØ³Øª Ù‡Ù†ÙˆØ² Ø§Ø¶Ø§ÙÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            execution_category,
            'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø´ØªØ±Ø§Ú© Ùˆ Follow-up',
            bool(subscription_hook),
            'Hook Ø§Ø±ØªÙ‚Ø§ Ùˆ ØªÙˆØµÛŒÙ‡ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.',
            'Ø¨Ø®Ø´ Ø§Ø´ØªØ±Ø§Ú© Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù‡Ù†ÙˆØ² Ø¢Ù…Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )

        # 2) UI / UX Quality
        ui_category = add_category('Ú©ÛŒÙÛŒØª Ø¨ØµØ±ÛŒ Ùˆ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ', 'ğŸ¨')
        add_item(
            ui_category,
            'ÙÙˆÙ†Øª Ùˆ ØªØ§ÛŒÙ¾ÙˆÚ¯Ø±Ø§ÙÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ',
            True,
            'ÙÙˆÙ†Øª Vazirmatn Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø±Ø¹Ø§ÛŒØª Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'ÙÙˆÙ†Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            ui_category,
            'Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ù…ØªÙˆØ§Ø²Ù†',
            True,
            'Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†ÛŒ Ùˆ ØªØ¶Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø·Ø¨Ù‚ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø±Ù†Ø¯ Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯.'
        )
        add_item(
            ui_category,
            'Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ùˆ Ø§ÛŒÙ†ÙÙˆÚ¯Ø±Ø§ÙÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø´ÙØ§Ù',
            bool(sales_analysis.get('before_after_comparison')),
            'Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ù‚ÛŒØ§Ø³ÛŒ Ùˆ Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ KPI Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ø­Ø¶ÙˆØ± Ø¯Ø§Ø±Ù†Ø¯.',
            'Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÙ†Ø¯.'
        )
        add_item(
            ui_category,
            'Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ Ùˆ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯',
            bool(action_plan.get('urgent')),
            'Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù‚Ø¯Ø§Ù… Ùˆ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ KPI Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.',
            'Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ø¯Ø§Ø±Ø¯.'
        )
        add_item(
            ui_category,
            'Ù†Ø³Ø®Ù‡ Ú†Ø§Ù¾ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡',
            True,
            'Print CSS Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ø§Ù¾ ØªÙ…ÛŒØ² ÙØ¹Ø§Ù„ Ø§Ø³Øª.',
            'Ù†Ø³Ø®Ù‡ Ú†Ø§Ù¾ÛŒ Ù‡Ù†ÙˆØ² Ø¨Ù‡ÛŒÙ†Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            ui_category,
            'Ù¾Ø§ÙˆØ±Ù‚ÛŒ Ùˆ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ',
            True,
            'Ù¾Ø§ÙˆØ±Ù‚ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ Ùˆ Ù†Ø³Ø®Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.',
            'Ù¾Ø§ÙˆØ±Ù‚ÛŒ Ùˆ Ù†Ø³Ø®Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙØ¹Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )

        # 3) Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¬Ø±Ø§ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        executionability_category = add_category('Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¬Ø±Ø§ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§', 'ğŸ§ ')
        add_item(
            executionability_category,
            'Ù¾ÙˆØ´Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ ÙˆØ±ÙˆØ¯ÛŒ',
            data.get('completeness_score', 0) >= 0.5,
            f"Ø§Ù…ØªÛŒØ§Ø² ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ {data.get('completeness_score', 0) * 100:.0f}% Ø§Ø³Øª.",
            'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù‚Øµ Ø§Ø³ØªØ› ØªÙˆØµÛŒÙ‡ Ø¨Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ±/ÙØ±ÙˆØ´.'
        )
        add_item(
            executionability_category,
            'Ø§Ù†Ø·Ø¨Ø§Ù‚ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø¨Ø§Ø²Ø§Ø± Ø§ÛŒØ±Ø§Ù†',
            bool(estimated_roi.get('estimated_cost')),
            'Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ ROI Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…Ø­Ù„ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ù‡Ø²ÛŒÙ†Ù‡ Ø¯Ù‚ÛŒÙ‚ Ù‡Ù†ÙˆØ² ÙˆØ§Ø±Ø¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            executionability_category,
            'Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØ´ KPI Ùˆ Ù‡Ø´Ø¯Ø§Ø±',
            bool(kpi_dashboard.get('conversion_rate')),
            'Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù Ùˆ Ø±ÙˆÙ†Ø¯ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø± KPI ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ KPI Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹Ø±ÛŒÙ Ø¯Ø§Ø±Ø¯.'
        )
        add_item(
            executionability_category,
            'Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø§Ø±Ú©ØªÛŒÙ†Ú¯ Ø¨Ø§ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ',
            bool(action_plan.get('medium_term')),
            'Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª Ø¨Ø§ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ Ùˆ Ø§ÙˆÙ„ÙˆÛŒØª Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.',
            'Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø§Ø±Ú©ØªÛŒÙ†Ú¯ÛŒ Ø¨Ø§ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            executionability_category,
            'Ø¨ÙˆØ¯Ø¬Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ ROI Ù‚Ø§Ø¨Ù„ Ø³Ù†Ø¬Ø´',
            bool(action_plan.get('urgent')),
            'Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø§Ù‚Ø¯Ø§Ù… Ù‡Ø²ÛŒÙ†Ù‡ Ùˆ ROI Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ ROI Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÚ©Ù…ÛŒÙ„ Ø¯Ø§Ø±Ø¯.'
        )

        # 4) ØªÙ…Ø§ÛŒØ² Ùˆ Ø±Ù‚Ø§Ø¨Øª
        differentiation_category = add_category('ØªÙ…Ø§ÛŒØ² Ùˆ Ø±Ù‚Ø§Ø¨Øª', 'ğŸš€')
        add_item(
            differentiation_category,
            'Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ÛŒÚ¯Ø§Ù†',
            metadata.get('total_pages', 0) >= 100,
            'Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ùˆ Ú©Ø§Ù…Ù„ Ùˆ Ú†Ù†Ø¯Ø¨Ø±Ø§Ø¨Ø± Ù†Ø³Ø®Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª.',
            'ØªÙØ§ÙˆØª Ù…Ø´Ø®ØµÛŒ Ø¨Ø§ Ù†Ø³Ø®Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯ÛŒØ¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.'
        )
        add_item(
            differentiation_category,
            'Ø§Ù„Ú¯ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹Øª',
            bool(technical_analysis.get('zones_analysis')),
            'Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Benchmarks Ùˆ Heatmap ØµÙ†Ø¹ØªÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ø§Ø±Ø¬Ø§Ø¹ Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§ÛŒ ØµÙ†Ø¹Øª Ù‡Ù†ÙˆØ² Ø§Ø¶Ø§ÙÙ‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            differentiation_category,
            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡',
            metadata.get('ai_engine') == 'GPT-4o',
            'Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ù…ÙˆØªÙˆØ± GPT-4o Ùˆ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'Ù…ÙˆØªÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            differentiation_category,
            'CTA Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙ‚Ø§ÛŒ Ù¾Ù„Ù† Ùˆ Ø§Ø´ØªØ±Ø§Ú©',
            bool(subscription_hook),
            'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø±ØªÙ‚Ø§ Ø¨Ù‡ Ù¾Ù„Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø¯Ø± Ù¾Ø§ÛŒØ§Ù† Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.',
            'CTA Ø§Ø±ØªÙ‚Ø§ Ù‡Ù†ÙˆØ² Ø·Ø±Ø§Ø­ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )

        # 5) Ø¯Ø³ØªØ±Ø³ÛŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡
        access_category = add_category('Ø¯Ø³ØªØ±Ø³ÛŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡', 'ğŸŒ')
        add_item(
            access_category,
            'Ù†Ø³Ø®Ù‡ HTML Ùˆ PDF Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§',
            bool(metadata.get('total_pages')),
            'Ú¯Ø²Ø§Ø±Ø´ HTML Ùˆ PDF Ø¨Ø§ Ú©ÛŒÙÛŒØª Ùˆ Ú©Ø§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø³Øª.',
            'Ù†Ø³Ø®Ù‡ HTML/PDF Ù‡Ù†ÙˆØ² ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            access_category,
            'Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ø§Ø±Ø¬Ø§Ø¹Ø§Øª Ø¯Ø§Ø®Ù„ÛŒ ÙØ¹Ø§Ù„',
            True,
            'TOCØŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ùˆ CTAâ€ŒÙ‡Ø§ ØªØ³Øª Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.',
            'Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø§Ø±Ù†Ø¯.'
        )
        add_item(
            access_category,
            'Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡',
            True,
            'Executive Summary Ø¯Ù‡ ØµÙØ­Ù‡â€ŒØ§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø§Ø³Øª.',
            'Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ù‡Ù†ÙˆØ² ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        )
        add_item(
            access_category,
            'Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÛŒÙ…â€ŒÙ‡Ø§',
            True,
            'Ø¯Ø± Ø¨Ø®Ø´ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ùˆ CTA ØªÙˆØ¶ÛŒØ­ Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªÙˆØ³Ø· ØªÛŒÙ…â€ŒÙ‡Ø§ Ø¢Ù…Ø¯Ù‡ Ø§Ø³Øª.',
            'Ú¯Ø²Ø§Ø±Ø´ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø§Ø±Ø¯.'
        )

        for category in categories:
            total = len(category['items'])
            done = sum(1 for item in category['items'] if item['status'])
            category['total'] = total
            category['completed'] = done
            category['score'] = round((done / total) * 100) if total else 0

        summary = {
            'total': total_items,
            'completed': completed_items,
            'pending': max(total_items - completed_items, 0),
            'score': round((completed_items / total_items) * 100) if total_items else 0
        }

        return {
            'categories': categories,
            'summary': summary
        }
    
    def _generate_fallback_report(self, analysis) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ fallback Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        checklist = {
            'categories': [{
                'title': 'ÙˆØ¶Ø¹ÛŒØª Ú¯Ø²Ø§Ø±Ø´',
                'icon': 'âš ï¸',
                'items': [{
                    'label': 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯',
                    'status': False,
                    'note': 'Ø¯Ø± Ø­Ø§Ù„Øª fallback ÙÙ‚Ø· Ø®Ø·Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø«Ø¨Øª Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.'
                }],
                'total': 1,
                'completed': 0,
                'score': 0
            }],
            'summary': {
                'total': 1,
                'completed': 0,
                'pending': 1,
                'score': 0
            }
        }

        # ØªÙˆÙ„ÛŒØ¯ ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ø­Ø¯Ø§Ù‚Ù„ÛŒ Ø§Ù…Ø§ Ú©Ø§Ù…Ù„ (Ø¨Ø¯ÙˆÙ† Ú©Ù„ÛŒØ¯ error Ú©Ù‡ Ø¨Ø§Ø¹Ø« Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        store_name = getattr(analysis, 'store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
        analysis_data = analysis.get_analysis_data() if hasattr(analysis, 'get_analysis_data') else {}
        
        return {
            'fallback_report': 'available',
            'cover_page': {
                'store_name': store_name,
                'layout_score': 70,
                'note': 'Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ø­Ø§Ù„Øª fallback ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª'
            },
            'executive_summary': {
                'paragraphs': [
                    f'Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ {store_name} Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø§Ø³Øª.',
                    'Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø¯Ø± Ø³ÛŒØ³ØªÙ…ØŒ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.',
                    'Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.'
                ],
                'expected_roi': 'Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡',
                'payback_period': 'Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡'
            },
            'technical_analysis': {
                'entry_analysis': {
                    'description': 'ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø§Ø³Øª.',
                    'recommendations': ['Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯']
                },
                'zones_analysis': {
                    'hot_zones': [],
                    'cold_zones': []
                }
            },
            'sales_analysis': {
                'narrative': 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø§Ø³Øª.',
                'insights': []
            },
            'behavior_analysis': {
                'movement': {
                    'primary_path_usage': 'Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„',
                    'recommendation': 'Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'
                }
            },
            'action_plan': {
                'urgent': [],
                'medium_term': []
            },
            'kpi_dashboard': {
                'layout_score': 70,
                'traffic_score': 75,
                'design_score': 80,
                'sales_score': 72
            },
            'quality_checklist': checklist,
            'quality_summary': checklist['summary'],
            'metadata': {
                'generated_at': timezone.now().isoformat(),
                'version': '1.0.0-fallback',
                'report_type': 'premium_fallback',
                'ai_engine': 'Fallback System',
                'status': 'fallback',
                'note': 'Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± Ø­Ø§Ù„Øª fallback ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.'
            }
        }
    
    def generate_pdf_report(self, report_data: Dict) -> bytes:
        """ØªÙˆÙ„ÛŒØ¯ PDF Ø§Ø² Ú¯Ø²Ø§Ø±Ø´"""
        # TODO: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ PDF Ø¨Ø§ ReportLab
        pass
    
    def generate_html_report(self, report_data: Dict) -> str:
        """ØªÙˆÙ„ÛŒØ¯ HTML Ø§Ø² Ú¯Ø²Ø§Ø±Ø´"""
        # TODO: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ HTML template
        pass

