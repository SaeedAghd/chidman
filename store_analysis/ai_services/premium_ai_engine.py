#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import logging
import requests
from datetime import datetime
from typing import Dict, List, Any, Optional
from django.conf import settings
from django.utils import timezone
from .professional_report_generator import ProfessionalReportGenerator

logger = logging.getLogger(__name__)

class PremiumAIAnalysisEngine:
    """Ù…ÙˆØªÙˆØ± ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù¾Ù„Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ Ø¨Ø§ GPT-4.1"""
    
    def __init__(self, package_type: str = 'professional'):
        self.package_type = package_type
        self.gpt4_api_key = getattr(settings, 'OPENAI_API_KEY', '')
        self.gpt4_base_url = getattr(settings, 'OPENAI_BASE_URL', 'https://api.openai.com/v1')
        self.report_generator = ProfessionalReportGenerator()
        
    def analyze_store_premium(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ GPT-4.1 Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù¾Ù„Ù†"""
        try:
            logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ù¾Ù„Ù† {self.package_type}")
            
            if self.package_type == 'professional':
                return self._professional_analysis(store_data)
            elif self.package_type == 'enterprise':
                return self._enterprise_analysis(store_data)
            else:
                return self._basic_analysis(store_data)
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡: {e}")
            return self._fallback_analysis(store_data)
    
    def _professional_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ GPT-4.1"""
        analysis_prompts = {
            'current_condition': self._generate_current_condition_prompt(store_data),
            'sales_analysis': self._generate_sales_analysis_prompt(store_data),
            'customer_flow': self._generate_customer_flow_prompt(store_data),
            'design_analysis': self._generate_design_analysis_prompt(store_data),
            'layout_proposal': self._generate_layout_proposal_prompt(store_data),
            'financial_analysis': self._generate_financial_analysis_prompt(store_data)
        }
        
        results = {}
        for section, prompt in analysis_prompts.items():
            try:
                response = self._call_gpt4(prompt)
                results[section] = self._parse_gpt4_response(response)
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {section}: {e}")
                results[section] = self._get_fallback_analysis(section)
        
        return self._synthesize_professional_results(results, store_data)
    
    def _enterprise_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø§ GPT-4.1 + ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ"""
        # ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù¾Ø§ÛŒÙ‡
        professional_results = self._professional_analysis(store_data)
        
        # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ù„Ù† Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ
        enterprise_prompts = {
            'advanced_psychology': self._generate_psychology_analysis_prompt(store_data),
            'competitive_analysis': self._generate_competitive_analysis_prompt(store_data),
            'technology_recommendations': self._generate_technology_prompt(store_data),
            'sustainability_analysis': self._generate_sustainability_prompt(store_data)
        }
        
        enterprise_results = {}
        for section, prompt in enterprise_prompts.items():
            try:
                response = self._call_gpt4(prompt)
                enterprise_results[section] = self._parse_gpt4_response(response)
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ {section}: {e}")
                enterprise_results[section] = self._get_fallback_analysis(section)
        
        # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
        return self._synthesize_enterprise_results(professional_results, enterprise_results, store_data)
    
    def _call_gpt4(self, prompt: str, max_tokens: int = 4000) -> str:
        """ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ GPT-4.1 API"""
        if not self.gpt4_api_key:
            logger.warning("âš ï¸ Ú©Ù„ÛŒØ¯ API OpenAI Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
            return "ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ GPT-4.1 Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        
        try:
            headers = {
                'Authorization': f'Bearer {self.gpt4_api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-4-turbo-preview',  # GPT-4.1
                'messages': [
                    {
                        'role': 'system',
                        'content': 'Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ 20 Ø³Ø§Ù„ ØªØ¬Ø±Ø¨Ù‡ Ù‡Ø³ØªÛŒØ¯. Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¹Ù„Ù…ÛŒØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø§Ø² Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ù‡Ø±Ú¯Ø² Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù…Ø«Ù„ regardsØŒ SmallØŒ Kids_ClothingØŒ NeutralØŒ attractivenessØŒ DesignØŒ functionalityØŒ example Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒØ¯.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': max_tokens,
                'temperature': 0.7
            }
            
            response = requests.post(
                f'{self.gpt4_base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± API GPT-4: {response.status_code}")
                return "Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ GPT-4.1"
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ GPT-4: {e}")
            return "Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ GPT-4.1"
    
    def _generate_current_condition_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ"""
        return f"""
ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
- Ù†ÙˆØ¹: {store_data.get('store_type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù…ØªØ±Ø§Ú˜: {store_data.get('area', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
- Ø´Ù‡Ø±: {store_data.get('city', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ú©Ù†Ø§Ù†: {store_data.get('staff_count', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI)
2. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù
3. ÙˆØ¶Ø¹ÛŒØª Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ¹Ù„ÛŒ
4. ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ùˆ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ
5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†

Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ Ùˆ Ø¨Ø§ Ø§Ø¹Ø¯Ø§Ø¯ Ù…Ø´Ø®Øµ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
"""
    
    def _generate_sales_analysis_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´"""
        return f"""
ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´:
- ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡: {store_data.get('daily_sales', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: {store_data.get('daily_customers', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„Ø§Øª: {store_data.get('product_types', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø² ÙØ±ÙˆØ´ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯ ÙØ±ÙˆØ´
2. Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù‡Ù… ÙØ±ÙˆØ´
3. Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØµÙ„ÛŒ
4. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù ÙØ±ÙˆØ´
5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ ÙØ±ÙˆØ´

Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù†Ø§Ù‚Øµ Ø§Ø³ØªØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ø±Ø¨Ù‡ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
"""
    
    def _generate_customer_flow_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ± Ùˆ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ±Ø§ÙÛŒÚ©:
- ØªØ±Ø§ÙÛŒÚ© Ø±ÙˆØ²Ø§Ù†Ù‡: {store_data.get('daily_customers', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ø²Ù…Ø§Ù† Ù…Ø§Ù†Ø¯Ú¯Ø§Ø±ÛŒ: {store_data.get('dwell_time', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: {store_data.get('conversion_rate', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø² Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ Ù…Ø´ØªØ±ÛŒØ§Ù†
2. Ù†Ù‚Ø§Ø· ØªÙˆÙ‚Ù Ùˆ Ø¬Ø°Ø¨
3. ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ©
4. Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø¯Ø± Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ
5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ

Ø§Ú¯Ø± ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ ØªØ±Ø§ÙÛŒÚ© Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
"""
    
    def _generate_design_analysis_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ø·Ø±Ø§Ø­ÛŒ"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø·Ø±Ø§Ø­ÛŒ:
- Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù…ØªØ±Ø§Ú˜: {store_data.get('area', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
- Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ: {store_data.get('color_scheme', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ÛŒ Ø§Ø² Ø·Ø±Ø§Ø­ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. ØªØ­Ù„ÛŒÙ„ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ ØªØ£Ø«ÛŒØ± Ø±ÙˆØ§Ù†ÛŒ
2. ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ
3. ØªØ­Ù„ÛŒÙ„ Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†
4. ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ù†Ø¯ÛŒÙ†Ú¯ Ø¨ØµØ±ÛŒ
5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ø·Ø±Ø§Ø­ÛŒ

Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙˆÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯ Ùˆ Ø·Ø±Ø§Ø­ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
"""
    
    def _generate_layout_proposal_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù†"""
        return f"""
Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ¹Ù„ÛŒ:
- Ù¾Ù„Ø§Ù† ÙØ¹Ù„ÛŒ: {store_data.get('current_layout', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù…Ø´Ú©Ù„Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: {store_data.get('identified_issues', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¬Ø§Ù…Ø¹ Ú†ÛŒØ¯Ù…Ø§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. Ù¾Ù„Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
2. ØªØºÛŒÛŒØ±Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¯Ø± Ù‡Ø± Ù†Ø§Ø­ÛŒÙ‡
3. Ø§Ù‡Ø¯Ø§Ù Ù‡Ø± ØªØºÛŒÛŒØ±
4. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø«Ø± Ø¨Ø± ÙØ±ÙˆØ´
5. Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ ØªØºÛŒÛŒØ±Ø§Øª

Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ùˆ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ù…Ø´ØªØ±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ù‡ÛŒØ¯.
"""
    
    def _generate_financial_analysis_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø§Ù„ÛŒ:
- ÙØ±ÙˆØ´ ÙØ¹Ù„ÛŒ: {store_data.get('daily_sales', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ: {store_data.get('operational_costs', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
- Ø¨ÙˆØ¯Ø¬Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³: {store_data.get('available_budget', 'Ù†Ø§Ù…Ø´Ø®Øµ')}

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ø¬Ø§Ù…Ø¹ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª
2. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø´Ø¯ ÙØ±ÙˆØ´
3. Ù…Ø­Ø§Ø³Ø¨Ù‡ ROI
4. Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡
5. ØªØ­Ù„ÛŒÙ„ Ø±ÛŒØ³Ú© Ùˆ Ø³ÙˆØ¯

Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ù†Ø§Ù‚Øµ Ø§Ø³ØªØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØµÙ†Ø¹Øª ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.
"""
    
    def _generate_psychology_analysis_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ (Ù¾Ù„Ù† Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ)"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ù…Ø´ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÛŒÙ‚ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ù…Ø´ØªØ±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ø®Ø±ÛŒØ¯
2. ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ú¯ÛŒØ²Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯
3. ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ§Ù†Ø¹ Ø®Ø±ÛŒØ¯
4. ØªØ­Ù„ÛŒÙ„ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ ÙØ±ÙˆØ´
"""
    
    def _generate_competitive_analysis_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø§Ø¨ØªÛŒ (Ù¾Ù„Ù† Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ)"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø§Ø¨ØªÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø§Ø¨ØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
2. ØªØ­Ù„ÛŒÙ„ Ù…Ø²ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø±Ù‚Ø§Ø¨ØªÛŒ
3. ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø±Ù‚Ø¨Ø§
4. Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ØªÙ…Ø§ÛŒØ²
5. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø±Ù‚Ø§Ø¨ØªÛŒ
"""
    
    def _generate_technology_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ (Ù¾Ù„Ù† Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ)"""
        return f"""
Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ù„Ø·ÙØ§Ù‹ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
2. ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
3. Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡
4. Ø§ØªÙˆÙ…Ø§Ø³ÛŒÙˆÙ† ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§
5. ROI ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§
"""
    
    def _generate_sustainability_prompt(self, store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ (Ù¾Ù„Ù† Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ)"""
        return f"""
ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}:

Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯ Ø´Ø§Ù…Ù„:
1. ØªØ­Ù„ÛŒÙ„ Ù…ØµØ±Ù Ø§Ù†Ø±Ú˜ÛŒ
2. ØªØ­Ù„ÛŒÙ„ Ù¾Ø³Ù…Ø§Ù†Ø¯
3. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø³Ø¨Ø²
4. Ù…Ø²Ø§ÛŒØ§ÛŒ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
5. Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
"""
    
    def _parse_gpt4_response(self, response: str) -> Dict[str, Any]:
        """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® GPT-4"""
        try:
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø±Ø³ JSON
            if response.startswith('{') and response.endswith('}'):
                return json.loads(response)
            
            # Ø§Ú¯Ø± JSON Ù†ÛŒØ³ØªØŒ Ø³Ø§Ø®ØªØ§Ø±Ø¯Ù‡ÛŒ Ù…ØªÙ†
            return {
                'analysis_text': response,
                'confidence': 0.8,
                'source': 'gpt4',
                'timestamp': timezone.now().isoformat()
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ù¾Ø§Ø³Ø® GPT-4: {e}")
            return {
                'analysis_text': response,
                'confidence': 0.6,
                'source': 'gpt4_parsed',
                'timestamp': timezone.now().isoformat()
            }
    
    def _get_fallback_analysis(self, section: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        fallback_texts = {
            'current_condition': 'ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'sales_analysis': 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'customer_flow': 'ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'design_analysis': 'ØªØ­Ù„ÛŒÙ„ Ø·Ø±Ø§Ø­ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙˆÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'layout_proposal': 'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'financial_analysis': 'ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØµÙ†Ø¹Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.'
        }
        
        return {
            'analysis_text': fallback_texts.get(section, 'ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª.'),
            'confidence': 0.5,
            'source': 'fallback',
            'timestamp': timezone.now().isoformat()
        }
    
    def _synthesize_professional_results(self, results: Dict[str, Any], store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
        return {
            'package_type': 'professional',
            'analysis_sections': results,
            'overall_score': self._calculate_overall_score(results),
            'key_insights': self._extract_key_insights(results),
            'recommendations': self._generate_recommendations(results),
            'confidence_score': self._calculate_confidence(results),
            'generated_at': timezone.now().isoformat(),
            'store_data': store_data
        }
    
    def _synthesize_enterprise_results(self, professional_results: Dict[str, Any], enterprise_results: Dict[str, Any], store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ"""
        return {
            'package_type': 'enterprise',
            'professional_analysis': professional_results,
            'enterprise_additions': enterprise_results,
            'overall_score': self._calculate_overall_score({**professional_results['analysis_sections'], **enterprise_results}),
            'key_insights': self._extract_key_insights({**professional_results['analysis_sections'], **enterprise_results}),
            'recommendations': self._generate_recommendations({**professional_results['analysis_sections'], **enterprise_results}),
            'confidence_score': self._calculate_confidence({**professional_results['analysis_sections'], **enterprise_results}),
            'generated_at': timezone.now().isoformat(),
            'store_data': store_data
        }
    
    def _calculate_overall_score(self, results: Dict[str, Any]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ"""
        try:
            scores = []
            for section, data in results.items():
                if isinstance(data, dict) and 'confidence' in data:
                    scores.append(data['confidence'])
            
            return sum(scores) / len(scores) if scores else 0.5
        except:
            return 0.5
    
    def _extract_key_insights(self, results: Dict[str, Any]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ"""
        insights = []
        for section, data in results.items():
            if isinstance(data, dict) and 'analysis_text' in data:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² Ù…ØªÙ†
                text = data['analysis_text']
                if 'Ù†Ù‚Ø§Ø· Ù‚ÙˆØª' in text or 'Ù…Ø²ÛŒØª' in text:
                    insights.append(f"Ø¨ÛŒÙ†Ø´ Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² {section}: Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
                if 'Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù' in text or 'Ù…Ø´Ú©Ù„' in text:
                    insights.append(f"Ø¨ÛŒÙ†Ø´ Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø² {section}: Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯")
        
        return insights[:5]  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ø¨ÛŒÙ†Ø´
    
    def _generate_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recommendations = []
        for section, data in results.items():
            if isinstance(data, dict) and 'analysis_text' in data:
                text = data['analysis_text']
                if 'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯' in text or 'ØªÙˆØµÛŒÙ‡' in text:
                    recommendations.append(f"ØªÙˆØµÛŒÙ‡ Ø§Ø² {section}: Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯")
        
        return recommendations[:10]  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 ØªÙˆØµÛŒÙ‡
    
    def _calculate_confidence(self, results: Dict[str, Any]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ Ú©Ù„ÛŒ"""
        try:
            confidences = []
            for section, data in results.items():
                if isinstance(data, dict) and 'confidence' in data:
                    confidences.append(data['confidence'])
            
            return sum(confidences) / len(confidences) if confidences else 0.5
        except:
            return 0.5
    
    def _basic_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡ (Ù¾Ù„Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†)"""
        return {
            'package_type': 'basic',
            'analysis_text': 'ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
            'confidence': 0.3,
            'source': 'local',
            'generated_at': timezone.now().isoformat(),
            'store_data': store_data
        }
    
    def _fallback_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        return {
            'package_type': self.package_type,
            'analysis_text': 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.',
            'confidence': 0.1,
            'source': 'error',
            'generated_at': timezone.now().isoformat(),
            'store_data': store_data
        }
