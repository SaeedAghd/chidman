#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from django.conf import settings
from django.utils import timezone
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import os

logger = logging.getLogger(__name__)

class ProfessionalReportGenerator:
    """ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¬Ù‡Ø§Ù†ÛŒ"""
    
    def __init__(self):
        self.styles = getSampleStyleSheet()
        self._setup_persian_fonts()
        self._setup_custom_styles()
    
    def _setup_persian_fonts(self):
        """ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ"""
        try:
            # Ø«Ø¨Øª ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ
            font_path = os.path.join(settings.STATIC_ROOT, 'fonts', 'Vazir.ttf')
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('Vazir', font_path))
                logger.info("âœ… ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø«Ø¨Øª Ø´Ø¯")
            else:
                logger.warning("âš ï¸ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø«Ø¨Øª ÙÙˆÙ†Øª: {e}")
    
    def _setup_custom_styles(self):
        """ØªÙ†Ø¸ÛŒÙ… Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ"""
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
        self.styles.add(ParagraphStyle(
            name='PersianTitle',
            parent=self.styles['Title'],
            fontName='Vazir',
            fontSize=24,
            spaceAfter=30,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.darkblue
        ))
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø²ÛŒØ±Ø¹Ù†ÙˆØ§Ù†
        self.styles.add(ParagraphStyle(
            name='PersianHeading',
            parent=self.styles['Heading1'],
            fontName='Vazir',
            fontSize=16,
            spaceAfter=12,
            alignment=2,
            textColor=colors.darkgreen
        ))
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
        self.styles.add(ParagraphStyle(
            name='PersianNormal',
            parent=self.styles['Normal'],
            fontName='Vazir',
            fontSize=12,
            spaceAfter=6,
            alignment=2,
            wordWrap='CJK'
        ))
    
    def validate_input_completeness(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù…Ù„ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ"""
        missing = []
        confidence_scores = {}
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´
        if not data.get("sales_file") and not data.get("sales_data"):
            missing.append("ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´ (csv/xlsx)")
            confidence_scores['sales'] = 0.3
        else:
            confidence_scores['sales'] = 0.9
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ù„Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if not data.get("store_plan") and not data.get("layout_image"):
            missing.append("Ù†Ù‚Ø´Ù‡ ÛŒØ§ Ù¾Ù„Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡")
            confidence_scores['layout'] = 0.4
        else:
            confidence_scores['layout'] = 0.8
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ù…Ø´ØªØ±ÛŒ
        if not data.get("customer_video") and not data.get("traffic_data"):
            missing.append("ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ")
            confidence_scores['traffic'] = 0.2
        else:
            confidence_scores['traffic'] = 0.9
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªØµØ§ÙˆÛŒØ± ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if not data.get("store_photos") or len(data.get("store_photos", [])) < 3:
            missing.append("ØªØµØ§ÙˆÛŒØ± Ø¹Ù…ÙˆÙ…ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ (Ø­Ø¯Ø§Ù‚Ù„ 3 ØªØµÙˆÛŒØ±)")
            confidence_scores['visuals'] = 0.5
        else:
            confidence_scores['visuals'] = 0.8
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ Ú©Ù„ÛŒ
        overall_confidence = sum(confidence_scores.values()) / len(confidence_scores)
        
        validation_result = {
            'missing_data': missing,
            'confidence_scores': confidence_scores,
            'overall_confidence': overall_confidence,
            'validation_message': self._generate_validation_message(missing, overall_confidence)
        }
        
        return validation_result
    
    def _generate_validation_message(self, missing: List[str], confidence: float) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ"""
        if not missing:
            return "âœ… ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª."
        
        confidence_percent = int(confidence * 100)
        missing_text = "\n- ".join(missing)
        
        return f"""âš ï¸ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø§Ø¹ØªÙ…Ø§Ø¯: {confidence_percent}%).
Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯:
- {missing_text}

ØªÙˆØµÛŒÙ‡: Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯."""
    
    def generate_executive_summary(self, analysis_data: Dict[str, Any], store_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ"""
        store_name = store_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
        store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
        
        # Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ ÙØ¹Ù„ÛŒ
        current_kpis = analysis_data.get('current_kpis', {})
        
        # Ø§Ù‡Ø¯Ø§Ù Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
        improvement_goals = analysis_data.get('improvement_goals', {})
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø«Ø±Ø§Øª
        predicted_effects = analysis_data.get('predicted_effects', {})
        
        summary = f"""
<h2>Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ - Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù† {store_name}</h2>

<h3>ğŸ“Š Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ ÙØ¹Ù„ÛŒ:</h3>
â€¢ ØªØ±Ø§ÙÛŒÚ© Ø±ÙˆØ²Ø§Ù†Ù‡: {current_kpis.get('daily_traffic', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù†ÙØ±
â€¢ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: {current_kpis.get('conversion_rate', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ ÙØ±ÙˆØ´ Ø¯Ø± Ù…ØªØ± Ù…Ø±Ø¨Ø¹: {current_kpis.get('sales_per_sqm', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†
â€¢ Ø²Ù…Ø§Ù† Ù…Ø§Ù†Ø¯Ú¯Ø§Ø±ÛŒ Ù…Ø´ØªØ±ÛŒ: {current_kpis.get('dwell_time', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø¯Ù‚ÛŒÙ‚Ù‡
â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø§Ù‚Ù„Ø§Ù… Ø³Ø¨Ø¯ Ø®Ø±ÛŒØ¯: {current_kpis.get('basket_items', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù‚Ù„Ù…

<h3>ğŸ¯ Ø§Ù‡Ø¯Ø§Ù Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:</h3>
â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: {improvement_goals.get('sales_increase', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: {improvement_goals.get('conversion_improvement', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ú©Ø§Ù‡Ø´ ÙØ¶Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡: {improvement_goals.get('space_optimization', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ø¨ØµØ±ÛŒ: {improvement_goals.get('visual_improvement', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%

<h3>ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø«Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­Ø§Øª:</h3>
â€¢ Ø±Ø´Ø¯ ÙØ±ÙˆØ´: +{predicted_effects.get('sales_growth', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: +{predicted_effects.get('conversion_growth', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ ROI: {predicted_effects.get('roi', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: {predicted_effects.get('payback_period', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…Ø§Ù‡
"""
        
        return summary
    
    def generate_current_condition_analysis(self, analysis_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ"""
        current_condition = analysis_data.get('current_condition', {})
        
        analysis = f"""
<h2>ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡</h2>

<h3>ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ø¨ØµØ±ÛŒ Ù¾Ù„Ø§Ù† ÙØ¹Ù„ÛŒ:</h3>
{current_condition.get('layout_summary', 'ØªØ­Ù„ÛŒÙ„ Ù¾Ù„Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ”¥ Heatmap Ø­Ø±Ú©ØªÛŒ:</h3>
{current_condition.get('traffic_heatmap', 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ“Š Ø¬Ø¯Ø§ÙˆÙ„ Ø¹Ø¯Ø¯ÛŒ:</h3>
<table>
<tr><th>Ø´Ø§Ø®Øµ</th><th>Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ</th><th>ÙˆØ¶Ø¹ÛŒØª</th></tr>
<tr><td>ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡</td><td>{current_condition.get('daily_sales', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>{self._get_status_emoji(current_condition.get('sales_status', 'medium'))}</td></tr>
<tr><td>Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„</td><td>{current_condition.get('conversion_rate', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td><td>{self._get_status_emoji(current_condition.get('conversion_status', 'medium'))}</td></tr>
<tr><td>ÙØ¶Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡</td><td>{current_condition.get('unused_space', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>{self._get_status_emoji(current_condition.get('space_status', 'medium'))}</td></tr>
<tr><td>ØªØ±Ø§ÙÛŒÚ© Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ</td><td>{current_condition.get('main_traffic', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td><td>{self._get_status_emoji(current_condition.get('traffic_status', 'medium'))}</td></tr>
<tr><td>Ù†ÙˆØ± Ø·Ø¨ÛŒØ¹ÛŒ</td><td>{current_condition.get('natural_light', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>{self._get_status_emoji(current_condition.get('light_status', 'medium'))}</td></tr>
</table>
"""
        
        return analysis
    
    def _get_status_emoji(self, status: str) -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§ÛŒÙ…ÙˆØ¬ÛŒ ÙˆØ¶Ø¹ÛŒØª"""
        status_map = {
            'excellent': 'ğŸŸ¢ Ø¹Ø§Ù„ÛŒ',
            'good': 'ğŸŸ¢ Ø®ÙˆØ¨',
            'medium': 'ğŸŸ¡ Ù…ØªÙˆØ³Ø·',
            'poor': 'ğŸ”´ Ø¶Ø¹ÛŒÙ',
            'critical': 'ğŸ”´ Ø¨Ø­Ø±Ø§Ù†ÛŒ'
        }
        return status_map.get(status, 'ğŸŸ¡ Ù†Ø§Ù…Ø´Ø®Øµ')
    
    def generate_sales_analysis(self, analysis_data: Dict[str, Any], validation: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´"""
        sales_data = analysis_data.get('sales_analysis', {})
        
        analysis = f"""
<h2>ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´</h2>

{validation.get('validation_message', '')}

<h3>ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± ØªØ±Ù†Ø¯ ÙØ±ÙˆØ´:</h3>
{sales_data.get('sales_trend', 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯ ÙØ±ÙˆØ´ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ“Š Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª:</h3>
{sales_data.get('product_categories', 'ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:</h3>
â€¢ Ø§Ù„Ú¯ÙˆÛŒ ÙØµÙ„ÛŒ: {sales_data.get('seasonal_pattern', 'Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„...')}
â€¢ Ù¾Ø±ÙØ±ÙˆØ´â€ŒØªØ±ÛŒÙ† Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§: {sales_data.get('top_categories', 'Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„...')}
â€¢ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù ÙØ±ÙˆØ´: {sales_data.get('weak_points', 'Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„...')}
"""
        
        return analysis
    
    def generate_customer_flow_analysis(self, analysis_data: Dict[str, Any], validation: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ"""
        flow_data = analysis_data.get('customer_flow', {})
        
        analysis = f"""
<h2>Ù…Ø³ÛŒØ± Ùˆ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù†</h2>

{validation.get('validation_message', '')}

<h3>ğŸ—ºï¸ Heatmap Ø±ÙØªâ€ŒÙˆØ¢Ù…Ø¯:</h3>
{flow_data.get('traffic_heatmap', 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>â¸ï¸ Ù†Ù‚Ø§Ø· ØªÙˆÙ‚Ù:</h3>
{flow_data.get('stop_points', 'ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· ØªÙˆÙ‚Ù Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ“‹ Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ:</h3>
<table>
<tr><th>Ù…Ø³ÛŒØ± Ù…Ø¹Ù…ÙˆÙ„ Ù…Ø´ØªØ±ÛŒ</th><th>Ø¯Ø±ØµØ¯ ØªØ±Ø¯Ø¯</th><th>Ø²Ù…Ø§Ù† ØªÙˆÙ‚Ù Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†</th></tr>
<tr><td>ÙˆØ±ÙˆØ¯ÛŒ ØªØ§ ØªØ®ÙÛŒÙâ€ŒÙ‡Ø§</td><td>{flow_data.get('entrance_to_discount', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td><td>{flow_data.get('discount_dwell_time', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø«Ø§Ù†ÛŒÙ‡</td></tr>
<tr><td>Ù‚ÙØ³Ù‡ Ø¬Ø¯ÛŒØ¯Ù‡Ø§</td><td>{flow_data.get('new_items_traffic', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td><td>{flow_data.get('new_items_dwell_time', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø«Ø§Ù†ÛŒÙ‡</td></tr>
<tr><td>ØµÙ†Ø¯ÙˆÙ‚ Ù¾Ø±Ø¯Ø§Ø®Øª</td><td>{flow_data.get('checkout_traffic', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td><td>{flow_data.get('checkout_time', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø«Ø§Ù†ÛŒÙ‡</td></tr>
</table>
"""
        
        return analysis
    
    def generate_design_analysis(self, analysis_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†"""
        design_data = analysis_data.get('design_analysis', {})
        
        analysis = f"""
<h2>Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø¯Ú©ÙˆØ±Ø§Ø³ÛŒÙˆÙ†</h2>

<h3>ğŸ¨ ØªØ±Ú©ÛŒØ¨ Ø±Ù†Ú¯ Ø¨Ø±Ù†Ø¯:</h3>
{design_data.get('color_scheme', 'ØªØ­Ù„ÛŒÙ„ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ’¡ Ù†ÙˆØ¹ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ:</h3>
{design_data.get('lighting_analysis', 'ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}

<h3>ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ:</h3>
â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª Ø¯Ø± Ø¨Ø®Ø´ ØªØ®ÙÛŒÙâ€ŒÙ‡Ø§
â€¢ Ù†ÙˆØ± Ù…ØªÙ…Ø±Ú©Ø² Ø¨Ø± Ù†Ù‚Ø§Ø· VIP
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ù…Ø³ÛŒØ± Ø±ÙˆØ§Ù†ÛŒ Ù…Ø´ØªØ±ÛŒ

<h3>ğŸ¯ ØªØ£Ø«ÛŒØ± Ø±ÙˆØ§Ù†ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§:</h3>
{design_data.get('color_psychology', 'ØªØ­Ù„ÛŒÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...')}
"""
        
        return analysis
    
    def generate_layout_proposal(self, analysis_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù†"""
        layout_data = analysis_data.get('layout_proposal', {})
        
        analysis = f"""
<h2>Ù¾Ù„Ø§Ù† Ø¬Ø¯ÛŒØ¯ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù†</h2>

<h3>ğŸ”„ ØªØµÙˆÛŒØ± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯:</h3>
{layout_data.get('before_after', 'ØªØµØ§ÙˆÛŒØ± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯...')}

<h3>ğŸ“‹ Ø¬Ø¯ÙˆÙ„ ØªØºÛŒÛŒØ±Ø§Øª:</h3>
<table>
<tr><th>Ù†Ø§Ø­ÛŒÙ‡</th><th>ØªØºÛŒÛŒØ± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ</th><th>Ù‡Ø¯Ù</th><th>Ø§Ø«Ø± Ø¨Ø± ÙØ±ÙˆØ´</th></tr>
<tr><td>ÙˆØ±ÙˆØ¯ÛŒ</td><td>{layout_data.get('entrance_change', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>Ú©Ø§Ù‡Ø´ ØªØ±Ø§ÙÛŒÚ© Ø³Ø±Ø¯</td><td>+{layout_data.get('entrance_effect', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td></tr>
<tr><td>Ù‚ÙØ³Ù‡ Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ</td><td>{layout_data.get('beverage_change', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>Ø§ÙØ²Ø§ÛŒØ´ Ø¯ÛŒØ¯</td><td>+{layout_data.get('beverage_effect', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td></tr>
<tr><td>Ø¨Ø®Ø´ ØªØ®ÙÛŒÙâ€ŒÙ‡Ø§</td><td>{layout_data.get('discount_change', 'Ù†Ø§Ù…Ø´Ø®Øµ')}</td><td>Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø°Ø¨</td><td>+{layout_data.get('discount_effect', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%</td></tr>
</table>
"""
        
        return analysis
    
    def generate_financial_analysis(self, analysis_data: Dict[str, Any], validation: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI"""
        financial_data = analysis_data.get('financial_analysis', {})
        
        analysis = f"""
<h2>ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI</h2>

{validation.get('validation_message', '')}

<h3>ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­Ø§Øª:</h3>
â€¢ Ù‡Ø²ÛŒÙ†Ù‡ ÙÙˆØ±ÛŒ: {financial_data.get('immediate_cost', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†
â€¢ Ù‡Ø²ÛŒÙ†Ù‡ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª: {financial_data.get('medium_cost', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†
â€¢ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª: {financial_data.get('long_cost', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†
â€¢ Ú©Ù„ Ù‡Ø²ÛŒÙ†Ù‡: {financial_data.get('total_cost', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†

<h3>ğŸ“ˆ Ø±Ø´Ø¯ ÙØ±ÙˆØ´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡:</h3>
â€¢ Ù…Ø§Ù‡ Ø§ÙˆÙ„: +{financial_data.get('month1_growth', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ù…Ø§Ù‡ Ø³ÙˆÙ…: +{financial_data.get('month3_growth', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ù…Ø§Ù‡ Ø´Ø´Ù…: +{financial_data.get('month6_growth', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%

<h3>ğŸ”„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡:</h3>
â€¢ ROI: {financial_data.get('roi', 'Ù†Ø§Ù…Ø´Ø®Øµ')}%
â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: {financial_data.get('payback_period', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…Ø§Ù‡
â€¢ NPV: {financial_data.get('npv', 'Ù†Ø§Ù…Ø´Ø®Øµ')} ØªÙˆÙ…Ø§Ù†

<h3>ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø´Ø¯ Ø¯Ø±Ø¢Ù…Ø¯:</h3>
{financial_data.get('revenue_chart', 'Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯...')}
"""
        
        return analysis
    
    def generate_execution_plan(self, analysis_data: Dict[str, Any]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ"""
        execution_data = analysis_data.get('execution_plan', {})
        
        plan = f"""
<h2>Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ùˆ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…</h2>

<h3>âš¡ ÙÙˆØ±ÛŒ (Û°â€“Û³ Ù…Ø§Ù‡):</h3>
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ÙˆÛŒØªØ±ÛŒÙ†
â€¢ Ù†ØµØ¨ ØªØ§Ø¨Ù„Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§
â€¢ Ø§ØµÙ„Ø§Ø­ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ

<h3>ğŸ”„ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª (Û³â€“Û¹ Ù…Ø§Ù‡):</h3>
â€¢ Ø§ØµÙ„Ø§Ø­ Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ø§Ø±ÛŒ
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… ØµÙâ€ŒØ¨Ù†Ø¯ÛŒ
â€¢ Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ

<h3>ğŸ—ï¸ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (Û¹â€“Û±Û¸ Ù…Ø§Ù‡):</h3>
â€¢ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ ÙˆØ±ÙˆØ¯ÛŒ
â€¢ Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ ÙØ¶Ø§ÛŒ ÙØ±ÙˆØ´

<h3>âš ï¸ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…:</h3>
â€¢ Ø¯Ø± ØµÙˆØ±Øª Ø§Ø±Ø³Ø§Ù„ ØªØµØ§ÙˆÛŒØ± Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø§Ø² Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù†Ø³Ø®Ù‡Ù” Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡Ù” Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„â€ŒØªØ±ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ø±Ø¯.
â€¢ ØªÙ…Ø§Ù… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ø·Ø±Ø§Ø­ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.
â€¢ Ø§Ø¬Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù†Ø¸Ø§Ø±Øª Ù…ØªØ®ØµØµ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.
"""
        
        return plan
    
    def generate_complete_report(self, store_data: Dict[str, Any], analysis_data: Dict[str, Any], output_file: str) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„"""
        try:
            # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            validation = self.validate_input_completeness(store_data)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø³Ù†Ø¯ PDF
            doc = SimpleDocTemplate(output_file, pagesize=(8.5*inch, 11*inch))
            story = []
            
            # ØµÙØ­Ù‡ 1: Ø¬Ù„Ø¯ Ùˆ Ù…Ø´Ø®ØµØ§Øª
            story.append(Paragraph("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡", self.styles['PersianTitle']))
            story.append(Spacer(1, 20))
            
            # Ù…Ø´Ø®ØµØ§Øª Ù…Ø´ØªØ±ÛŒ
            customer_info = f"""
<h3>Ù…Ø´Ø®ØµØ§Øª Ù…Ø´ØªØ±ÛŒ:</h3>
â€¢ Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
â€¢ Ø´Ù‡Ø±: {store_data.get('city', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
â€¢ Ù…ØªØ±Ø§Ú˜: {store_data.get('area', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
â€¢ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
â€¢ ØªØ§Ø±ÛŒØ® Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {datetime.now().strftime('%Y/%m/%d')}
â€¢ Ù†Ø§Ù… ØªØ­Ù„ÛŒÙ„Ú¯Ø±: AI Retail Analyst v2 â€“ GPT-4.1 Engine
â€¢ Ø¯Ø±Ø¬Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø¯Ù„: {int(validation['overall_confidence'] * 100)}%
"""
            story.append(Paragraph(customer_info, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 2: Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
            executive_summary = self.generate_executive_summary(analysis_data, store_data)
            story.append(Paragraph(executive_summary, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 3: ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ
            current_condition = self.generate_current_condition_analysis(analysis_data)
            story.append(Paragraph(current_condition, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 4: ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´
            sales_analysis = self.generate_sales_analysis(analysis_data, validation)
            story.append(Paragraph(sales_analysis, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 5: Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒ
            customer_flow = self.generate_customer_flow_analysis(analysis_data, validation)
            story.append(Paragraph(customer_flow, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 6: Ø·Ø±Ø§Ø­ÛŒ
            design_analysis = self.generate_design_analysis(analysis_data)
            story.append(Paragraph(design_analysis, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 7: Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù†
            layout_proposal = self.generate_layout_proposal(analysis_data)
            story.append(Paragraph(layout_proposal, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 8: ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ
            financial_analysis = self.generate_financial_analysis(analysis_data, validation)
            story.append(Paragraph(financial_analysis, self.styles['PersianNormal']))
            story.append(PageBreak())
            
            # ØµÙØ­Ù‡ 9: Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
            execution_plan = self.generate_execution_plan(analysis_data)
            story.append(Paragraph(execution_plan, self.styles['PersianNormal']))
            
            # Ø³Ø§Ø®Øª PDF
            doc.build(story)
            
            logger.info(f"âœ… Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´: {e}")
            raise e
