"""
Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ØªØµØ§ÙˆÛŒØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡
Advanced Intelligent Image Analysis System
"""

import cv2
import numpy as np
import base64
import io
from PIL import Image, ImageEnhance, ImageFilter
import json
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import requests
from django.conf import settings

logger = logging.getLogger(__name__)

@dataclass
class ImageAnalysisResult:
    """Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ±"""
    store_type_confidence: float
    size_estimation: Dict[str, Any]
    layout_analysis: Dict[str, Any]
    color_analysis: Dict[str, Any]
    object_detection: List[Dict[str, Any]]
    consistency_score: float
    recommendations: List[str]
    quality_score: float
    professional_grade: bool

class AdvancedImageAnalyzer:
    """ØªØ­Ù„ÛŒÙ„Ú¯Ø± ØªØµØ§ÙˆÛŒØ± Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ AI"""
    
    def __init__(self):
        self.liara_ai_service = None
        self._init_liara_ai()
        
    def _init_liara_ai(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ Chidmano1 AI"""
        try:
            from .liara_ai_service import LiaraAIService
            self.liara_ai_service = LiaraAIService()
        except Exception as e:
            logger.warning(f"Chidmano1 AI service not available: {e}")
    
    def analyze_store_images(self, images: List[str], store_info: Dict[str, Any]) -> ImageAnalysisResult:
        """
        ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ØªØµØ§ÙˆÛŒØ± ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ AI Ù¾ÛŒØ´Ø±ÙØªÙ‡
        
        Args:
            images: Ù„ÛŒØ³Øª ØªØµØ§ÙˆÛŒØ± base64
            store_info: Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
            
        Returns:
            ImageAnalysisResult: Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„
        """
        try:
            # 1. ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ØªØµØ§ÙˆÛŒØ±
            basic_analysis = self._basic_image_analysis(images)
            
            # 2. ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ AI Ù¾ÛŒØ´Ø±ÙØªÙ‡
            ai_analysis = self._advanced_ai_analysis(images, store_info)
            
            # 3. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ùˆ ØªØ·Ø¨ÛŒÙ‚
            consistency_analysis = self._consistency_check(basic_analysis, ai_analysis, store_info)
            
            # 4. ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
            recommendations = self._generate_professional_recommendations(
                basic_analysis, ai_analysis, consistency_analysis, store_info
            )
            
            # 5. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
            overall_score = self._calculate_overall_score(
                basic_analysis, ai_analysis, consistency_analysis
            )
            
            return ImageAnalysisResult(
                store_type_confidence=ai_analysis.get('store_type_confidence', 0.0),
                size_estimation=basic_analysis.get('size_estimation', {}),
                layout_analysis=basic_analysis.get('layout_analysis', {}),
                color_analysis=basic_analysis.get('color_analysis', {}),
                object_detection=basic_analysis.get('object_detection', []),
                consistency_score=consistency_analysis.get('score', 0.0),
                recommendations=recommendations,
                quality_score=basic_analysis.get('quality_score', 0.0),
                professional_grade=overall_score > 0.8
            )
            
        except Exception as e:
            logger.error(f"Error in advanced image analysis: {e}")
            return self._create_fallback_result()
    
    def _basic_image_analysis(self, images: List[str]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ OpenCV"""
        results = {
            'size_estimation': {},
            'layout_analysis': {},
            'color_analysis': {},
            'object_detection': [],
            'quality_score': 0.0
        }
        
        try:
            for i, img_base64 in enumerate(images):
                # ØªØ¨Ø¯ÛŒÙ„ base64 Ø¨Ù‡ ØªØµÙˆÛŒØ±
                img = self._base64_to_image(img_base64)
                if img is None:
                    continue
                
                # ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¯Ø§Ø²Ù‡
                size_analysis = self._analyze_image_size(img, i)
                results['size_estimation'][f'image_{i}'] = size_analysis
                
                # ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†
                layout_analysis = self._analyze_layout(img, i)
                results['layout_analysis'][f'image_{i}'] = layout_analysis
                
                # ØªØ­Ù„ÛŒÙ„ Ø±Ù†Ú¯
                color_analysis = self._analyze_colors(img, i)
                results['color_analysis'][f'image_{i}'] = color_analysis
                
                # ØªØ´Ø®ÛŒØµ Ø§Ø´ÛŒØ§Ø¡
                objects = self._detect_objects(img, i)
                results['object_detection'].extend(objects)
                
                # Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª
                quality = self._calculate_image_quality(img)
                results['quality_score'] = max(results['quality_score'], quality)
            
            return results
            
        except Exception as e:
            logger.error(f"Error in basic image analysis: {e}")
            return results
    
    def _advanced_ai_analysis(self, images: List[str], store_info: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ AI"""
        if not self.liara_ai_service:
            return self._fallback_ai_analysis(store_info)
        
        try:
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ prompt Ø¨Ø±Ø§ÛŒ AI
            prompt = self._create_advanced_analysis_prompt(images, store_info)
            
            # Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Chidmano1 AI
            response = self.liara_ai_service.analyze_store_images(
                images=images,
                store_info=store_info,
                analysis_type='comprehensive'
            )
            
            if response and response.get('status') == 'success':
                return response.get('analysis', {})
            else:
                return self._fallback_ai_analysis(store_info)
                
        except Exception as e:
            logger.error(f"Error in advanced AI analysis: {e}")
            return self._fallback_ai_analysis(store_info)
    
    def _consistency_check(self, basic_analysis: Dict, ai_analysis: Dict, store_info: Dict) -> Dict[str, Any]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒÙ† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±"""
        consistency_score = 0.0
        inconsistencies = []
        
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            user_store_type = store_info.get('store_type', '').lower()
            ai_store_type = ai_analysis.get('detected_store_type', '').lower()
            
            if user_store_type and ai_store_type:
                if user_store_type in ai_store_type or ai_store_type in user_store_type:
                    consistency_score += 0.3
                else:
                    inconsistencies.append(f"Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: Ú©Ø§Ø±Ø¨Ø± '{user_store_type}' Ø§Ù…Ø§ AI ØªØ´Ø®ÛŒØµ '{ai_store_type}'")
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            user_size = store_info.get('store_size', 0)
            estimated_size = basic_analysis.get('size_estimation', {}).get('total_estimated_size', 0)
            
            if user_size and estimated_size:
                size_diff = abs(user_size - estimated_size) / max(user_size, estimated_size)
                if size_diff < 0.3:  # Ø§Ø®ØªÙ„Ø§Ù Ú©Ù…ØªØ± Ø§Ø² 30%
                    consistency_score += 0.3
                else:
                    inconsistencies.append(f"Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: Ú©Ø§Ø±Ø¨Ø± {user_size}mÂ² Ø§Ù…Ø§ ØªØ®Ù…ÛŒÙ† {estimated_size}mÂ²")
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª ØªØµØ§ÙˆÛŒØ±
            quality_score = basic_analysis.get('quality_score', 0)
            if quality_score > 0.7:
                consistency_score += 0.2
            elif quality_score < 0.4:
                inconsistencies.append("Ú©ÛŒÙÛŒØª ØªØµØ§ÙˆÛŒØ± Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ØªÙ†ÙˆØ¹ ØªØµØ§ÙˆÛŒØ±
            num_images = len(basic_analysis.get('size_estimation', {}))
            if num_images >= 3:
                consistency_score += 0.2
            else:
                inconsistencies.append("ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª (Ø­Ø¯Ø§Ù‚Ù„ 3 ØªØµÙˆÛŒØ±)")
            
            return {
                'score': min(consistency_score, 1.0),
                'inconsistencies': inconsistencies,
                'recommendations': self._generate_consistency_recommendations(inconsistencies)
            }
            
        except Exception as e:
            logger.error(f"Error in consistency check: {e}")
            return {'score': 0.0, 'inconsistencies': [], 'recommendations': []}
    
    def _generate_professional_recommendations(self, basic_analysis: Dict, ai_analysis: Dict, 
                                             consistency_analysis: Dict, store_info: Dict) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
        recommendations = []
        
        try:
            # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ
            if consistency_analysis.get('score', 0) < 0.7:
                recommendations.extend([
                    "ğŸ“¸ ØªØµØ§ÙˆÛŒØ± Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø² Ø²ÙˆØ§ÛŒØ§ÛŒ Ù…Ø®ØªÙ„Ù ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯",
                    "ğŸ¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ ØªØµØ§ÙˆÛŒØ± Ù†Ù…Ø§ÛŒØ§Ù†Ú¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡Ø³ØªÙ†Ø¯",
                    "ğŸ“ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ù‚ÛŒÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø«Ø¨Øª Ú©Ù†ÛŒØ¯"
                ])
            
            # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©ÛŒÙÛŒØª ØªØµØ§ÙˆÛŒØ±
            quality_score = basic_analysis.get('quality_score', 0)
            if quality_score < 0.6:
                recommendations.extend([
                    "ğŸ“· Ø§Ø² Ù†ÙˆØ± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø§Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
                    "ğŸ” ØªØµØ§ÙˆÛŒØ± Ø±Ø§ Ø¨Ø§ ÙˆØ¶ÙˆØ­ Ø¨Ø§Ù„Ø§ ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯",
                    "ğŸ“ ØªØµØ§ÙˆÛŒØ± Ø±Ø§ Ø§Ø² Ø²ÙˆØ§ÛŒØ§ÛŒ Ù…Ø®ØªÙ„Ù Ùˆ Ú©Ø§Ù…Ù„ Ø¨Ú¯ÛŒØ±ÛŒØ¯"
                ])
            
            # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            store_type = store_info.get('store_type', '').lower()
            if 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡' in store_type or 'shop' in store_type:
                recommendations.extend([
                    "ğŸª Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯",
                    "ğŸ’¡ Ø§Ø² Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
                    "ğŸ¨ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ùˆ Ø¬Ø°Ø§Ø¨ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯"
                ])
            elif 'Ø±Ø³ØªÙˆØ±Ø§Ù†' in store_type or 'restaurant' in store_type:
                recommendations.extend([
                    "ğŸ½ï¸ Ù…ÛŒØ²Ù‡Ø§ Ùˆ ØµÙ†Ø¯Ù„ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ù†Ø¸Ù… Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ù†ÛŒØ¯",
                    "ğŸŒ¿ Ø§Ø² Ú¯ÛŒØ§Ù‡Ø§Ù† Ùˆ ØªØ²Ø¦ÛŒÙ†Ø§Øª Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯",
                    "ğŸ’¡ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ú¯Ø±Ù… Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯"
                ])
            
            # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ
            recommendations.extend([
                "ğŸ“Š ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø¸Ù… Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯",
                "ğŸ¯ Ø§Ù‡Ø¯Ø§Ù Ù…Ø´Ø®Øµ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯",
                "ğŸ“ˆ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
            ])
            
            return recommendations[:10]  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 ØªÙˆØµÛŒÙ‡
            
        except Exception as e:
            logger.error(f"Error generating recommendations: {e}")
            return ["Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"]
    
    def _base64_to_image(self, base64_string: str) -> Optional[np.ndarray]:
        """ØªØ¨Ø¯ÛŒÙ„ base64 Ø¨Ù‡ ØªØµÙˆÛŒØ± OpenCV"""
        try:
            # Ø­Ø°Ù prefix Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            if ',' in base64_string:
                base64_string = base64_string.split(',')[1]
            
            # ØªØ¨Ø¯ÛŒÙ„ base64 Ø¨Ù‡ bytes
            img_bytes = base64.b64decode(base64_string)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ PIL Image
            pil_image = Image.open(io.BytesIO(img_bytes))
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ OpenCV format
            opencv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            
            return opencv_image
            
        except Exception as e:
            logger.error(f"Error converting base64 to image: {e}")
            return None
    
    def _analyze_image_size(self, img: np.ndarray, image_index: int) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± Ùˆ ØªØ®Ù…ÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
        try:
            height, width = img.shape[:2]
            
            # ØªØ®Ù…ÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±
            # Ø§ÛŒÙ† ÛŒÚ© ØªØ®Ù…ÛŒÙ† Ø³Ø§Ø¯Ù‡ Ø§Ø³Øª - Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ø¨Ø§ÛŒØ¯ Ø§Ø² AI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯
            estimated_size = (width * height) / 10000  # ÙØ±Ù…ÙˆÙ„ Ø³Ø§Ø¯Ù‡
            
            return {
                'dimensions': {'width': width, 'height': height},
                'estimated_area': estimated_size,
                'aspect_ratio': width / height,
                'resolution_quality': 'high' if width > 1000 and height > 1000 else 'medium'
            }
            
        except Exception as e:
            logger.error(f"Error analyzing image size: {e}")
            return {}
    
    def _analyze_layout(self, img: np.ndarray, image_index: int) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø³Ø§Ø®ØªØ§Ø± ØªØµÙˆÛŒØ±"""
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø®Ø§Ú©Ø³ØªØ±ÛŒ
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # ØªØ´Ø®ÛŒØµ Ù„Ø¨Ù‡â€ŒÙ‡Ø§
            edges = cv2.Canny(gray, 50, 150)
            
            # ØªØ´Ø®ÛŒØµ Ø®Ø·ÙˆØ·
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)
            
            # ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†
            layout_analysis = {
                'has_horizontal_lines': False,
                'has_vertical_lines': False,
                'symmetry_score': 0.0,
                'organization_level': 'low'
            }
            
            if lines is not None:
                horizontal_lines = 0
                vertical_lines = 0
                
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                    
                    if abs(angle) < 15 or abs(angle - 180) < 15:
                        horizontal_lines += 1
                    elif abs(angle - 90) < 15 or abs(angle + 90) < 15:
                        vertical_lines += 1
                
                layout_analysis['has_horizontal_lines'] = horizontal_lines > 0
                layout_analysis['has_vertical_lines'] = vertical_lines > 0
                layout_analysis['symmetry_score'] = min(1.0, (horizontal_lines + vertical_lines) / 10)
                
                if layout_analysis['symmetry_score'] > 0.7:
                    layout_analysis['organization_level'] = 'high'
                elif layout_analysis['symmetry_score'] > 0.4:
                    layout_analysis['organization_level'] = 'medium'
            
            return layout_analysis
            
        except Exception as e:
            logger.error(f"Error analyzing layout: {e}")
            return {}
    
    def _analyze_colors(self, img: np.ndarray, image_index: int) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±"""
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ HSV Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ØªØ± Ø±Ù†Ú¯â€ŒÙ‡Ø§
            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø±Ù†Ú¯â€ŒÙ‡Ø§
            hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])
            hist_s = cv2.calcHist([hsv], [1], None, [256], [0, 256])
            hist_v = cv2.calcHist([hsv], [2], None, [256], [0, 256])
            
            # Ø±Ù†Ú¯ ØºØ§Ù„Ø¨
            dominant_hue = np.argmax(hist_h)
            dominant_saturation = np.argmax(hist_s)
            dominant_value = np.argmax(hist_v)
            
            # ØªÙ†ÙˆØ¹ Ø±Ù†Ú¯
            color_diversity = len(np.where(hist_h > hist_h.max() * 0.1)[0])
            
            return {
                'dominant_hue': int(dominant_hue),
                'dominant_saturation': int(dominant_saturation),
                'dominant_value': int(dominant_value),
                'color_diversity': int(color_diversity),
                'brightness_level': 'bright' if dominant_value > 128 else 'dark',
                'saturation_level': 'vibrant' if dominant_saturation > 128 else 'muted'
            }
            
        except Exception as e:
            logger.error(f"Error analyzing colors: {e}")
            return {}
    
    def _detect_objects(self, img: np.ndarray, image_index: int) -> List[Dict[str, Any]]:
        """ØªØ´Ø®ÛŒØµ Ø§Ø´ÛŒØ§Ø¡ Ø¯Ø± ØªØµÙˆÛŒØ±"""
        try:
            # Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ®ØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯
            # Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„ Ø­Ø§Ø¶Ø±ØŒ ØªØ´Ø®ÛŒØµ Ø³Ø§Ø¯Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
            
            objects = []
            
            # ØªØ´Ø®ÛŒØµ Ù…Ø³ØªØ·ÛŒÙ„â€ŒÙ‡Ø§ (Ù…ÛŒØ²ØŒ Ù‚ÙØ³Ù‡ØŒ Ùˆ ØºÛŒØ±Ù‡)
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 1000:  # ÙÙ‚Ø· Ø§Ø´ÛŒØ§Ø¡ Ø¨Ø²Ø±Ú¯
                    x, y, w, h = cv2.boundingRect(contour)
                    objects.append({
                        'type': 'rectangle',
                        'position': {'x': int(x), 'y': int(y)},
                        'size': {'width': int(w), 'height': int(h)},
                        'area': int(area),
                        'confidence': min(1.0, area / 10000)
                    })
            
            return objects
            
        except Exception as e:
            logger.error(f"Error detecting objects: {e}")
            return []
    
    def _calculate_image_quality(self, img: np.ndarray) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©ÛŒÙÛŒØª ØªØµÙˆÛŒØ±"""
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ¶ÙˆØ­
            height, width = img.shape[:2]
            resolution_score = min(1.0, (width * height) / (1920 * 1080))
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ØªØ±Ø§Ø³Øª
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            contrast = gray.std()
            contrast_score = min(1.0, contrast / 100)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ
            brightness = gray.mean()
            brightness_score = 1.0 - abs(brightness - 128) / 128
            
            # Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
            quality_score = (resolution_score * 0.4 + contrast_score * 0.3 + brightness_score * 0.3)
            
            return quality_score
            
        except Exception as e:
            logger.error(f"Error calculating image quality: {e}")
            return 0.0
    
    def _create_advanced_analysis_prompt(self, images: List[str], store_info: Dict[str, Any]) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ prompt Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ AI"""
        return f"""
        ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
        - Ù†Ø§Ù…: {store_info.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
        - Ù†ÙˆØ¹: {store_info.get('store_type', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
        - Ø§Ù†Ø¯Ø§Ø²Ù‡: {store_info.get('store_size', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
        - Ø´Ù‡Ø±: {store_info.get('city', 'Ù†Ø§Ù…Ø´Ø®Øµ')}
        
        Ù„Ø·ÙØ§Ù‹ ØªØµØ§ÙˆÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:
        
        1. Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
        2. Ú©ÛŒÙÛŒØª Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø·Ø±Ø§Ø­ÛŒ
        3. ØªÙ†Ø§Ø³Ø¨ Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ùˆ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ
        4. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù
        5. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        6. Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ (0-100)
        
        ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø§Ø´Ø¯.
        """
    
    def _fallback_ai_analysis(self, store_info: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ AI"""
        return {
            'detected_store_type': store_info.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ'),
            'store_type_confidence': 0.7,
            'analysis_quality': 'basic',
            'recommendations': [
                'Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ ØªØµØ§ÙˆÛŒØ± Ø¨ÛŒØ´ØªØ±ÛŒ ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯',
                'Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ ØªØµØ§ÙˆÛŒØ± Ù†Ù…Ø§ÛŒØ§Ù†Ú¯Ø± ÙˆØ§Ù‚Ø¹ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡Ø³ØªÙ†Ø¯'
            ]
        }
    
    def _generate_consistency_recommendations(self, inconsistencies: List[str]) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒâ€ŒÙ‡Ø§"""
        recommendations = []
        
        for inconsistency in inconsistencies:
            if 'Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡' in inconsistency:
                recommendations.append('Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯')
            elif 'Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡' in inconsistency:
                recommendations.append('Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ù‚ÛŒÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ú©Ù†ÛŒØ¯')
            elif 'Ú©ÛŒÙÛŒØª ØªØµØ§ÙˆÛŒØ±' in inconsistency:
                recommendations.append('ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§ØªØ± ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯')
            elif 'ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ±' in inconsistency:
                recommendations.append('ØªØµØ§ÙˆÛŒØ± Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø² Ø²ÙˆØ§ÛŒØ§ÛŒ Ù…Ø®ØªÙ„Ù ØªÙ‡ÛŒÙ‡ Ú©Ù†ÛŒØ¯')
        
        return recommendations
    
    def _calculate_overall_score(self, basic_analysis: Dict, ai_analysis: Dict, consistency_analysis: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ"""
        try:
            # Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª ØªØµØ§ÙˆÛŒØ± (40%)
            quality_score = basic_analysis.get('quality_score', 0) * 0.4
            
            # Ø§Ù…ØªÛŒØ§Ø² AI (30%)
            ai_confidence = ai_analysis.get('store_type_confidence', 0) * 0.3
            
            # Ø§Ù…ØªÛŒØ§Ø² Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ (30%)
            consistency_score = consistency_analysis.get('score', 0) * 0.3
            
            return quality_score + ai_confidence + consistency_score
            
        except Exception as e:
            logger.error(f"Error calculating overall score: {e}")
            return 0.0
    
    def _create_fallback_result(self) -> ImageAnalysisResult:
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†ØªÛŒØ¬Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        return ImageAnalysisResult(
            store_type_confidence=0.5,
            size_estimation={},
            layout_analysis={},
            color_analysis={},
            object_detection=[],
            consistency_score=0.5,
            recommendations=['Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØµØ§ÙˆÛŒØ± - Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'],
            quality_score=0.5,
            professional_grade=False
        )
