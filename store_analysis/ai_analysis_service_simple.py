#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Optimized by Craser for Chidmano AI - Enhanced Analysis Service

import json
import logging
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import numpy as np
import os
import pandas as pd
from django.core.cache import cache
from django.utils import timezone
from pathlib import Path

from .services.liara_ai_client import LiaraAIClient, LiaraAIError

logger = logging.getLogger(__name__)

class SimpleAIAnalysisService:
    """Ø³Ø±ÙˆÛŒØ³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡"""
    
    def __init__(self):
        self.cache_timeout = 3600  # 1 hour cache
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.analysis_cache = {}
        self.ai_client = LiaraAIClient()
        
    async def analyze_store_async(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AI Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ cache
            cache_key = f"analysis_{hash(str(store_data))}"
            cached_result = cache.get(cache_key)
            if cached_result:
                logger.info("ØªØ­Ù„ÛŒÙ„ Ø§Ø² cache Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯")
                return cached_result
            
            logger.info(f"Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ AI Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
            
            # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ
            tasks = [
                self._analyze_layout_advanced(store_data),
                self._analyze_traffic_patterns_advanced(store_data),
                self._analyze_customer_behavior_advanced(store_data),
                self._analyze_sales_data(store_data),
                self._analyze_image_data(store_data)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
            analysis_result = self._combine_analysis_results(store_data, results)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
            cache.set(cache_key, analysis_result, self.cache_timeout)
            
            logger.info(f"ØªØ­Ù„ÛŒÙ„ AI Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ - Ø§Ù…ØªÛŒØ§Ø²: {analysis_result.get('overall_score', 0)}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù†: {e}")
            return self._get_fallback_analysis(store_data)
    
    def analyze_store(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        try:
            # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù†
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self.analyze_store_async(store_data))
            loop.close()
            return result
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {e}")
            return self._get_fallback_analysis(store_data)
    
    async def _analyze_layout_advanced(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
        try:
            store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
            store_size = float(store_data.get('store_size', 0))
            
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            layout_scores = {
                'supermarket': {'aisle_width': 0.9, 'product_density': 0.8, 'checkout_efficiency': 0.7},
                'clothing': {'display_area': 0.9, 'fitting_rooms': 0.8, 'circulation': 0.7},
                'electronics': {'demo_area': 0.9, 'security': 0.8, 'product_grouping': 0.7},
                'pharmacy': {'prescription_area': 0.9, 'otc_display': 0.8, 'privacy': 0.7},
                'Ø¹Ù…ÙˆÙ…ÛŒ': {'general_layout': 0.7, 'product_placement': 0.6, 'customer_flow': 0.6}
            }
            
            base_scores = layout_scores.get(store_type, layout_scores['Ø¹Ù…ÙˆÙ…ÛŒ'])
            
            # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            size_factor = min(store_size / 100, 1.0) if store_size > 0 else 0.5
            
            return {
                'layout_type': store_type,
                'size_factor': size_factor,
                'scores': {k: v * size_factor for k, v in base_scores.items()},
                'recommendations': self._get_layout_recommendations(store_type, store_size),
                'confidence': 0.85
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    async def _analyze_traffic_patterns_advanced(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ©"""
        try:
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            peak_hours = store_data.get('peak_hours', '10-12, 18-20')
            customer_count = int(store_data.get('daily_customers', 100))
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ©
            traffic_patterns = {
                'peak_hours': peak_hours,
                'average_customers_per_hour': customer_count / 12,
                'traffic_density': 'high' if customer_count > 200 else 'medium' if customer_count > 100 else 'low',
                'bottlenecks': self._identify_bottlenecks(store_data),
                'flow_efficiency': self._calculate_flow_efficiency(store_data)
            }
            
            return {
                'patterns': traffic_patterns,
                'recommendations': self._get_traffic_recommendations(traffic_patterns),
                'confidence': 0.8
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ©: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    async def _analyze_customer_behavior_advanced(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù†"""
        try:
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ú†ÛŒØ¯Ù…Ø§Ù†
            product_categories = store_data.get('product_categories', [])
            store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
            
            behavior_analysis = {
                'dwell_time': self._estimate_dwell_time(store_type, product_categories),
                'purchase_patterns': self._analyze_purchase_patterns(product_categories),
                'customer_segments': self._identify_customer_segments(store_type),
                'conversion_factors': self._identify_conversion_factors(store_data)
            }
            
            return {
                'behavior': behavior_analysis,
                'recommendations': self._get_behavior_recommendations(behavior_analysis),
                'confidence': 0.75
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    async def _analyze_sales_data(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ø¨Ø§ pandas"""
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´
            sales_file_path = None
            if 'uploaded_files' in store_data:
                uploaded_files = store_data['uploaded_files']
                if 'sales_file' in uploaded_files and 'path' in uploaded_files['sales_file']:
                    sales_file_path = uploaded_files['sales_file']['path']
            
            if sales_file_path and os.path.exists(sales_file_path):
                # ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´ ÙˆØ§Ù‚Ø¹ÛŒ
                return await self._analyze_real_sales_data(sales_file_path)
            else:
                # ØªØ­Ù„ÛŒÙ„ ØªØ®Ù…ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                return await self._analyze_estimated_sales_data(store_data)
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    async def _analyze_image_data(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±ÛŒ"""
        try:
            if 'image_analysis' in store_data:
                return store_data['image_analysis']
            else:
                return {'status': 'no_images', 'confidence': 0.5}
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØµØ§ÙˆÛŒØ±: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    def _combine_analysis_results(self, store_data: Dict[str, Any], results: List[Any]) -> Dict[str, Any]:
        """ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆÙÙ‚
            successful_results = [r for r in results if not isinstance(r, Exception)]
            
            if not successful_results:
                return self._get_fallback_analysis(store_data)
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
            overall_score = self._calculate_advanced_score(successful_results)
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
            final_report = {
                "status": "ok",
                "confidence": min(0.95, sum(r.get('confidence', 0.5) for r in successful_results) / len(successful_results)),
                "summary": self._generate_advanced_summary(store_data, successful_results),
                "key_findings": self._extract_key_findings(successful_results),
                "recommendations": self._generate_advanced_recommendations(successful_results),
                "predictions": self._generate_predictions(store_data, successful_results),
                "overall_score": overall_score,
                "report_ready": True,
                "timestamp": timezone.now().isoformat()
            }
            
            if self.ai_client.enabled:
                try:
                    enriched = self._generate_managerial_summary_with_ai(store_data, final_report)
                    if enriched:
                        final_report.update(enriched)
                        final_report.setdefault('metadata', {})['summary_model'] = 'openai/gpt-4o-mini'
                except LiaraAIError as exc:
                    logger.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø¨Ø§ Liara: %s", exc)
                except Exception as exc:  # pragma: no cover
                    logger.error("âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ: %s", exc, exc_info=True)

            return final_report
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬: {e}")
            return self._get_fallback_analysis(store_data)
    
    def _get_fallback_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ fallback Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§"""
        return {
            "status": "ok",
            "confidence": 0.6,
            "summary": f"ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.",
            "key_findings": ["Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚"],
            "recommendations": {
                "layout": ["Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ù„ÛŒ"],
                "lighting": ["Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ"],
                "customer_flow": ["Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ± Ù…Ø´ØªØ±ÛŒØ§Ù†"]
            },
            "predictions": {
                "expected_sales_increase": "+15%",
                "roi": "6 Ù…Ø§Ù‡"
            },
            "overall_score": 65,
            "report_ready": True,
            "timestamp": timezone.now().isoformat()
        }

    def _generate_managerial_summary_with_ai(self, store_data: Dict[str, Any], base_report: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ØªÙ‡ÛŒÙ‡ Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§ GPT-4o-mini"""

        system_prompt = (
            "ØªÙˆ ÛŒÚ© Ù…Ø´Ø§ÙˆØ± Ø§Ø±Ø´Ø¯ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ Ù‡Ø³ØªÛŒ. Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ JSON Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ "
            "summary (Ù…ØªÙ† Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± 180 Ú©Ù„Ù…Ù‡)ØŒ key_findings (Ù„ÛŒØ³Øª Ø¨ÙˆÙ„Øª Ú©ÙˆØªØ§Ù‡)ØŒ "
            "recommendations (Ù„ÛŒØ³ØªÛŒ Ø´Ø§Ù…Ù„ Ø³Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ø§ ØªÙ…Ø±Ú©Ø² Ù…Ø¯ÛŒØ±ÛŒØªÛŒ) Ø¨Ø§Ø´Ø¯."
        )

        data_snippet = {
            "store": store_data,
            "report": {
                "summary": base_report.get('summary'),
                "key_findings": base_report.get('key_findings'),
                "recommendations": base_report.get('recommendations'),
                "predictions": base_report.get('predictions'),
                "overall_score": base_report.get('overall_score'),
            }
        }

        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ prompt
        data_snippet_str = json.dumps(data_snippet, ensure_ascii=False, default=str)
        if len(data_snippet_str) > 2500:
            data_snippet_str = data_snippet_str[:2500]
            logger.warning("âš ï¸ Managerial summary prompt truncated to 2500 chars")
        
        user_prompt = (
            "ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø®Ù„Ø§ØµÙ‡ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ú©Ù†:\n"
            f"{data_snippet_str}"
        )

        try:
            response = self.ai_client.chat(
                model='openai/gpt-4o-mini',
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.25,
                max_output_tokens=1500,
            )

            data = response.json()
            enriched: Dict[str, Any] = {}
            if data.get('summary'):
                enriched['summary'] = data['summary']
            if data.get('key_findings'):
                enriched['key_findings'] = data['key_findings']
            if data.get('recommendations'):
                enriched['executive_recommendations'] = data['recommendations']
            
            if enriched:
                logger.info("âœ… Managerial summary Ø¨Ø§ AI ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
            else:
                logger.warning("âš ï¸ Managerial summary Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")
            
            return enriched
        except LiaraAIError as exc:
            logger.warning("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Managerial summary Ø¨Ø§ Liara: %s", exc)
            return None
        except Exception as exc:
            logger.error("âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Managerial summary: %s", exc, exc_info=True)
            return None
    
    # Ù…ØªØ¯Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    def _get_layout_recommendations(self, store_type: str, store_size: float) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†"""
        recommendations = {
            'supermarket': [
                "Ø¹Ø±Ø¶ Ø±Ø§Ù‡Ø±ÙˆÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø­Ø¯Ø§Ù‚Ù„ 1.5 Ù…ØªØ± Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯",
                "Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ Ø±Ø§ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ Ø±Ø§Ù‡Ø±ÙˆÙ‡Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯",
                "ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ø¯Ø± Ù†Ù‚Ø§Ø· Ù…Ø®ØªÙ„Ù Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯"
            ],
            'clothing': [
                "ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§ØªØ§Ù‚â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ùˆ ÙØ±Ø§Ù‡Ù… Ú©Ù†ÛŒØ¯",
                "Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯",
                "Ù…Ø³ÛŒØ± Ú¯Ø±Ø¯Ø´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù†ÛŒØ¯"
            ],
            'electronics': [
                "ÙØ¶Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯",
                "Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ø±Ø§ ØªÙ‚ÙˆÛŒØª Ú©Ù†ÛŒØ¯",
                "Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø±Ø§ Ú©Ù†Ø§Ø± Ù‡Ù… Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯"
            ],
            'pharmacy': [
                "Ø¨Ø®Ø´ Ù†Ø³Ø®Ù‡ Ø±Ø§ Ø§Ø² Ø³Ø§ÛŒØ± Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯",
                "Ù…Ø­ØµÙˆÙ„Ø§Øª OTC Ø±Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯",
                "Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ Ø­ÙØ¸ Ú©Ù†ÛŒØ¯"
            ]
        }
        return recommendations.get(store_type, ["Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"])
    
    def _identify_bottlenecks(self, store_data: Dict[str, Any]) -> List[str]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú¯Ù„ÙˆÚ¯Ø§Ù‡â€ŒÙ‡Ø§"""
        bottlenecks = []
        store_size = float(store_data.get('store_size', 0))
        daily_customers = int(store_data.get('daily_customers', 100))
        
        if store_size < 50 and daily_customers > 100:
            bottlenecks.append("ÙØ¶Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†")
        
        if daily_customers > 200:
            bottlenecks.append("Ù†ÛŒØ§Ø² Ø¨Ù‡ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨ÛŒØ´ØªØ±")
        
        return bottlenecks
    
    def _calculate_flow_efficiency(self, store_data: Dict[str, Any]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¬Ø±ÛŒØ§Ù† Ù…Ø´ØªØ±ÛŒØ§Ù†"""
        store_size = float(store_data.get('store_size', 0))
        daily_customers = int(store_data.get('daily_customers', 100))
        
        if store_size == 0:
            return 0.5
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø³Ø¨Øª Ù…Ø´ØªØ±ÛŒ Ø¨Ù‡ Ù…ØªØ± Ù…Ø±Ø¨Ø¹
        customer_density = daily_customers / store_size
        
        if customer_density < 2:
            return 0.9
        elif customer_density < 4:
            return 0.7
        else:
            return 0.5
    
    def _estimate_dwell_time(self, store_type: str, product_categories: List[str]) -> Dict[str, Any]:
        """ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† Ù…Ø§Ù†Ø¯Ú¯Ø§Ø±ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†"""
        base_times = {
            'supermarket': {'min': 15, 'max': 45, 'avg': 25},
            'clothing': {'min': 20, 'max': 60, 'avg': 35},
            'electronics': {'min': 30, 'max': 90, 'avg': 50},
            'pharmacy': {'min': 10, 'max': 30, 'avg': 18},
            'Ø¹Ù…ÙˆÙ…ÛŒ': {'min': 15, 'max': 40, 'avg': 25}
        }
        
        return base_times.get(store_type, base_times['Ø¹Ù…ÙˆÙ…ÛŒ'])
    
    def _analyze_purchase_patterns(self, product_categories: List[str]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯"""
        return {
            'impulse_buy_potential': 'high' if len(product_categories) > 5 else 'medium',
            'cross_selling_opportunities': len(product_categories),
            'seasonal_patterns': 'moderate'
        }
    
    def _identify_customer_segments(self, store_type: str) -> List[str]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†"""
        segments = {
            'supermarket': ['Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡â€ŒÙ‡Ø§', 'Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù†', 'Ø´Ø§ØºÙ„ÛŒÙ†'],
            'clothing': ['Ø¬ÙˆØ§Ù†Ø§Ù†', 'Ù…ÛŒØ§Ù†Ø³Ø§Ù„Ø§Ù†', 'Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡â€ŒÙ‡Ø§'],
            'electronics': ['ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒØ¯ÙˆØ³ØªØ§Ù†', 'Ø­Ø±ÙÙ‡â€ŒØ§ÛŒâ€ŒÙ‡Ø§', 'Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒØ§Ù†'],
            'pharmacy': ['Ø³Ø§Ù„Ù…Ù†Ø¯Ø§Ù†', 'ÙˆØ§Ù„Ø¯ÛŒÙ†', 'Ø¨ÛŒÙ…Ø§Ø±Ø§Ù† Ù…Ø²Ù…Ù†']
        }
        return segments.get(store_type, ['Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¹Ù…ÙˆÙ…ÛŒ'])
    
    def _identify_conversion_factors(self, store_data: Dict[str, Any]) -> List[str]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø¹ÙˆØ§Ù…Ù„ ØªØ¨Ø¯ÛŒÙ„"""
        factors = []
        
        if store_data.get('lighting_type') == 'mixed':
            factors.append("Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ù…Ù†Ø§Ø³Ø¨")
        
        if float(store_data.get('store_size', 0)) > 100:
            factors.append("ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ")
        
        if int(store_data.get('daily_customers', 0)) > 150:
            factors.append("ØªØ±Ø§ÙÛŒÚ© Ø¨Ø§Ù„Ø§")
        
        return factors if factors else ["Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹ÙˆØ§Ù…Ù„ ØªØ¨Ø¯ÛŒÙ„"]
    
    def _get_traffic_recommendations(self, traffic_patterns: Dict[str, Any]) -> List[str]:
        """ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ©"""
        recommendations = []
        
        if traffic_patterns['traffic_density'] == 'high':
            recommendations.append("Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª")
            recommendations.append("Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ Ùˆ Ø®Ø±ÙˆØ¬")
        
        if traffic_patterns['flow_efficiency'] < 0.6:
            recommendations.append("Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù†")
        
        return recommendations
    
    def _get_behavior_recommendations(self, behavior_analysis: Dict[str, Any]) -> List[str]:
        """ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ"""
        recommendations = []
        
        dwell_time = behavior_analysis.get('dwell_time', {}).get('avg', 25)
        if dwell_time < 20:
            recommendations.append("Ø§ÙØ²Ø§ÛŒØ´ Ø¬Ø°Ø§Ø¨ÛŒØª Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ù…Ø§Ù†Ø¯Ú¯Ø§Ø±ÛŒ")
        
        if behavior_analysis.get('purchase_patterns', {}).get('impulse_buy_potential') == 'high':
            recommendations.append("Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‚Ø±Ø§Ø±Ú¯ÛŒØ±ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯Ù‡Ø§ÛŒ Ø¢Ù†ÛŒ")
        
        return recommendations
    
    async def _analyze_real_sales_data(self, file_path: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´ ÙˆØ§Ù‚Ø¹ÛŒ"""
        try:
            # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ø§ pandas
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            elif file_path.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(file_path)
            else:
                return {'error': 'ÙØ±Ù…Øª ÙØ§ÛŒÙ„ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯', 'confidence': 0.3}
            
            # ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ
            analysis = {
                'total_sales': df['sales'].sum() if 'sales' in df.columns else 0,
                'average_daily_sales': df['sales'].mean() if 'sales' in df.columns else 0,
                'growth_rate': self._calculate_growth_rate(df),
                'peak_hours': self._identify_peak_hours(df),
                'seasonal_patterns': self._analyze_seasonal_patterns(df),
                'confidence': 0.9
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ ÙØ±ÙˆØ´: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    async def _analyze_estimated_sales_data(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ ØªØ®Ù…ÛŒÙ†ÛŒ ÙØ±ÙˆØ´"""
        try:
            store_size = float(store_data.get('store_size', 0))
            daily_customers = int(store_data.get('daily_customers', 100))
            store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
            
            # ØªØ®Ù…ÛŒÙ† ÙØ±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            avg_purchase_values = {
                'supermarket': 150000,
                'clothing': 300000,
                'electronics': 2000000,
                'pharmacy': 200000,
                'Ø¹Ù…ÙˆÙ…ÛŒ': 200000
            }
            
            avg_purchase = avg_purchase_values.get(store_type, 200000)
            estimated_daily_sales = daily_customers * avg_purchase * 0.3  # 30% conversion rate
            
            return {
                'estimated_daily_sales': estimated_daily_sales,
                'estimated_monthly_sales': estimated_daily_sales * 30,
                'conversion_rate': 0.3,
                'average_purchase_value': avg_purchase,
                'confidence': 0.6
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØ®Ù…ÛŒÙ†ÛŒ ÙØ±ÙˆØ´: {e}")
            return {'error': str(e), 'confidence': 0.3}
    
    def _calculate_growth_rate(self, df: pd.DataFrame) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø±Ø® Ø±Ø´Ø¯"""
        try:
            if 'date' in df.columns and 'sales' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                df = df.sort_values('date')
                first_month = df['sales'].iloc[:len(df)//2].mean()
                last_month = df['sales'].iloc[len(df)//2:].mean()
                return ((last_month - first_month) / first_month) * 100
            return 0
        except:
            return 0
    
    def _identify_peak_hours(self, df: pd.DataFrame) -> List[str]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§Ø¹Ø§Øª Ù¾ÛŒÚ©"""
        try:
            if 'hour' in df.columns:
                peak_hours = df.groupby('hour')['sales'].sum().nlargest(3).index.tolist()
                return [f"{h}:00" for h in peak_hours]
            return ["10-12", "18-20"]
        except:
            return ["10-12", "18-20"]
    
    def _analyze_seasonal_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ÙØµÙ„ÛŒ"""
        try:
            if 'date' in df.columns:
                df['month'] = pd.to_datetime(df['date']).dt.month
                monthly_sales = df.groupby('month')['sales'].sum()
                return {
                    'peak_month': monthly_sales.idxmax(),
                    'low_month': monthly_sales.idxmin(),
                    'seasonality_factor': monthly_sales.max() / monthly_sales.min()
                }
            return {'seasonality_factor': 1.2}
        except:
            return {'seasonality_factor': 1.2}
    
    def _calculate_advanced_score(self, results: List[Dict[str, Any]]) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        try:
            total_score = 0
            weight_sum = 0
            
            for result in results:
                if 'confidence' in result:
                    weight = result['confidence']
                    score = self._extract_score_from_result(result)
                    total_score += score * weight
                    weight_sum += weight
            
            if weight_sum > 0:
                return int(total_score / weight_sum)
            return 70
        except:
            return 70
    
    def _extract_score_from_result(self, result: Dict[str, Any]) -> int:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù…ØªÛŒØ§Ø² Ø§Ø² Ù†ØªÛŒØ¬Ù‡"""
        if 'scores' in result:
            scores = result['scores']
            if isinstance(scores, dict):
                return int(sum(scores.values()) / len(scores) * 100)
        return 70
    
    def _generate_advanced_summary(self, store_data: Dict[str, Any], results: List[Dict[str, Any]]) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        store_name = store_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§')
        store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
        
        summary = f"ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ø§Ø² Ù†ÙˆØ¹ {store_type} Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. "
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        key_points = []
        for result in results:
            if 'recommendations' in result:
                key_points.append("Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù†")
            if 'patterns' in result and 'traffic_density' in result['patterns']:
                density = result['patterns']['traffic_density']
                key_points.append(f"ØªØ±Ø§ÙÛŒÚ© {density}")
        
        if key_points:
            summary += f"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {', '.join(key_points[:3])}. "
        
        summary += "Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙØ±ÙˆØ´ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯."
        
        return summary
    
    def _extract_key_findings(self, results: List[Dict[str, Any]]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒØ§ÙØªÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ"""
        findings = []
        
        for result in results:
            if 'bottlenecks' in result:
                findings.extend(result['bottlenecks'])
            if 'patterns' in result and 'traffic_density' in result['patterns']:
                density = result['patterns']['traffic_density']
                findings.append(f"ØªØ±Ø§ÙÛŒÚ© {density} Ù…Ø´ØªØ±ÛŒØ§Ù†")
        
        return findings[:5] if findings else ["Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ù„ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†"]
    
    def _generate_advanced_recommendations(self, results: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        recommendations = {
            "layout": [],
            "lighting": [],
            "customer_flow": []
        }
        
        for result in results:
            if 'recommendations' in result:
                recs = result['recommendations']
                if isinstance(recs, list):
                    recommendations["layout"].extend(recs[:2])
                elif isinstance(recs, dict):
                    for category, items in recs.items():
                        if category in recommendations:
                            recommendations[category].extend(items[:2])
        
        # Ø­Ø°Ù Ù…ÙˆØ§Ø±Ø¯ ØªÚ©Ø±Ø§Ø±ÛŒ
        for category in recommendations:
            recommendations[category] = list(set(recommendations[category]))[:3]
        
        return recommendations
    
    def _generate_predictions(self, store_data: Dict[str, Any], results: List[Dict[str, Any]]) -> Dict[str, str]:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§"""
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
        overall_score = self._calculate_advanced_score(results)
        
        if overall_score > 80:
            sales_increase = "+25%"
            roi = "3 Ù…Ø§Ù‡"
        elif overall_score > 70:
            sales_increase = "+20%"
            roi = "4 Ù…Ø§Ù‡"
        elif overall_score > 60:
            sales_increase = "+15%"
            roi = "5 Ù…Ø§Ù‡"
        else:
            sales_increase = "+10%"
            roi = "6 Ù…Ø§Ù‡"
        
        return {
            "expected_sales_increase": sales_increase,
            "roi": roi
        }
    
    def _calculate_data_completeness(self, store_data: Dict) -> Dict:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯"""
        # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        important_fields = [
            'store_name', 'store_type', 'store_size', 'store_location',
            'daily_customers', 'monthly_revenue', 'employee_count',
            'checkout_count', 'fixed_shelves', 'high_traffic_areas',
            'ignored_sections', 'customer_videos', 'store_photos'
        ]
        
        # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ (Ú©Ù…ØªØ± Ù…Ù‡Ù…)
        optional_fields = [
            'phone', 'email', 'store_dimensions', 'city', 'area',
            'establishment_year', 'working_hours'
        ]
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾Ø± Ø´Ø¯Ù‡
        filled_important = 0
        filled_optional = 0
        
        for field in important_fields:
            value = store_data.get(field)
            if value and value != '' and value != [] and value != 0:
                filled_important += 1
        
        for field in optional_fields:
            value = store_data.get(field)
            if value and value != '' and value != [] and value != 0:
                filled_optional += 1
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯
        total_important = len(important_fields)
        total_optional = len(optional_fields)
        
        important_percentage = (filled_important / total_important) * 100
        optional_percentage = (filled_optional / total_optional) * 100
        
        # ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ: ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… 80% Ùˆ Ø§Ø®ØªÛŒØ§Ø±ÛŒ 20%
        overall_percentage = (important_percentage * 0.8) + (optional_percentage * 0.2)
        
        return {
            'percentage': round(overall_percentage, 1),
            'important_fields_filled': filled_important,
            'important_fields_total': total_important,
            'optional_fields_filled': filled_optional,
            'optional_fields_total': total_optional,
            'missing_important_fields': [field for field in important_fields if not store_data.get(field) or store_data.get(field) == '' or store_data.get(field) == []],
            'filled_fields': [field for field in important_fields + optional_fields if store_data.get(field) and store_data.get(field) != '' and store_data.get(field) != []]
        }
    
    def _calculate_analysis_confidence(self, data_completeness: Dict) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† ØªØ­Ù„ÛŒÙ„"""
        percentage = data_completeness['percentage']
        
        if percentage >= 80:
            return "Ø¹Ø§Ù„ÛŒ"
        elif percentage >= 60:
            return "Ø®ÙˆØ¨"
        elif percentage >= 40:
            return "Ù…ØªÙˆØ³Ø·"
        elif percentage >= 20:
            return "Ø¶Ø¹ÛŒÙ"
        else:
            return "Ø®ÛŒÙ„ÛŒ Ø¶Ø¹ÛŒÙ"
    
    def _generate_missing_data_warning(self, data_completeness: Dict) -> Dict:
        """ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ù‚Øµ"""
        percentage = data_completeness['percentage']
        missing_fields = data_completeness['missing_important_fields']
        
        if percentage >= 70:
            return {
                'level': 'info',
                'message': f'ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ {percentage}% Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.',
                'suggestion': 'Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.'
            }
        elif percentage >= 40:
            return {
                'level': 'warning',
                'message': f'ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ {percentage}% Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø±Ø®ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù‡Ù… Ù†Ø§Ù‚Øµ Ø§Ø³Øª.',
                'suggestion': f'ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù†Ø§Ù‚Øµ: {", ".join(missing_fields[:5])}',
                'impact': 'Ø¯Ù‚Øª ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª.'
            }
        else:
            return {
                'level': 'error',
                'message': f'ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ {percentage}% Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø³ÛŒØ§Ø± Ù†Ø§Ù‚Øµ Ø§Ø³Øª.',
                'suggestion': f'Ù„Ø·ÙØ§Ù‹ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ù‡Ù… Ø²ÛŒØ± Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯: {", ".join(missing_fields[:5])}',
                'impact': 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ø¯Ù‚Øª Ù¾Ø§ÛŒÛŒÙ† Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ØªØ§ÛŒØ¬ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ù†Ø¨Ø§Ø´Ø¯.'
            }
    
    def _calculate_overall_score(self, layout: Dict, traffic: Dict, customer: Dict) -> int:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ"""
        scores = []
        if layout and 'score' in layout:
            scores.append(layout['score'])
        if traffic and 'score' in traffic:
            scores.append(traffic['score'])
        if customer and 'score' in customer:
            scores.append(customer['score'])
        
        return sum(scores) // len(scores) if scores else 5
    
    def _generate_recommendations(self, layout: Dict, traffic: Dict, customer: Dict) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recommendations = []
        
        if layout and 'recommendations' in layout:
            recommendations.extend(layout['recommendations'])
        if traffic and 'recommendations' in traffic:
            recommendations.extend(traffic['recommendations'])
        if customer and 'recommendations' in customer:
            recommendations.extend(customer['recommendations'])
        
        return recommendations[:10]  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 ØªÙˆØµÛŒÙ‡
    
    def _generate_key_insights(self, store_data: Dict, layout: Dict) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ"""
        insights = []
        
        store_name = store_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
        store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
        
        insights.append(f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ø§Ø² Ù†ÙˆØ¹ {store_type} Ø§Ø³Øª")
        
        if layout and 'insights' in layout:
            insights.extend(layout['insights'])
        
        return insights[:5]  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ø¨ÛŒÙ†Ø´
    
    def perform_complete_analysis(self, store_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
        try:
            logger.info(f"Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ AI Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
            
            # ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†
            layout_analysis = self._analyze_layout(store_data)
            
            # ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ©
            traffic_analysis = self._analyze_traffic_patterns(store_data)
            
            # ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù†
            customer_analysis = self._analyze_customer_behavior(store_data)
            
            # ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ
            overall_analysis = self._analyze_overall_performance(store_data)
            
            # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬ Ùˆ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
            final_report = self._generate_final_report(
                store_data, 
                layout_analysis, 
                traffic_analysis, 
                customer_analysis,
                overall_analysis
            )
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ PDF
            formatted_text = self._format_final_report_for_pdf(final_report, store_data)
            
            logger.info(f"ØªØ­Ù„ÛŒÙ„ AI ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
            
            return {
                'status': 'completed',
                'timestamp': timezone.now().isoformat(),
                'store_name': store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                'formatted_text': formatted_text,  # Ù…ØªÙ† ÙØ±Ù…Øª Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ PDF
                'analysis_summary': final_report['summary'],
                'detailed_analysis': final_report['detailed'],
                'recommendations': final_report['recommendations'],
                'implementation_plan': final_report['implementation'],
                'expected_improvements': final_report['improvements'],
                'visualizations': final_report['visualizations'],
                'metrics': final_report['metrics']
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ AI: {str(e)}")
            return {
                'status': 'error',
                'error_message': str(e),
                'timestamp': timezone.now().isoformat()
            }
    
    def _analyze_layout(self, store_data: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
        store_size = store_data.get('store_size', '0')
        checkout_count = store_data.get('checkout_count', '1')
        fixed_shelves = store_data.get('fixed_shelves', [])
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø¹Ø¯Ø¯
        try:
            store_size_num = int(store_size) if isinstance(store_size, str) else store_size
            checkout_count_num = int(checkout_count) if isinstance(checkout_count, str) else checkout_count
        except (ValueError, TypeError):
            store_size_num = 0
            checkout_count_num = 1
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†
        layout_score = 70.0  # Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÙ‡
        
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if store_size_num > 100:
            layout_score += 10
        if store_size_num > 200:
            layout_score += 10
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§
        if checkout_count_num >= 3:
            layout_score += 10
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ø«Ø§Ø¨Øª
        if isinstance(fixed_shelves, list) and len(fixed_shelves) > 2:
            layout_score += 5
            
        return {
            'score': min(layout_score, 100.0),
            'insights': [
                f'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù…ØªØ±Ø§Ú˜ {store_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹',
                f'ØªØ¹Ø¯Ø§Ø¯ {checkout_count} ØµÙ†Ø¯ÙˆÙ‚ Ù¾Ø±Ø¯Ø§Ø®Øª',
                f'ØªØ¹Ø¯Ø§Ø¯ {len(fixed_shelves)} Ù‚ÙØ³Ù‡ Ø«Ø§Ø¨Øª'
            ],
            'recommendations': [
                'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§',
                'Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙˆØ§Ø¶Ø­',
                'Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª'
            ]
        }
    
    def _analyze_traffic_patterns(self, store_data: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ©"""
        daily_customers = store_data.get('daily_customers', 0)
        high_traffic_areas = store_data.get('high_traffic_areas', [])
        ignored_sections = store_data.get('ignored_sections', [])
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ø§ÙÛŒÚ©
        traffic_score = 70.0
        
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†
        if daily_customers > 100:
            traffic_score += 15
        if daily_customers > 200:
            traffic_score += 10
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø§Ø·Ù‚ Ù¾Ø±ØªØ±Ø¯Ø¯
        if len(high_traffic_areas) >= 3:
            traffic_score += 10
            
        # Ú©Ø§Ù‡Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡
        if len(ignored_sections) > 2:
            traffic_score -= 10
            
        return {
            'score': max(traffic_score, 0.0),
            'insights': [
                f'ØªØ¹Ø¯Ø§Ø¯ {daily_customers} Ù…Ø´ØªØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡',
                f'ØªØ¹Ø¯Ø§Ø¯ {len(high_traffic_areas)} Ù…Ù†Ø·Ù‚Ù‡ Ù¾Ø±ØªØ±Ø¯Ø¯',
                f'ØªØ¹Ø¯Ø§Ø¯ {len(ignored_sections)} Ø¨Ø®Ø´ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡'
            ],
            'recommendations': [
                'Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† ØªØ±Ø§ÙÛŒÚ©',
                'Ú©Ø§Ù‡Ø´ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡',
                'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø·Ù‚ Ù¾Ø±ØªØ±Ø¯Ø¯'
            ]
        }
    
    def _analyze_customer_behavior(self, store_data: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù†"""
        top_selling_products = store_data.get('top_selling_products', [])
        attraction_elements = store_data.get('attraction_elements', [])
        lighting_type = store_data.get('lighting_type', '')
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ
        behavior_score = 70.0
        
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´
        if len(top_selling_products) >= 3:
            behavior_score += 15
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù†Ø§ØµØ± Ø¬Ø°Ø§Ø¨
        if len(attraction_elements) >= 2:
            behavior_score += 10
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ
        if lighting_type in ['led', 'natural']:
            behavior_score += 5
            
        return {
            'score': min(behavior_score, 100.0),
            'insights': [
                f'ØªØ¹Ø¯Ø§Ø¯ {len(top_selling_products)} Ù…Ø­ØµÙˆÙ„ Ù¾Ø±ÙØ±ÙˆØ´',
                f'ØªØ¹Ø¯Ø§Ø¯ {len(attraction_elements)} Ø¹Ù†ØµØ± Ø¬Ø°Ø§Ø¨',
                f'Ù†ÙˆØ¹ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ: {lighting_type}'
            ],
            'recommendations': [
                'Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´',
                'Ø§ÙØ²Ø§ÛŒØ´ Ø¹Ù†Ø§ØµØ± Ø¬Ø°Ø§Ø¨',
                'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ'
            ]
        }
    
    def _analyze_overall_performance(self, store_data: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ù„ÛŒ"""
        store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
        report_detail_level = store_data.get('report_detail_level', 'basic')
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
        overall_score = 75.0
        
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if store_type in ['Ø³ÙˆÙ¾Ø±Ù…Ø§Ø±Ú©Øª', 'Ù‡Ø§ÛŒÙ¾Ø±Ù…Ø§Ø±Ú©Øª']:
            overall_score += 10
            
        # Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø·Ø­ Ø¬Ø²Ø¦ÛŒØ§Øª Ú¯Ø²Ø§Ø±Ø´
        if report_detail_level == 'detailed':
            overall_score += 5
            
        return {
            'score': min(overall_score, 100.0),
            'insights': [
                f'Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_type}',
                f'Ø³Ø·Ø­ Ø¬Ø²Ø¦ÛŒØ§Øª: {report_detail_level}'
            ],
            'recommendations': [
                'Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ù„ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†',
                'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§',
                'Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ'
            ]
        }
    
    def _generate_final_report(self, store_data: Dict, layout: Dict, traffic: Dict, 
                             customer: Dict, overall: Dict) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ"""
        
        store_name = store_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§')
        store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
        store_size = store_data.get('store_size', 0)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
        overall_score = (layout['score'] + traffic['score'] + customer['score'] + overall['score']) / 4
        
        # ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        executive_summary = f"""
        ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ {store_name}
        
        Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_type}
        Ù…ØªØ±Ø§Ú˜: {store_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
        Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ: {overall_score:.1f}/100
        
        Ù†ØªØ§ÛŒØ¬ Ú©Ù„ÛŒØ¯ÛŒ:
        - Ú©Ø§Ø±Ø§ÛŒÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†: {layout['score']:.1f}%
        - Ø¬Ø±ÛŒØ§Ù† ØªØ±Ø§ÙÛŒÚ©: {traffic['score']:.1f}%
        - Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ: {customer['score']:.1f}%
        - Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©Ù„ÛŒ: {overall['score']:.1f}%
        """
        
        # ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ
        all_recommendations = []
        all_recommendations.extend(layout['recommendations'])
        all_recommendations.extend(traffic['recommendations'])
        all_recommendations.extend(customer['recommendations'])
        all_recommendations.extend(overall['recommendations'])
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§
        unique_recommendations = list(set(all_recommendations))
        
        # Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        implementation_plan = {
            'Ù…Ø±Ø­Ù„Ù‡ 1': 'ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ (1-2 Ù‡ÙØªÙ‡)',
            'Ù…Ø±Ø­Ù„Ù‡ 2': 'Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ø¬Ø¯ÛŒØ¯ (2-3 Ù‡ÙØªÙ‡)',
            'Ù…Ø±Ø­Ù„Ù‡ 3': 'Ø§Ø¬Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª (3-4 Ù‡ÙØªÙ‡)',
            'Ù…Ø±Ø­Ù„Ù‡ 4': 'Ù†Ø¸Ø§Ø±Øª Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ (Ù…Ø³ØªÙ…Ø±)'
        }
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
        improvements = {
            'sales_increase': '15-25%',
            'customer_satisfaction': '20-30%',
            'efficiency_improvement': '25-35%',
            'wait_time_reduction': '30-40%'
        }
        
        # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        metrics = {
            'overall_performance': overall_score,
            'layout_efficiency': layout['score'],
            'traffic_flow': traffic['score'],
            'customer_experience': customer['score'],
            'space_utilization': overall['score']
        }
        
        return {
            'summary': executive_summary,
            'detailed': {
                'layout_analysis': layout,
                'traffic_analysis': traffic,
                'customer_analysis': customer,
                'overall_analysis': overall
            },
            'recommendations': unique_recommendations,
            'implementation': implementation_plan,
            'improvements': improvements,
            'visualizations': {
                'charts': ['performance_chart', 'traffic_flow_chart', 'customer_behavior_chart'],
                'heatmaps': ['traffic_heatmap', 'sales_heatmap']
            },
            'metrics': metrics
        }
    
    def _format_final_report_for_pdf(self, report: Dict[str, Any], store_data: Dict[str, Any]) -> str:
        """ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ PDF Ø¨Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
            name = store_data.get("store_name", "ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§")
            store_type = store_data.get("store_type", "Ø¹Ù…ÙˆÙ…ÛŒ")
            score = report.get("metrics", {}).get("overall_performance", 70)
            summary = report.get("summary", "ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
            recs = report.get("recommendations", [])
            improvements = report.get("improvements", {})
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ PDF
            def process_persian_text_for_pdf(text):
                """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ PDF"""
                if not text:
                    return text
                
                try:
                    import arabic_reshaper
                    # Ø§Ø¹Ù…Ø§Ù„ Character Shaping Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§
                    processed_text = arabic_reshaper.reshape(text)
                    return processed_text
                except Exception as e:
                    logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ: {e}")
                    return text
            
            # ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            formatted_recs = ""
            for i, rec in enumerate(recs[:10], 1):  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 ØªÙˆØµÛŒÙ‡
                formatted_recs += f"\nğŸ“Œ {i}. {rec}"
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            formatted_recs = process_persian_text_for_pdf(formatted_recs)
            
            # ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
            improvements_text = ""
            if isinstance(improvements, dict):
                for key, value in improvements.items():
                    improvements_text += f"\nâ€¢ {key}: {value}"
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
            improvements_text = process_persian_text_for_pdf(improvements_text)
            
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
            final_text = f"""
{'='*60}
ğŸ›ï¸ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {name}
{'='*60}

ğŸ“‹ Ù…Ø´Ø®ØµØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
   â€¢ Ù†Ø§Ù…: {name}
   â€¢ Ù†ÙˆØ¹: {store_type}
   â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ: {score:.1f}/100

{'='*60}
ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ:
{'='*60}

{summary.strip()}

{'='*60}
âœ… ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯:
{'='*60}
{formatted_recs.strip()}

{'='*60}
ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ Ù¾Ø³ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:
{'='*60}
{improvements_text.strip() if improvements_text else 'â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'}

{'='*60}
ğŸ“… ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {timezone.now().strftime('%Y/%m/%d - %H:%M')}
ğŸ’¡ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ ØªÙˆØ³Ø· Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª
{'='*60}
            """
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ PDF
            final_text = process_persian_text_for_pdf(final_text)
            
            return final_text.strip()
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ: {str(e)}")
            return f"Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_data.get('store_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}"

def perform_ai_analysis_for_order(order_id: str, store_data: Dict) -> Dict[str, Any]:
    """ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ AI"""
    service = SimpleAIAnalysisService()
    return service.perform_complete_analysis(store_data)
