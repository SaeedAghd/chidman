from django.shortcuts import render, redirect, get_object_or_404
from django.http import JsonResponse, HttpResponse
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib import messages
from django.http import Http404
from django.utils import timezone
from django.core.paginator import Paginator
from django.db.models import Q
from django.template.loader import render_to_string
from django.urls import reverse
from django.views.decorators.csrf import csrf_exempt
from django.core.mail import send_mail
from django.conf import settings
import json
import os
import uuid
from datetime import datetime, timedelta
from decimal import Decimal
from .models import Payment, PaymentLog, ServicePackage, UserSubscription, StoreAnalysis, SupportTicket, FAQService, PageView, SiteStats, DiscountCode, StoreBasicInfo, StoreAnalysisResult, TicketMessage, UserProfile, AnalysisRequest, StoreLayout, StoreTraffic, StoreDesign, StoreSurveillance, StoreProducts, PricingPlan, AIConsultantService, AIConsultantQuestion, AIConsultantSession, AIConsultantPayment, Transaction, Order
from django.contrib.auth.models import User
# Admin views moved to chidmano.admin_dashboard
# from .ai_analysis import StoreAnalysisAI  # ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚ØªØ§Ù‹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
# from .ai_services.advanced_ai_manager import AdvancedAIManager  # ÙØ§ÛŒÙ„ ai_analysis ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
# from .services.faq_service import FAQService
# Admin views moved to chidmano.admin_dashboard
# from .forms import StoreAnalysisForm, ProfessionalStoreAnalysisForm

# Import Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ PDF Ùˆ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
try:
    import jdatetime  # type: ignore
    import arabic_reshaper  # type: ignore
    from bidi.algorithm import get_display  # type: ignore
except ImportError:
    # Fallback Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ·â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ù†ØµØ¨ Ù†ÛŒØ³ØªÙ†Ø¯
    jdatetime = None
    arabic_reshaper = None
    get_display = None
from io import BytesIO
from .utils import generate_initial_ai_analysis, color_name_to_hex
from decimal import Decimal
from .ai_analysis_service_simple import SimpleAIAnalysisService

def calculate_analysis_cost(form_data):
    """
    Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù…
    
    Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§ÙØªØªØ§Ø­ÛŒÙ‡:
    - Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡: 2,000,000 ØªÙˆÙ…Ø§Ù†
    - ØªØ®ÙÛŒÙ Ø§ÙØªØªØ§Ø­ÛŒÙ‡: 90% (1,800,000 ØªÙˆÙ…Ø§Ù†)
    - Ù‚ÛŒÙ…Øª Ù†Ù‡Ø§ÛŒÛŒ: 200,000 ØªÙˆÙ…Ø§Ù†
    """
    try:
        # ğŸ’° Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡: 2 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†
        base_cost = Decimal('2000000')
        
        # ÙØ¹Ù„Ø§Ù‹ Ø¨Ø¯ÙˆÙ† Ù‡Ø²ÛŒÙ†Ù‡ Ø§Ø¶Ø§ÙÛŒ - Ù‡Ù…Ù‡ Ú†ÛŒØ² flat rate
        additional_cost = Decimal('0')
        
        total = base_cost + additional_cost
        
        # ğŸ‰ ØªØ®ÙÛŒÙ Ø§ÙØªØªØ§Ø­ÛŒÙ‡: 90%
        from datetime import datetime
        current_date = datetime.now()
        launch_end_date = datetime(2025, 12, 31)  # ØªØ§ Ù¾Ø§ÛŒØ§Ù† Ø³Ø§Ù„ 2025
        
        discount = Decimal('0')
        discount_percentage = 0
        
        if current_date <= launch_end_date:
            # ØªØ®ÙÛŒÙ 90% Ø§ÙØªØªØ§Ø­ÛŒÙ‡
            discount_percentage = 90
            discount = total * Decimal('0.90')  # 1,800,000 ØªÙˆÙ…Ø§Ù† ØªØ®ÙÛŒÙ
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚ÛŒÙ…Øª Ù†Ù‡Ø§ÛŒÛŒ
        final = total - discount  # 200,000 ØªÙˆÙ…Ø§Ù†
        
        return {
            'base': float(base_cost),  # 2,000,000
            'additional': float(additional_cost),  # 0
            'total': float(total),  # 2,000,000
            'discount': float(discount),  # 1,800,000
            'discount_percentage': discount_percentage,  # 90
            'final': float(final),  # 200,000
            'breakdown': [
                {
                    'item': 'ğŸ’ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ AI',
                    'amount': base_cost,
                    'description': 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡'
                }
            ]
        }
        
    except Exception as e:
        logger.error(f"Error calculating analysis cost: {str(e)}")
        # Fallback Ø¨Ù‡ Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡
        return {
            'base': 2000000.0,
            'additional': 0.0,
            'total': 2000000.0,
            'discount': 1800000.0,
            'discount_percentage': 90,
            'final': 200000.0,
            'breakdown': [
                {
                    'item': 'ğŸ’ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ AI',
                    'amount': 2000000.0,
                    'description': 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ'
                }
            ]
        }

def create_discount_notification():
    """Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø·Ù„Ø§Ø¹ÛŒÙ‡ ØªØ®ÙÛŒÙ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…"""
    try:
        from .models import DiscountNotification, SystemSettings
        from django.utils import timezone
        from datetime import timedelta
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ®ÙÛŒÙ
        opening_discount = int(SystemSettings.get_setting('opening_discount_percentage', '100'))
        seasonal_discount = int(SystemSettings.get_setting('seasonal_discount_percentage', '0'))
        nowruz_discount = int(SystemSettings.get_setting('nowruz_discount_percentage', '0'))
        
        # ØªØ¹ÛŒÛŒÙ† ØªØ®ÙÛŒÙ ÙØ¹Ø§Ù„
        active_discount = 0
        discount_type = 'opening'
        
        if opening_discount > 0:
            active_discount = opening_discount
            discount_type = 'opening'
        elif seasonal_discount > 0:
            active_discount = seasonal_discount
            discount_type = 'seasonal'
        elif nowruz_discount > 0:
            active_discount = nowruz_discount
            discount_type = 'nowruz'
        
        if active_discount > 0:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø§Ø·Ù„Ø§Ø¹ÛŒÙ‡ ÙØ¹Ø§Ù„
            existing_notification = DiscountNotification.objects.filter(
                discount_type=discount_type,
                is_active=True
            ).first()
            
            if not existing_notification:
                # Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø·Ù„Ø§Ø¹ÛŒÙ‡ Ø¬Ø¯ÛŒØ¯
                now = timezone.now()
                end_date = now + timedelta(days=30)  # 30 Ø±ÙˆØ² Ø§Ø¹ØªØ¨Ø§Ø±
                
                title = f"ØªØ®ÙÛŒÙ ÙˆÛŒÚ˜Ù‡ {active_discount}%"
                message = f"ğŸ‰ ÙØ±ØµØª Ø·Ù„Ø§ÛŒÛŒ! ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§ Ø¨Ø§ ØªØ®ÙÛŒÙ {active_discount}% Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª. Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ø³ÙØ§Ø±Ø´ Ø¯Ù‡ÛŒØ¯!"
                
                DiscountNotification.objects.create(
                    title=title,
                    message=message,
                    discount_percentage=active_discount,
                    discount_type=discount_type,
                    is_active=True,
                    start_date=now,
                    end_date=end_date
                )
                
                logger.info(f"Created discount notification: {active_discount}% {discount_type}")
        
    except Exception as e:
        logger.error(f"Error creating discount notification: {e}")

def get_discount_context():
    """Ø¯Ø±ÛŒØ§ÙØª context ØªØ®ÙÛŒÙ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± ØµÙØ­Ø§Øª"""
    try:
        from .models import DiscountNotification
        
        current_discount = DiscountNotification.get_current_discount()
        
        if current_discount:
            return {
                'has_discount': True,
                'discount_percentage': current_discount.discount_percentage,
                'discount_title': current_discount.title,
                'discount_message': current_discount.message,
                'discount_type': current_discount.discount_type,
                'discount_end_date': current_discount.end_date
            }
        else:
            return {
                'has_discount': False,
                'discount_percentage': 0,
                'discount_title': '',
                'discount_message': '',
                'discount_type': 'none',
                'discount_end_date': None
            }
            
    except Exception as e:
        logger.error(f"Error getting discount context: {e}")
        return {
            'has_discount': False,
            'discount_percentage': 0,
            'discount_title': '',
            'discount_message': '',
            'discount_type': 'none',
            'discount_end_date': None
        }

# Ø§ÛŒÙ† ÙØ§Ù†Ú©Ø´Ù† Ø¯ÛŒÚ¯Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ - Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¯Ø± calculate_analysis_cost Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡
def calculate_analysis_cost_OLD_DATABASE_VERSION(analysis):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ StoreAnalysis object - Ù†Ø³Ø®Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ Ú©Ù‡ Ø§Ø² database Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ø±Ø¯"""
    try:
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‚ÛŒÙ…Øª Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        from .models import SystemSettings
        
        # Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª
        base_price_simple = Decimal(SystemSettings.get_setting('price_simple_analysis', '200000'))
        base_price_medium = Decimal(SystemSettings.get_setting('price_medium_analysis', '350000'))
        base_price_complex = Decimal(SystemSettings.get_setting('price_complex_analysis', '500000'))
        
        # Ù‡Ø²ÛŒÙ†Ù‡ Ù¾Ø§ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„
        analysis_type = getattr(analysis, 'analysis_type', 'medium')
        if analysis_type == 'simple':
            base_cost = base_price_simple
        elif analysis_type == 'complex' or analysis_type == 'advanced':
            base_cost = base_price_complex
        else:
            base_cost = base_price_medium
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² analysis_data
        analysis_data = analysis.analysis_data or {}
        
        additional_cost = Decimal('0')
        
        if analysis_data:
            # Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            store_type = analysis_data.get('store_type', '')
            if 'Ù¾ÙˆØ´Ø§Ú©' in store_type:
                additional_cost += Decimal('100000')
            elif 'Ù…ÙˆØ§Ø¯ ØºØ°Ø§ÛŒÛŒ' in store_type:
                additional_cost += Decimal('80000')
            elif 'Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©' in store_type:
                additional_cost += Decimal('150000')
            
            # Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            store_size_str = analysis_data.get('store_size', '0')
            try:
                store_size = int(store_size_str)
            except (ValueError, TypeError):
                # Ø§Ú¯Ø± store_size Ø±Ø´ØªÙ‡ Ø§Ø³ØªØŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†
                size_mapping = {
                    'small': 50,
                    'medium': 150,
                    'large': 300,
                    'very_large': 500
                }
                store_size = size_mapping.get(store_size_str.lower(), 100)
            
            if store_size > 1000:
                    additional_cost += Decimal('200000')
            elif store_size > 500:
                    additional_cost += Decimal('100000')
            elif store_size > 200:
                    additional_cost += Decimal('50000')
        
        # Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        if hasattr(analysis, 'analysis_type') and analysis.analysis_type == 'advanced':
            additional_cost += Decimal('200000')
        
        # Ù‡Ø²ÛŒÙ†Ù‡ Ú¯Ø²Ø§Ø±Ø´ PDF (Ù‡Ù…ÛŒØ´Ù‡ Ø´Ø§Ù…Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        additional_cost += Decimal('200000')
        
        total_cost = base_cost + additional_cost
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ®ÙÛŒÙ Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…
        discount_percentage = 0
        
        # ØªØ®ÙÛŒÙ Ø§ÙØªØªØ§Ø­ÛŒÙ‡
        opening_discount = int(SystemSettings.get_setting('opening_discount_percentage', '100'))
        if opening_discount > 0:
            discount_percentage = opening_discount
        
        # ØªØ®ÙÛŒÙ ÙØµÙ„ÛŒ
        seasonal_discount = int(SystemSettings.get_setting('seasonal_discount_percentage', '0'))
        if seasonal_discount > discount_percentage:
            discount_percentage = seasonal_discount
        
        # ØªØ®ÙÛŒÙ Ù†ÙˆØ±ÙˆØ²ÛŒ
        nowruz_discount = int(SystemSettings.get_setting('nowruz_discount_percentage', '0'))
        if nowruz_discount > discount_percentage:
            discount_percentage = nowruz_discount
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¨Ù„Øº ØªØ®ÙÛŒÙ
        discount_amount = (total_cost * discount_percentage) / 100
        final_cost = total_cost - discount_amount
        
        # Ø³Ø§Ø®Øª breakdown
        breakdown = [
            {
                'item': 'ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡',
                'amount': base_cost,
                'description': 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
            },
            {
                'item': 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ PDF',
                'amount': Decimal('200000'),
                'description': 'Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
            }
        ]
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if additional_cost > 0:
            breakdown.append({
                'item': 'ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ',
                'amount': additional_cost,
                'description': 'ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ ØªØ®ØµØµÛŒ'
            })
        
        return {
            'base_price': base_cost,
            'total': total_cost,
            'final': final_cost,
            'discount': discount_amount,
            'discount_percentage': discount_percentage,
            'breakdown': breakdown,
            'discount_type': 'opening' if opening_discount > 0 else 'seasonal' if seasonal_discount > 0 else 'nowruz' if nowruz_discount > 0 else 'none'
        }
        
    except Exception as e:
        logger.error(f"Error calculating analysis cost: {e}")
        # Ù‡Ø²ÛŒÙ†Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        return {
            'base_price': Decimal('500000'),
            'total': Decimal('500000'),
            'final': Decimal('500000'),
            'discount': Decimal('0'),
            'discount_percentage': 0,
            'breakdown': [
                {
                    'item': 'ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡',
                    'amount': Decimal('500000'),
                    'description': 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
                }
            ]
        }

def generate_free_initial_analysis(analysis):
    """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù†"""
    try:
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        basic_info = StoreBasicInfo.objects.filter(analysis=analysis).first()
        
        if not basic_info:
            return {
                'error': 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯',
                'recommendations': []
            }
        
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯
        recommendations = []
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if basic_info.store_type:
            if 'Ù¾ÙˆØ´Ø§Ú©' in basic_info.store_type:
                recommendations.extend([
                    'Ú†ÛŒØ¯Ù…Ø§Ù† Ù¾ÙˆØ´Ø§Ú© Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØµÙ„ Ùˆ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§Ø´Ø¯',
                    'Ø±Ø§Ù‡Ø±ÙˆÙ‡Ø§ÛŒ Ø¹Ø±ÛŒØ¶ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ø­ØªÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª',
                    'Ø¢ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø¨Ø±Ø§ÛŒ Ø§Ù…ØªØ­Ø§Ù† Ù„Ø¨Ø§Ø³ Ù…Ù‡Ù… Ø§Ø³Øª'
                ])
            elif 'Ù…ÙˆØ§Ø¯ ØºØ°Ø§ÛŒÛŒ' in basic_info.store_type:
                recommendations.extend([
                    'Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØ§Ø²Ù‡ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø¯ÛŒØ¯ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯',
                    'Ø±Ø§Ù‡Ø±ÙˆÙ‡Ø§ÛŒ Ø¨Ø§Ø±ÛŒÚ© Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª',
                    'Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯'
                ])
            elif 'Ø§Ù„Ú©ØªØ±ÙˆÙ†ÛŒÚ©' in basic_info.store_type:
                recommendations.extend([
                    'Ù…Ø­ØµÙˆÙ„Ø§Øª Ú¯Ø±Ø§Ù†â€ŒÙ‚ÛŒÙ…Øª Ø¯Ø± ÙˆÛŒØªØ±ÛŒÙ† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯',
                    'ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø­ØµÙˆÙ„Ø§Øª ÙØ±Ø§Ù‡Ù… Ú©Ù†ÛŒØ¯',
                    'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª'
                ])
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        if basic_info.store_size:
            if basic_info.store_size < 50:
                recommendations.append('ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ú©ÙˆÚ†Ú©: Ø§Ø² ÙØ¶Ø§ÛŒ Ø¹Ù…ÙˆØ¯ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯')
            elif basic_info.store_size > 200:
                recommendations.append('ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø²Ø±Ú¯: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ ØªØ§Ø¨Ù„ÙˆÙ‡Ø§')
        
        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ÙˆÙ‚Ø¹ÛŒØª
        if basic_info.location:
            if 'Ù…Ø±Ú©Ø² Ø´Ù‡Ø±' in basic_info.location:
                recommendations.append('Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ø±Ú©Ø²ÛŒ: Ø§Ø² ØªØ±Ø§ÙÛŒÚ© Ø¨Ø§Ù„Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯')
            elif 'Ø­ÙˆÙ…Ù‡' in basic_info.location:
                recommendations.append('Ù…ÙˆÙ‚Ø¹ÛŒØª Ø­ÙˆÙ…Ù‡: Ù¾Ø§Ø±Ú©ÛŒÙ†Ú¯ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯')
        
        return {
            'store_name': basic_info.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§',
            'store_type': basic_info.store_type or 'Ù†Ø§Ù…Ø´Ø®Øµ',
            'store_size': basic_info.store_size or 0,
            'location': basic_info.location or 'Ù†Ø§Ù…Ø´Ø®Øµ',
            'recommendations': recommendations[:5],  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 ØªÙˆØµÛŒÙ‡
            'analysis_date': timezone.now(),
            'is_free': True
        }
        
    except Exception as e:
        logger.error(f"Error generating free analysis: {e}")
        return {
            'error': 'Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„',
            'recommendations': [
                'Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ØŒ Ù„Ø·ÙØ§Ù‹ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯',
                'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³Øª'
            ]
        }
# from .services.ai_consultant_service import AIConsultantService
import logging

# Setup logger
logger = logging.getLogger(__name__)


def ensure_basic_analysis_results(analysis: StoreAnalysis) -> None:
    """Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ ÛŒØ§ Ù…Ø¹Ù„Ù‚ØŒ Ù†ØªÛŒØ¬Ù‡ Ù¾Ø§ÛŒÙ‡ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        needs_generation = (
            analysis.status in ['pending', 'processing', 'paid'] and
            (not analysis.results or not analysis.results.get('analysis_text'))
        )

        if not needs_generation:
            return

        logger.info(
            "âš ï¸ Analysis %s Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª %s Ø¨Ø¯ÙˆÙ† Ù†ØªÛŒØ¬Ù‡ Ù…Ø§Ù†Ø¯Ù‡ Ø§Ø³ØªØ› ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ fallback Ø´Ø±ÙˆØ¹ Ø´Ø¯.",
            analysis.id,
            analysis.status
        )

        service = SimpleAIAnalysisService()
        base_data = analysis.analysis_data.copy() if isinstance(analysis.analysis_data, dict) else {}

        base_data.setdefault('store_name', analysis.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§')
        base_data.setdefault('store_type', analysis.store_type or 'Ø¹Ù…ÙˆÙ…ÛŒ')
        base_data.setdefault('store_size', analysis.store_size or '0')
        base_data.setdefault('daily_customers', base_data.get('daily_customers', 80))
        base_data.setdefault('peak_hours', base_data.get('peak_hours', '10-12, 18-20'))
        base_data.setdefault('product_categories', base_data.get('product_categories', ['Ù…ÙˆØ§Ø¯ ØºØ°Ø§ÛŒÛŒ', 'Ù†ÙˆØ´ÛŒØ¯Ù†ÛŒ']))

        fallback = service.analyze_store(base_data)

        summary_text = fallback.get('summary') or fallback.get('analysis_text') or 'ØªØ­Ù„ÛŒÙ„ Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§ Ø«Ø¨Øª Ø´Ø¯.'
        overall_score = fallback.get('overall_score', 72)
        confidence = fallback.get('confidence', 0.68)
        predictions = fallback.get('predictions', {}) or {}
        recommendations = fallback.get('recommendations', {})

        analysis.results = {
            'report_type': analysis.package_type or 'basic',
            'analysis_text': summary_text,
            'overall_score': overall_score,
            'quality_score': overall_score,
            'confidence_score': confidence if confidence <= 1 else confidence / 100,
            'ai_provider': fallback.get('status', 'fallback'),
            'source': 'fallback',
            'key_findings': fallback.get('key_findings', []),
            'recommendations': recommendations if isinstance(recommendations, list) else recommendations,
            'strategic_recommendations': fallback.get('strategic_recommendations', []),
            'executive_summary': {
                'summary': summary_text,
                'paragraphs': [summary_text],
                'key_metrics': {
                    'projected_sales': predictions.get('expected_sales_increase', '+15%'),
                    'roi_estimate': predictions.get('roi', '6 Ù…Ø§Ù‡'),
                    'current_sales': base_data.get('current_sales', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                    'customer_conversion_rate': predictions.get('conversion_rate', '12%')
                }
            },
            'ai_models_used': ['SimpleAIAnalysisService'],
        }

        analysis.status = 'completed'
        analysis.completed_at = timezone.now()
        analysis.updated_at = timezone.now()
        analysis.save(update_fields=['results', 'status', 'completed_at', 'updated_at'])

        logger.info("âœ… Ú¯Ø²Ø§Ø±Ø´ fallback Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s ØªÙˆÙ„ÛŒØ¯ Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ completed ØªØºÛŒÛŒØ± ÛŒØ§ÙØª.", analysis.id)

    except Exception:
        logger.error(
            "âŒ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ fallback Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ %s Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯.",
            analysis.id,
            exc_info=True
        )
def serialize_analysis_result(result_object):
    """Convert complex analysis result objects to a JSON-serializable dict."""
    try:
        if isinstance(result_object, dict):
            return result_object
        
        # Ø§Ú¯Ø± object Ø§Ø³ØªØŒ Ø³Ø¹ÛŒ Ú©Ù† Ø¢Ù† Ø±Ø§ Ø¨Ù‡ dict ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†
        if hasattr(result_object, '__dict__'):
            result_dict = {}
            for key, value in result_object.__dict__.items():
                if not key.startswith('_'):
                    if isinstance(value, (str, int, float, bool, type(None))):
                        result_dict[key] = value
                    elif isinstance(value, list):
                        result_dict[key] = [serialize_analysis_result(item) for item in value]
                    elif isinstance(value, dict):
                        result_dict[key] = {k: serialize_analysis_result(v) for k, v in value.items()}
                    else:
                        result_dict[key] = str(value)
            return result_dict
        
        # Ø§Ú¯Ø± dataclass Ø§Ø³Øª
        try:
            import dataclasses
            if dataclasses.is_dataclass(result_object):
                return dataclasses.asdict(result_object)
        except Exception:
            pass
        
        # Ø§Ú¯Ø± to_dict method Ø¯Ø§Ø±Ø¯
        if hasattr(result_object, 'to_dict') and callable(getattr(result_object, 'to_dict')):
            return result_object.to_dict()
        
        # Ø¢Ø®Ø±ÛŒÙ† ØªÙ„Ø§Ø´: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string
        return {
            'analysis_text': str(result_object),
            'overall_score': 75,
            'strengths': ['ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª'],
            'weaknesses': ['Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¨ÛŒØ´ØªØ±'],
            'recommendations': ['Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯'],
            'serialization_method': 'string_fallback'
        }
        
    except Exception as e:
        logger.error(f"Serialization of analysis result failed: {e}")
        return {
            'analysis_text': 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ - Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯',
            'overall_score': 50,
            'strengths': [],
            'weaknesses': ['Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´'],
            'recommendations': ['ØªÙ…Ø§Ø³ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ'],
            'error': 'serialization_failed',
            'error_message': str(e)
        }
# --- ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ ---

def index(request):
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ - ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
    context = {}
    
    # Ø¯Ø±ÛŒØ§ÙØª ØªØ¨Ù„ÛŒØºØ§Øª ÙØ¹Ø§Ù„ (Ø§Ú¯Ø± Ù…Ø¯Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
    try:
        from .models import PromotionalBanner
        active_banners = PromotionalBanner.objects.filter(
            is_active=True,
            start_date__lte=timezone.now(),
            end_date__gte=timezone.now()
        ).order_by('-created_at')
    except ImportError:
        # Ø§Ú¯Ø± Ù…Ø¯Ù„ PromotionalBanner ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
        active_banners = []
    
    context['active_banners'] = active_banners
    
    if request.user.is_authenticated:
        # Ø¢Ù…Ø§Ø± Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù‡ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ contact_phone
        from django.db import connection
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT 
                    COUNT(*) as total,
                    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
                    SUM(CASE WHEN status = 'processing' THEN 1 ELSE 0 END) as processing,
                    SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) as pending
                FROM store_analysis_storeanalysis
                WHERE user_id = %s
            """, [request.user.id])
            row = cursor.fetchone()
            context.update({
                'total_analyses': row[0] if row else 0,
                'completed_analyses': row[1] if row else 0,
                'processing_analyses': row[2] if row else 0,
                'pending_analyses': row[3] if row else 0,
            })
    
    return render(request, 'chidmano/landing.html', context)

def problem_detection(request):
    """ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ AI"""
    if request.method == 'POST':
        # Ø¯Ø±ÛŒØ§ÙØª ØªØµØ§ÙˆÛŒØ± Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        # form = ProfessionalStoreAnalysisForm(request.POST, request.FILES)
        if form.is_valid():
            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡
            analysis = StoreAnalysis.objects.create(
                user=request.user if request.user.is_authenticated else None,
                analysis_type='problem_detection',
                store_name=form.cleaned_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¬Ø¯ÛŒØ¯'),
                status='processing',
                results='',
                error_message='',
                priority='high',
                estimated_duration=10
            )
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            analysis.set_analysis_data(form.cleaned_data)
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ AI
            ai_analyzer = StoreAnalysisAI()
            problems = ai_analyzer.detect_store_problems(form.cleaned_data)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
            analysis.preliminary_analysis = json.dumps(problems, ensure_ascii=False)
            analysis.status = 'preliminary_completed'
            analysis.save()
            
            return redirect('store_analysis:smart_recommendations', pk=analysis.pk)
    else:
        # form = ProfessionalStoreAnalysisForm()
        pass
        form = None
    
    context = {
        'form': None,
        'step': 'problem_detection'
    }
    return render(request, 'store_analysis/problem_detection.html', context)

def smart_recommendations(request, pk):
    """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø±Ø§Ù‡Ú©Ø§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        recommendations = ai_analyzer.generate_smart_recommendations(analysis_data)
        layout_suggestions = ai_analyzer.generate_layout_suggestions(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
        analysis.set_analysis_data({
            **analysis_data,
            'recommendations': recommendations,
            'layout_suggestions': layout_suggestions
        })
        
        return redirect('store_analysis:visual_simulation', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'smart_recommendations'
    }
    return render(request, 'store_analysis/smart_recommendations.html', context)

def visual_simulation(request, pk):
    """Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨ØµØ±ÛŒ 2D/3D"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        simulation_2d = ai_analyzer.generate_2d_simulation(analysis_data)
        simulation_3d = ai_analyzer.generate_3d_simulation(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§
        analysis.set_analysis_data({
            **analysis_data,
            'simulation_2d': simulation_2d,
            'simulation_3d': simulation_3d
        })
        
        return redirect('store_analysis:detailed_report', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'visual_simulation'
    }
    return render(request, 'store_analysis/visual_simulation.html', context)

def detailed_report(request, pk):
    """Ú¯Ø²Ø§Ø±Ø´ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ø¢ÛŒÙ†Ø¯Ù‡â€ŒÙ†Ú¯Ø±"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        detailed_report = ai_analyzer.generate_detailed_report(analysis_data)
        forecast = ai_analyzer.generate_forecast(analysis_data)
        dashboard_data = ai_analyzer.generate_dashboard_data(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´
        analysis.set_analysis_data({
            **analysis_data,
            'detailed_report': detailed_report,
            'forecast': forecast,
            'dashboard_data': dashboard_data
        })
        
        return redirect('store_analysis:inspiration_library', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'detailed_report'
    }
    return render(request, 'store_analysis/detailed_report.html', context)

def inspiration_library(request, pk):
    """Ø§Ù„Ù‡Ø§Ù… Ùˆ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ - Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        inspiration_examples = ai_analyzer.generate_inspiration_examples(analysis_data)
        similar_stores = ai_analyzer.find_similar_stores(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
        analysis.set_analysis_data({
            **analysis_data,
            'inspiration_examples': inspiration_examples,
            'similar_stores': similar_stores
        })
        
        return redirect('store_analysis:virtual_consultant', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'inspiration_library'
    }
    return render(request, 'store_analysis/inspiration_library.html', context)

def virtual_consultant(request, pk):
    """Ù…Ø´Ø§ÙˆØ± Ø¢Ù†Ù„Ø§ÛŒÙ† Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ù…Ø´Ø§ÙˆØ±Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        consultation = ai_analyzer.generate_virtual_consultation(analysis_data)
        qa_system = ai_analyzer.generate_qa_system(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø´Ø§ÙˆØ±Ù‡
        analysis.set_analysis_data({
            **analysis_data,
            'consultation': consultation,
            'qa_system': qa_system
        })
        
        return redirect('store_analysis:implementation_guide', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'virtual_consultant'
    }
    return render(request, 'store_analysis/virtual_consultant.html', context)

def implementation_guide(request, pk):
    """Ø§Ù…Ú©Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª - Ø®Ø±ÙˆØ¬ÛŒ ÙÙ†ÛŒ"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    if request.method == 'POST':
        # ØªÙˆÙ„ÛŒØ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø¬Ø±Ø§
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        implementation_guide = ai_analyzer.generate_implementation_guide(analysis_data)
        technical_specs = ai_analyzer.generate_technical_specifications(analysis_data)
        supplier_connections = ai_analyzer.generate_supplier_connections(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§
        analysis.set_analysis_data({
            **analysis_data,
            'implementation_guide': implementation_guide,
            'technical_specs': technical_specs,
            'supplier_connections': supplier_connections
        })
        
        # ØªÚ©Ù…ÛŒÙ„ ØªØ­Ù„ÛŒÙ„
        analysis.status = 'completed'
        analysis.save()
        
        messages.success(request, 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!')
        return redirect('store_analysis:analysis_results', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'step': 'implementation_guide'
    }
    return render(request, 'store_analysis/implementation_guide.html', context)

def education_library(request):
    """Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ"""
    category = request.GET.get('category', '')
    
    # ØªØ¹Ø±ÛŒÙ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    categories = {
        'ai-analysis': {
            'title': 'ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'articles': [
                {'title': 'Ù…Ù‚Ø¯Ù…Ù‡â€ŒØ§ÛŒ Ø¨Ø± ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'slug': 'ai-introduction'},
                {'title': 'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ AI', 'slug': 'advanced-ai-algorithms'},
                {'title': 'Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ AI Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'slug': 'ai-practical-applications'},
            ]
        },
        'traffic-analysis': {
            'title': 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ©',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†',
            'articles': [
                {'title': 'Ø§ØµÙˆÙ„ ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'slug': 'traffic-analysis-basics'},
                {'title': 'Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†', 'slug': 'customer-movement-patterns'},
                {'title': 'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'slug': 'store-path-optimization'},
            ]
        },
        'layout-optimization': {
            'title': 'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'articles': [
                {'title': 'Ø§ØµÙˆÙ„ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡', 'slug': 'color-psychology'},
                {'title': 'Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ù‡ÛŒÙ†Ù‡', 'slug': 'optimal-layout-design'},
                {'title': 'ØªØ§Ø«ÛŒØ± Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ø± ÙØ±ÙˆØ´', 'slug': 'layout-sales-impact'},
            ]
        },
        'reports': {
            'title': 'Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ',
            'articles': [
                {'title': 'Ù†Ø­ÙˆÙ‡ Ø®ÙˆØ§Ù†Ø¯Ù† Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ', 'slug': 'reading-analytical-reports'},
                {'title': 'ØªÙØ³ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´', 'slug': 'sales-data-interpretation'},
                {'title': 'ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§', 'slug': 'decision-making-reports'},
            ]
        },
        'predictions': {
            'title': 'Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±ÙˆØ´',
            'articles': [
                {'title': 'Ø§ØµÙˆÙ„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±ÙˆØ´', 'slug': 'sales-prediction-basics'},
                {'title': 'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ', 'slug': 'prediction-algorithms'},
                {'title': 'Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ø¯Ù‡â€ŒÙ†Ú¯Ø±', 'slug': 'future-strategies'},
            ]
        },
        'auto-optimization': {
            'title': 'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±',
            'description': 'Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±',
            'articles': [
                {'title': 'Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±', 'slug': 'auto-optimization-systems'},
                {'title': 'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†', 'slug': 'machine-learning-algorithms'},
                {'title': 'Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø³ØªÙ…Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯', 'slug': 'continuous-improvement'},
            ]
        }
    }
    
    context = {
        'category': category,
        'category_data': categories.get(category, {}),
        'all_categories': categories,
    }
    
    return render(request, 'store_analysis/education.html', context)

def features(request):
    """ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
    return render(request, 'store_analysis/features.html')

def article_detail(request, slug):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ù‚Ø§Ù„Ù‡"""
    # Ø§ÛŒÙ† view Ø¨Ø¹Ø¯Ø§Ù‹ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    return render(request, 'store_analysis/article_detail.html', {'slug': slug})



# --- ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ ---

@login_required
def analysis_list(request):
    """Ù„ÛŒØ³Øª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§"""
    # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ ØªÙ…Ø§Ù… ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡
    if request.user.is_staff or request.user.is_superuser:
        analyses = StoreAnalysis.objects.all().order_by('-created_at')
    else:
        analyses = StoreAnalysis.objects.filter(user=request.user).order_by('-created_at')
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
    for analysis in analyses:
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù¾ÛŒØ´Ø±ÙØª
        if analysis.status == 'completed':
            analysis.progress = 100
        elif analysis.status == 'processing':
            analysis.progress = 75
        elif analysis.status == 'pending':
            analysis.progress = 25
        else:
            analysis.progress = 0
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù¾ÛŒØ´â€ŒØªØ­Ù„ÛŒÙ„ (Ø¨Ù‡ ØµÙˆØ±Øª Ù…ØªØºÛŒØ± Ù…ÙˆÙ‚Øª)
        analysis.has_preliminary_temp = bool(analysis.results or analysis.preliminary_analysis)
    
    paginator = Paginator(analyses, 10)
    page = request.GET.get('page')
    analyses = paginator.get_page(page)
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ù„Ù† Ùˆ Ù¾Ø±Ø¯Ø§Ø®Øª
    def is_paid(a):
        try:
            return a.package_type in ['professional', 'enterprise'] and a.status in ['paid', 'completed'] and bool(a.results)
        except Exception:
            return False

    free_plan = [a for a in analyses if a.package_type in [None, '', 'basic', 'free']]
    professional_plan = [a for a in analyses if a.package_type == 'professional']
    enterprise_plan = [a for a in analyses if a.package_type == 'enterprise']
    
    context = {
        'analyses': analyses,
        'free_plan': free_plan,
        'professional_plan': professional_plan,
        'enterprise_plan': enterprise_plan,
        'is_admin': request.user.is_staff or request.user.is_superuser,
        'total_analyses': len(analyses),
    }
    return render(request, 'store_analysis/analysis_list.html', context)

@login_required
def delete_incomplete_analyses(request):
    """Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯."""
    try:
        from django.db import transaction
        
        queryset = StoreAnalysis.objects.all()
        if not (request.user.is_staff or request.user.is_superuser):
            queryset = queryset.filter(user=request.user)
        
        incomplete_analyses = list(queryset.filter(status__in=['pending', 'failed']))
        actual_count = 0
        
        # Ø­Ø°Ù Ù‡Ø± ØªØ­Ù„ÛŒÙ„ Ø¯Ø± ÛŒÚ© transaction Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        for analysis in incomplete_analyses:
            try:
                with transaction.atomic():
                    # 1. Ø­Ø°Ù Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú†Øª Ù…Ø±ØªØ¨Ø· (Ø§Ø² Ø·Ø±ÛŒÙ‚ session)
                    try:
                        from .models import ChatMessage, ChatSession
                        chat_sessions = ChatSession.objects.filter(store_analysis=analysis)
                        for session in chat_sessions:
                            ChatMessage.objects.filter(session=session).delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting chat messages for {analysis.id}: {e}")
                    
                    # 2. Ø­Ø°Ù ChatSession
                    try:
                        from .models import ChatSession
                        ChatSession.objects.filter(store_analysis=analysis).delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting chat sessions for {analysis.id}: {e}")
                    
                    # 3. Ø­Ø°Ù AnalysisRequest (Ø§Ú¯Ø± ÙÛŒÙ„Ø¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
                    try:
                        from .models import AnalysisRequest
                        from django.db import connection
                        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ† Ø¨Ø§ raw SQL
                        with connection.cursor() as cursor:
                            cursor.execute("""
                                SELECT column_name 
                                FROM information_schema.columns 
                                WHERE table_name='store_analysis_analysisrequest' 
                                AND column_name='store_analysis_id'
                            """)
                            if cursor.fetchone():
                                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù
                                cursor.execute("""
                                    DELETE FROM store_analysis_analysisrequest 
                                    WHERE store_analysis_id = %s
                                """, [analysis.id])
                                logger.info(f"âœ… AnalysisRequests deleted for analysis {analysis.id}")
                            else:
                                logger.debug(f"âš ï¸ store_analysis_id column does not exist in AnalysisRequest table")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting analysis requests for {analysis.id}: {e}")
                    
                    # 4. Ø­Ø°Ù StoreAnalysisResult
                    try:
                        from .models import StoreAnalysisResult
                        StoreAnalysisResult.objects.filter(store_analysis=analysis).delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting analysis results for {analysis.id}: {e}")
                    
                    # 5. Ø­Ø°Ù ReviewReminder
                    try:
                        from .models import ReviewReminder
                        ReviewReminder.objects.filter(analysis=analysis).delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting review reminders for {analysis.id}: {e}")
                    
                    # 6. SupportTicket ÙÛŒÙ„Ø¯ store_analysis Ù†Ø¯Ø§Ø±Ø¯ - skip
                    
                    # 7. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Payment (update to null)
                    try:
                        from .models import Payment
                        Payment.objects.filter(store_analysis=analysis).update(store_analysis=None)
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error updating payments for {analysis.id}: {e}")
                    
                    # 8. Ø­Ø°Ù Order
                    try:
                        if hasattr(analysis, 'order') and analysis.order:
                            analysis.order.delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error deleting order for {analysis.id}: {e}")
                    
                    # 9. Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„ (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ§Ø¨Ø· Django)
                    try:
                        from django.db import connection
                        with connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM store_analysis_storeanalysis 
                                WHERE id = %s
                            """, [analysis.id])
                        actual_count += 1
                        logger.info(f"âœ… Incomplete analysis {analysis.id} deleted using raw SQL")
                    except Exception as e:
                        # Ø§Ú¯Ø± raw SQL Ø®Ø·Ø§ Ø¯Ø§Ø¯ØŒ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ø§ ORM Ø­Ø°Ù Ú©Ù†ÛŒÙ…
                        try:
                            analysis.delete()
                            actual_count += 1
                            logger.info(f"âœ… Incomplete analysis {analysis.id} deleted using ORM")
                        except Exception as orm_error:
                            logger.error(f"âŒ Error deleting analysis {analysis.id} with ORM: {orm_error}")
                            raise
                    
            except Exception as e:
                logger.error(f"âŒ Error deleting incomplete analysis {analysis.id}: {e}", exc_info=True)
                # Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø¹Ø¯ÛŒ
                continue
        
        if actual_count > 0:
            messages.success(request, f"âœ… {actual_count} ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‚Øµ Ø­Ø°Ù Ø´Ø¯")
        else:
            messages.info(request, "ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù‚ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
    except Exception as e:
        logger.error(f"âŒ delete_incomplete_analyses error: {e}", exc_info=True)
        messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ: {str(e)}')
    
    return redirect('store_analysis:user_dashboard')
@login_required
def analysis_results(request, pk):
    """Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„"""
    try:
        # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ Ù‡Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
        if request.user.is_staff or request.user.is_superuser:
            analysis = StoreAnalysis.objects.get(pk=pk)
        else:
            # Ú©Ø§Ø±Ø¨Ø± Ø¹Ø§Ø¯ÛŒ ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯
            analysis = StoreAnalysis.objects.get(pk=pk, user=request.user)
    except StoreAnalysis.DoesNotExist:
        from django.http import Http404
        raise Http404("ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯")
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ù…Ù†Ø§Ø³Ø¨
    if analysis.status == 'processing':
        messages.info(request, 'â³ ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ù‡Ø³ØªÛŒÙ…ØŒ ØªØ§ Û³Û° Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯ÛŒÚ¯Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´Ù‡. Ù„Ø·ÙØ§Ù‹ ØµØ¨ÙˆØ± Ø¨Ø§Ø´ÛŒØ¯.')
    elif analysis.status == 'failed':
        messages.warning(request, 'âŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ù…Ø´Ú©Ù„ Ø¨Ø±Ø®ÙˆØ±Ø¯Ù‡. Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ø¯Ø¯ Ø§Ù‚Ø¯Ø§Ù… Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
    elif analysis.status == 'pending':
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡
        has_form_data = analysis.analysis_data and analysis.analysis_data.get('uploaded_files')
        if not has_form_data:
            messages.warning(request, 'ğŸ“ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ù‡Ù†ÙˆØ² ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ±Ù… Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
            return redirect('store_analysis:forms', analysis_id=pk)
    
    # Handle POST requests for AI analysis
    if request.method == 'POST':
        try:
            import json
            data = json.loads(request.body)
            action = data.get('action')
            
            if action == 'reprocess_ollama':
                # Start Ollama processing
                from .tasks import process_analysis_with_ollama
                process_analysis_with_ollama.delay(pk)
                return JsonResponse({'status': 'success', 'message': 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Chidmano2 AI Ø´Ø±ÙˆØ¹ Ø´Ø¯'})
            
            elif action == 'reprocess_liara':
                # Start Liara AI processing
                from .tasks import process_analysis_with_liara
                process_analysis_with_liara.delay(pk)
                return JsonResponse({'status': 'success', 'message': 'ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Chidmano1 AI Ø´Ø±ÙˆØ¹ Ø´Ø¯'})
            
            else:
                return JsonResponse({'status': 'error', 'message': 'Ø¹Ù…Ù„ÛŒØ§Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'})
                
        except Exception as e:
            return JsonResponse({'status': 'error', 'message': f'Ø®Ø·Ø§: {str(e)}'})
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
    ensure_basic_analysis_results(analysis)
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„
    try:
        result = analysis.storeanalysisresult_set.first()
    except:
        result = None
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø§Ø² Ù†ØªØ§ÛŒØ¬ AI
    scores = {}
    if analysis.results and 'executive_summary' in analysis.results:
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ confidence_score
        confidence_score = analysis.results.get('confidence_score', 0.85)
        overall_score = int(confidence_score * 100)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø¬Ø²Ø¦ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        analysis_data = analysis.get_analysis_data() or {}

        def to_float(value, default):
            try:
                if value in [None, '']:
                    return float(default)
                return float(value)
            except (ValueError, TypeError):
                try:
                    mapping = {
                        'small': 300,
                        'medium': 600,
                        'large': 1000,
                        'very_large': 1500
                    }
                    return float(mapping.get(str(value).lower(), default))
                except Exception:
                    return float(default)

        conversion_rate = to_float(analysis_data.get('conversion_rate'), 42.5)
        customer_traffic = to_float(analysis_data.get('customer_traffic'), 180)
        store_size = to_float(analysis_data.get('store_size'), 1200)
        unused_area_size = to_float(analysis_data.get('unused_area_size'), 150)
        
        # Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù† (Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ¶Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ Ùˆ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„)
        layout_score = max(60, 100 - (unused_area_size / store_size * 100) if store_size > 0 else 80)
        layout_score = min(95, layout_score + (conversion_rate - 30) * 0.5)
        
        # Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ø§ÙÛŒÚ© (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù†)
        traffic_score = min(95, max(60, customer_traffic / 10))
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø·Ø±Ø§Ø­ÛŒ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ùˆ ØªØ±Ø§ÙÛŒÚ©)
        design_score = min(95, max(60, conversion_rate * 1.5 + traffic_score * 0.3))
        
        # Ø§Ù…ØªÛŒØ§Ø² ÙØ±ÙˆØ´ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„)
        sales_score = min(95, max(60, conversion_rate * 2))
        
        scores = {
            'overall_score': overall_score,
            'layout_score': int(layout_score),
            'traffic_score': int(traffic_score),
            'design_score': int(design_score),
            'sales_score': int(sales_score)
        }
    else:
        # Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        scores = {
            'overall_score': 75,
            'layout_score': 70,
            'traffic_score': 75,
            'design_score': 80,
            'sales_score': 72
        }
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ
    is_admin = request.user.is_staff or request.user.is_superuser
    show_management_report = False
    
    if is_admin:
        # Ø§Ø¯Ù…ÛŒÙ† Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø±Ø¯
        show_management_report = True
    elif analysis.status == 'completed' and analysis.results:
        # Ú©Ø§Ø±Ø¨Ø± Ø¹Ø§Ø¯ÛŒ ÙˆÙ‚ØªÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ Ùˆ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        show_management_report = True
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù†ØªØ§ÛŒØ¬ AI Ø¯Ø± JSONField
    has_ai_results = analysis.results and 'executive_summary' in analysis.results
    
    # Ø¯Ø±ÛŒØ§ÙØª order Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ analysis
    order = None
    if hasattr(analysis, 'order') and analysis.order:
        order = analysis.order
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ø§ÛŒ ØªÙ…Ù¾Ù„Øª
    analysis_results = analysis.results or {}
    
    # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© object Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ…Ù¾Ù„Øª
    class ResultsObject:
        def __init__(self, analysis_data, scores_data):
            self.analysis_text = analysis_data.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª')
            self.source = analysis_data.get('source', 'manual')
            self.ai_provider = analysis_data.get('ai_provider', 'Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„')
            self.package_type = analysis_data.get('package_type', 'basic')
            self.quality_score = analysis_data.get('quality_score', 0.8)
            self.confidence_score = analysis_data.get('confidence_score', 0.85)
            self.free_plan = analysis_data.get('free_plan', True)
            self.scores = scores_data
    
    results_obj = ResultsObject(analysis_results, scores)
    
    context = {
        'analysis': analysis,
        'store_analysis': analysis,  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ØªØºÛŒØ± store_analysis
        'result': result,
        'results': results_obj,  # object Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ…Ù¾Ù„Øª
        'analysis_results': analysis_results,  # Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø§Ø² JSONField
        'scores': scores,
        'has_ai_results': has_ai_results,
        'show_management_report': show_management_report,
        'is_admin': is_admin,
        'order': order,
        'view_report_url': request.build_absolute_uri(
            reverse('store_analysis:view_analysis_report', kwargs={'pk': analysis.pk})
        ),
        'download_pdf_url': request.build_absolute_uri(
            reverse('store_analysis:download_analysis', kwargs={'pk': analysis.pk})
        ) + '?type=pdf',
    }
    return render(request, 'store_analysis/modern_analysis_results.html', context)

def translate_english_to_persian(value):
    """ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„Ù…Ø§Øª Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
    if value is None:
        return value
    if not isinstance(value, (str, dict, list, int, float, bool)):
        return value
    
    # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ (Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø·ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±)
    translations = {
        # Status and analysis types - long phrases first
        'pending_video_upload': 'Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÛŒØ¯ÛŒÙˆ',
        'zones analysis': 'ØªØ­Ù„ÛŒÙ„ Ù…Ù†Ø§Ø·Ù‚',
        'shelf analysis': 'ØªØ­Ù„ÛŒÙ„ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§',
        'density analysis': 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§Ú©Ù…',
        'customer visibility': 'Ù‚Ø§Ø¨Ù„ÛŒØª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…Ø´ØªØ±ÛŒ',
        'checkout analysis': 'ØªØ­Ù„ÛŒÙ„ ØµÙ†Ø¯ÙˆÙ‚',
        'queue analysis': 'ØªØ­Ù„ÛŒÙ„ ØµÙ',
        'lighting analysis': 'ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ',
        'color psychology': 'Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯',
        'unused spaces': 'ÙØ¶Ø§Ù‡Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡',
        'video analysis': 'ØªØ­Ù„ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ',
        'movement patterns': 'Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø­Ø±Ú©Øª',
        'interaction points': 'Ù†Ù‚Ø§Ø· ØªØ¹Ø§Ù…Ù„',
        'ux analysis': 'ØªØ­Ù„ÛŒÙ„ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ',
        'movement path': 'Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª',
        'Layout Score': 'Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†',
        
        # Status values
        'simulation': 'Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ',
        'Very High': 'Ø®ÛŒÙ„ÛŒ Ø¨Ø§Ù„Ø§',
        'High': 'Ø¨Ø§Ù„Ø§',
        'Medium': 'Ù…ØªÙˆØ³Ø·',
        'Low': 'Ù¾Ø§ÛŒÛŒÙ†',
        'Critical': 'Ø¨Ø­Ø±Ø§Ù†ÛŒ',
        'Good': 'Ø®ÙˆØ¨',
        
        # Metrics - long keys first
        'current_density': 'ØªØ±Ø§Ú©Ù… ÙØ¹Ù„ÛŒ',
        'optimal_density': 'ØªØ±Ø§Ú©Ù… Ø¨Ù‡ÛŒÙ†Ù‡',
        'current_layout': 'Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ¹Ù„ÛŒ',
        'proposed_layout': 'Ú†ÛŒØ¯Ù…Ø§Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ',
        'product_visibility_rate': 'Ù†Ø±Ø® Ù‚Ø§Ø¨Ù„ÛŒØª Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…Ø­ØµÙˆÙ„',
        'average_wait_time': 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±',
        'peak_wait_time': 'Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ù¾ÛŒÚ©',
        'current_lighting': 'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ÙØ¹Ù„ÛŒ',
        'current_lighting_level': 'Ø³Ø·Ø­ Ù†ÙˆØ± ÙØ¹Ù„ÛŒ',
        'lux_measurement': 'Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù„ÙˆÚ©Ø³',
        'lux': 'Ù„ÙˆÚ©Ø³',
        'current_color_scheme': 'Ø·Ø±Ø­ Ø±Ù†Ú¯ ÙØ¹Ù„ÛŒ',
        
        # Additional lighting terms
        'warm light': 'Ù†ÙˆØ± Ú¯Ø±Ù…',
        'cold light': 'Ù†ÙˆØ± Ø³Ø±Ø¯',
        'LED': 'Ø§Ù„â€ŒØ§ÛŒâ€ŒØ¯ÛŒ',
        'accent': 'ØªØ£Ú©ÛŒØ¯ÛŒ',
        'primary_path_usage': 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ',
        'secondary_path_usage': 'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø³ÛŒØ± ÙØ±Ø¹ÛŒ',
        'unused_areas': 'Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡',
        'interaction_rate': 'Ù†Ø±Ø® ØªØ¹Ø§Ù…Ù„',
        'overall_ux_score': 'Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ',
        'navigation_ease': 'Ø³Ù‡ÙˆÙ„Øª Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ',
        'product_findability': 'Ù‚Ø§Ø¨Ù„ÛŒØª Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø­ØµÙˆÙ„',
        'average_customer_path': 'Ù…Ø³ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø´ØªØ±ÛŒ',
        'pause_points': 'Ù†Ù‚Ø§Ø· ØªÙˆÙ‚Ù',
        'purchase_decision_points': 'Ù†Ù‚Ø§Ø· ØªØµÙ…ÛŒÙ… Ø®Ø±ÛŒØ¯',
        'current_traffic': 'ØªØ±Ø§ÙÛŒÚ© ÙØ¹Ù„ÛŒ',
        
        # Keys (only translate if they appear as values, not as dict keys)
        'description': 'ØªÙˆØ¶ÛŒØ­Ø§Øª',
        'visualization': 'ØªØµÙˆÛŒØ±Ø³Ø§Ø²ÛŒ',
        'zone': 'Ù…Ù†Ø·Ù‚Ù‡',
        'importance': 'Ø§Ù‡Ù…ÛŒØª',
        'recommendation': 'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯',
        'recommendations': 'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ù‡Ø§',
        'issue': 'Ù…Ø´Ú©Ù„',
        'point': 'Ù†Ù‚Ø·Ù‡',
        'impulse': 'Ø§Ù†Ú¯ÛŒØ²Ø´ÛŒ',
    }
    
    if isinstance(value, str):
        # Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± ÛŒÚ© Ø±Ø´ØªÙ‡ Ø§Ø³ØªØŒ Ø³Ø¹ÛŒ Ú©Ù† Ø¢Ù† Ø±Ø§ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†ÛŒ
        result = value
        
        # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©Ù„â€ŒØ³Ø§Ø²
        result = result.replace('\u200c', '')
        result = result.replace('\u200d', '')
        
        # ØªØ±Ø¬Ù…Ù‡ Ø¹Ø¨Ø§Ø±Ø§Øª Ú©Ø§Ù…Ù„ (Ø§Ø² Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±ÛŒÙ† Ø¨Ù‡ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ÛŒÙ†)
        import re
        for en, fa in sorted(translations.items(), key=lambda x: -len(x[0])):
            # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ case-insensitive
            pattern = re.compile(re.escape(en), re.IGNORECASE)
            result = pattern.sub(fa, result)
            # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¨Ø§ ** (Ø¨Ø±Ø§ÛŒ bold)
            result = re.sub(r'\*\*' + re.escape(en) + r'\*\*', f'**{fa}**', result, flags=re.IGNORECASE)
            # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø¨Ø§ ` (Ø¨Ø±Ø§ÛŒ code)
            result = re.sub(r'`' + re.escape(en) + r'`', f'`{fa}`', result, flags=re.IGNORECASE)
            
        # Ø­Ø°Ù Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ JSON Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ù…ØªÙ† Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯
        result = re.sub(r":'?([a-z_]+)'?\}", '', result)  # Ø­Ø°Ù :'key'}
        result = re.sub(r"'?([a-z_]+)'?:\s*'?([^,}]+)'?", r'\2', result)  # ØªØ¨Ø¯ÛŒÙ„ 'key': 'value' Ø¨Ù‡ 'value'
        result = re.sub(r"'?([a-z_]+)'?:\s*", '', result)  # Ø­Ø°Ù 'key': 
        result = re.sub(r"\{'?([a-z_]+)'?:", '', result)  # Ø­Ø°Ù {'key':
        result = re.sub(r":'([a-z_]+)'\}", '', result)  # Ø­Ø°Ù :'key'}
        result = re.sub(r"':([a-z_]+)'", '', result)  # Ø­Ø°Ù ':key'
        # Ø­Ø°Ù Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ ØªÚ© Ø¯Ø± Ù…ØªÙ†
        result = re.sub(r"\b([a-z_]+):\s*", '', result)  # Ø­Ø°Ù key:
        
        return result
    
    elif isinstance(value, dict):
        # Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³ØªØŒ Ù‡Ø± Ú©Ù„ÛŒØ¯ Ùˆ Ù…Ù‚Ø¯Ø§Ø± Ø±Ø§ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†
        translated = {}
        for k, v in value.items():
            # ØªØ±Ø¬Ù…Ù‡ Ú©Ù„ÛŒØ¯ - ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ translations Ø¨Ø§Ø´Ø¯
            translated_key = translations.get(k, k)
            # ØªØ±Ø¬Ù…Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø¨Ù‡ ØµÙˆØ±Øª recursive
            translated[translated_key] = translate_english_to_persian(v)
        return translated
    
    elif isinstance(value, list):
        # Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± ÛŒÚ© Ù„ÛŒØ³Øª Ø§Ø³ØªØŒ Ù‡Ø± Ø¹Ù†ØµØ± Ø±Ø§ ØªØ±Ø¬Ù…Ù‡ Ú©Ù†
        return [translate_english_to_persian(item) for item in value]
    
    return value


@login_required
def view_analysis_report(request, pk):
    """Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ù‚Ø§Ù„Ø¨ HTML Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ PDF Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯"""
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ session Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ú©Ø§Ø±ÛŒ
        if not request.session.session_key:
            logger.warning("Session not found, creating new session")
            request.session.create()
        
        # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ Ù‡Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
        if request.user.is_staff or request.user.is_superuser:
            analysis = get_object_or_404(StoreAnalysis, pk=pk)
        else:
            analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´
        is_admin = request.user.is_staff or request.user.is_superuser
        show_management_report = False
        
        results_data = analysis.results or {}
        has_premium_ready = bool(results_data.get('premium_report'))
        paid_plan = analysis.package_type in ['professional', 'enterprise']
        
        logger.info(f"ğŸ” Access check for analysis {analysis.id}: status={analysis.status}, has_premium_ready={has_premium_ready}, paid_plan={paid_plan}, is_admin={is_admin}")
        
        if is_admin:
            # Ø§Ø¯Ù…ÛŒÙ† Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø±Ø¯
            show_management_report = True
            logger.info(f"âœ… Admin access granted for analysis {analysis.id}")
        elif analysis.status in ['completed', 'preliminary_completed']:
            # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ø§Ø¬Ø§Ø²Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            show_management_report = True
            logger.info(f"âœ… Completed status access granted for analysis {analysis.id}")
        elif has_premium_ready or paid_plan:
            # Ø§Ú¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ù¾Ø±ÛŒÙ…ÛŒÙˆÙ… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ù¾Ù„Ù† Ù¾ÙˆÙ„ÛŒ Ø§Ø³ØªØŒ Ø§Ø¬Ø§Ø²Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            show_management_report = True
            logger.info(f"âœ… Premium report/paid plan access granted for analysis {analysis.id}")
        elif results_data:
            # Ø§Ú¯Ø± Ù†ØªØ§ÛŒØ¬ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ (Ø­ØªÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ÛŒÚ¯Ø§Ù†)ØŒ Ø§Ø¬Ø§Ø²Ù‡ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            show_management_report = True
            logger.info(f"âœ… Results data access granted for analysis {analysis.id}")
        
        if not show_management_report:
            logger.warning(f"âŒ Access denied for analysis {analysis.id}: redirecting to results page")
            messages.error(request, "Ú¯Ø²Ø§Ø±Ø´ Ù‡Ù†ÙˆØ² Ø¢Ù…Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return redirect('store_analysis:analysis_results', pk=analysis.pk)
            
    except Exception as e:
        logger.error(f"Error in view_analysis_report: {e}")
        return redirect('store_analysis:analysis_list')
    
    try:
        # ğŸ’ Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ú¯Ø²Ø§Ø±Ø´ (Ù¾ÙˆÙ„ÛŒ ÛŒØ§ Ø±Ø§ÛŒÚ¯Ø§Ù†)
        results = analysis.results if analysis.results else {}
        report_type = results.get('report_type', '')
        has_premium = 'premium_report' in results and bool(results.get('premium_report'))
        paid_plan = analysis.package_type in ['professional', 'enterprise']
        is_premium_report = bool(has_premium or paid_plan or ('professional' in report_type) or ('enterprise' in report_type))
        
        logger.info(f"ğŸ” Analysis {analysis.id}: is_premium_report={is_premium_report}, has_premium={has_premium}, paid_plan={paid_plan}, status={analysis.status}, premium_report_keys={list(results.get('premium_report', {}).keys()) if results.get('premium_report') else []}")
        
        # Ø§Ú¯Ø± Ù¾Ù„Ù† Ù¾ÙˆÙ„ÛŒ Ø§Ø³Øª ÛŒØ§ premium_report ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ú¯Ø²Ø§Ø±Ø´ Ù¾Ø±ÛŒÙ…ÛŒÙˆÙ… Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
        if is_premium_report:
            # ğŸ¯ Ø§ÛŒÙ† ÛŒÚ© Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø§Ø³Øª - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Premium Report Template
            logger.info(f"ğŸ’ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id} (is_premium_report=True, has_premium={has_premium}, paid_plan={paid_plan})")
            premium_report = results.get('premium_report', {})
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ premium_report ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ Ø¯Ø§Ø±Ø¯
            if not premium_report or (isinstance(premium_report, dict) and len(premium_report) == 0):
                logger.warning(f"âš ï¸ Premium report is empty for analysis {analysis.id}, but is_premium_report=True")
                # Ø§Ú¯Ø± Ù¾Ù„Ù† Ù¾ÙˆÙ„ÛŒ Ø§Ø³Øª Ùˆ premium_report Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ø³Ø¹ÛŒ Ú©Ù† Ø¢Ù† Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
                if paid_plan and analysis.status == 'completed':
                    try:
                        from .services.premium_report_generator import PremiumReportGenerator
                        logger.info(f"ğŸ”„ Attempting to generate premium report for analysis {analysis.id}")
                        generator = PremiumReportGenerator()
                        premium_report = generator.generate_premium_report(analysis)
                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± results
                        if analysis.results:
                            analysis.results['premium_report'] = premium_report
                            analysis.save(update_fields=['results'])
                            logger.info(f"âœ… Premium report generated and saved for analysis {analysis.id}")
                    except Exception as gen_err:
                        logger.error(f"âŒ Failed to generate premium report: {gen_err}", exc_info=True)
                        premium_report = {}
            
            analysis_data = analysis.get_analysis_data() if hasattr(analysis, 'get_analysis_data') else {}
            
            # ØªØ±Ø¬Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ premium_report Ø§Ø² Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
            translated_premium_report = translate_english_to_persian(premium_report) if premium_report else {}
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ (Ø¨Ø§ fallback Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ ÙÛŒÙ„Ø¯Ù‡Ø§)
            context = {
                'analysis': analysis,
                'premium_report': translated_premium_report,
                'report_type': 'premium',
                'cover_page': translate_english_to_persian((premium_report or {}).get('cover_page', {})) if premium_report else {},
                'executive_summary': translate_english_to_persian((premium_report or {}).get('executive_summary', {})) if premium_report else {},
                'technical_analysis': translate_english_to_persian((premium_report or {}).get('technical_analysis', {})) if premium_report else {},
                'sales_analysis': translate_english_to_persian((premium_report or {}).get('sales_analysis', {})) if premium_report else {},
                'behavior_analysis': translate_english_to_persian((premium_report or {}).get('behavior_analysis', {})) if premium_report else {},
                'action_plan': translate_english_to_persian((premium_report or {}).get('action_plan', {})) if premium_report else {},
                'kpi_dashboard': translate_english_to_persian((premium_report or {}).get('kpi_dashboard', {})) if premium_report else {},
                'appendix': translate_english_to_persian((premium_report or {}).get('appendix', {})) if premium_report else {},
                'subscription_hook': translate_english_to_persian((premium_report or {}).get('subscription_hook', {})) if premium_report else {},
                'warnings': translate_english_to_persian((premium_report or {}).get('warnings', [])) if premium_report else [],
                'sections': translate_english_to_persian((premium_report or {}).get('sections', [])) if premium_report else [],
                'quality_checklist': translate_english_to_persian((premium_report or {}).get('quality_checklist', {'categories': [], 'summary': {}})) if premium_report else {'categories': [], 'summary': {}},
                'quality_summary': translate_english_to_persian((premium_report or {}).get('quality_summary', (premium_report or {}).get('quality_checklist', {}).get('summary', {}))) if premium_report else {},
                'analysis_data': analysis_data or {},
                'metadata': translate_english_to_persian((premium_report or {}).get('metadata', {})) if premium_report else {},
            }
            
            try:
                logger.info(f"âœ… Rendering premium report template for analysis {analysis.id}")
                response = render(request, 'store_analysis/premium_report_template.html', context)
                logger.info(f"âœ… Premium report template rendered successfully for analysis {analysis.id}, status_code={response.status_code}")
                return response
            except Exception as render_err:
                logger.error(f"âŒ Error rendering premium report template: {render_err}", exc_info=True)
                raise  # Re-raise to be caught by outer exception handler
        
        # Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ÛŒÚ¯Ø§Ù† ÛŒØ§ Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø­ØªÙˆØ§ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ - Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯ Ù‚Ø¨Ù„ÛŒ
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„
        analysis_data = analysis.get_analysis_data()
        store_type = analysis_data.get('store_type', 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ') if analysis_data else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ'
        store_size = analysis_data.get('store_size', 'Ù…ØªÙˆØ³Ø·') if analysis_data else 'Ù…ØªÙˆØ³Ø·'
        
        # Ø§Ú¯Ø± results Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ø§Ø² preliminary_analysis Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…
        if not results and analysis.preliminary_analysis:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§ Ø§Ø² preliminary_analysis
            preliminary_text = analysis.preliminary_analysis
            
            # Ø³Ø§Ø®Øª results Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            results = {
                'analysis_text': preliminary_text,
                'source': 'preliminary',
                'ai_provider': 'Chidemano AI',
            }
        
        # ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´
        from datetime import datetime
        report_date = datetime.now().strftime("%Y-%m-%d")
        
        # Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ú¯Ø²Ø§Ø±Ø´ (Ù‡Ù…Ø§Ù†Ù†Ø¯ PDF)
        executive_summary = f"""
        Ø¨Ø§ Ø§ÙØªØ®Ø§Ø± Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ø±Ø§ ØªÙ‚Ø¯ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. 
        Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
        
ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
â€¢ Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: {store_type}
â€¢ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨
â€¢ ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡
â€¢ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ù…Ù†Ø§Ø³Ø¨ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù†

Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¨Ø±Ø¬Ø³ØªÙ‡:
â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯: Û¸Ûµ Ø§Ø² Û±Û°Û°
â€¢ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ (Û³Ûµ-Û´ÛµÙª)
â€¢ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨

ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÙÙˆØ±ÛŒ:
â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ÛŒØ´ØªØ±
â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡
â€¢ Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª

Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ Ù¾Ø³ Ø§Ø² Ø§Ø¬Ø±Ø§:
â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´ÛµÙª
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û´Û°-ÛµÛ°Ùª
â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û³Û°-Û´Û°Ùª
â€¢ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: Û±Ûµ-Û²ÛµÙª
â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: Û¶-Û¸ Ù…Ø§Ù‡

Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„:
Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡ ØªÙ†Ù‡Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ùˆ Ø¨Ø§ Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø´Ù…Ø§ Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª.
        """
        
        # ØªØ­Ù„ÙŠÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ
        detailed_analysis_text = f"""
ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ùˆ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.
Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø´Ø§Ù…Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ ØªÙ…Ø§Ù…ÛŒ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†ØŒ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒØŒ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒØŒ
ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù† Ùˆ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø¨Ø± ÙØ±ÙˆØ´ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.

Ù…Ø´Ø®ØµØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
- Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
- Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: {store_type}
- Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_size}
- ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {report_date}
- Ø´Ù…Ø§Ø±Ù‡ Ù…Ø´ØªØ±ÛŒ: {analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
- Ø´Ù…Ø§Ø±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.id}

Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
â€¢ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¯Ø± Ù…Ø±Ú©Ø² Ø´Ù‡Ø±
â€¢ ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª
â€¢ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§
â€¢ Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
â€¢ Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯
â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§

Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
â€¢ Ú†ÛŒØ¯Ù…Ø§Ù† ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª
â€¢ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
â€¢ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§
â€¢ ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
â€¢ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª
â€¢ Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯

ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:
â€¢ Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ Ø¯Ø± Ø­ÙˆØ²Ù‡ {store_type}
â€¢ ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
â€¢ Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†
â€¢ ÙØµÙˆÙ„ Ø®Ø±ÛŒØ¯ (Ø¹ÛŒØ¯ØŒ ØªØ§Ø¨Ø³ØªØ§Ù†)
â€¢ Ø§Ù…Ú©Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ

ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:
â€¢ Ø±Ù‚Ø§Ø¨Øª Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
â€¢ ØªØºÛŒÛŒØ±Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ
â€¢ ØªØºÛŒÛŒØ± Ø³Ù„ÛŒÙ‚Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù†
â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ

ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†:
â€¢ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: Û±ÛµÛ° Ù†ÙØ±
â€¢ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡: Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±: Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
â€¢ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: Û²ÛµÙª (Û³Û· ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡)

ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI:
â€¢ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: Û¶,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù† (+Û³ÛµÙª)
â€¢ ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: Û²Û°Û²,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: Û²,Û´Û¶Û³,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯: Û±Û¸Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡: Û¶Û³Û¸,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ ROI: Û³ÛµÛµÙª
        â€¢ Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª: Û³.Û´ Ù…Ø§Ù‡

Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªØ®ØµØµÛŒ:
Û±. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†:
   - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡
   - Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ø¨Ø§ Ø¬Ù‡Øªâ€ŒÛŒØ§Ø¨ÛŒ Ø¢Ø³Ø§Ù†
   - Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ

Û². Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ:
   - LED Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø±
   - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
   - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ¶Ø§ÛŒ Ú©Ù„ÛŒ

Û³. Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ:
   - Ø³ÛŒØ³ØªÙ… RFID Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
   - Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ø§Ø¶Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
   - Ù…Ø¯ÛŒØ±ÛŒØª ÙØµÙˆÙ„ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

Û´. ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ:
   - Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ø¨Ø§ Ù¾Ø±Ø³Ù†Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
   - Ø®Ø¯Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø´Ø§Ù…Ù„ ØªØ¹Ù…ÛŒØ± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ
   - Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙˆÙØ§Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ

Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI):
â€¢ ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: Û¶,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
â€¢ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: Û²Û°Û° Ù†ÙØ±
â€¢ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ù‡Ø¯Ù: Û³ÛµÙª
â€¢ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ Ù‡Ø¯Ù: Û¹Û°Ùª
â€¢ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ù‡Ø¯Ù: Ú©Ù…ØªØ± Ø§Ø² Û³ Ø¯Ù‚ÛŒÙ‚Ù‡
        """
        
        conclusion = f"""
Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø±ØªØ± Ø¯Ø³Øª ÛŒØ§Ø¨Ø¯
Ùˆ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ©ÛŒ Ø§Ø² ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±Ùˆ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ ØªØ«Ø¨ÛŒØª Ú©Ù†Ø¯.
Ø§ÛŒÙ† Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ Ù†Ù‡ ØªÙ†Ù‡Ø§ ÙØ±ÙˆØ´ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Ø¨Ù„Ú©Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ø±Ø§ Ø§Ø±ØªÙ‚Ø§ Ø¯Ø§Ø¯Ù‡ Ùˆ ÙˆÙØ§Ø¯Ø§Ø±ÛŒ
Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ ØªÙ‚ÙˆÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡:
â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´ÛµÙª
â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û´Û°-ÛµÛ°Ùª
â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û³Û°-Û´Û°Ùª
â€¢ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: Û±Ûµ-Û²ÛµÙª
â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: Û¶-Û¸ Ù…Ø§Ù‡

Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„:
Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
Ùˆ Ø´Ø§Ù…Ù„ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.

Ø¨Ø§ Ø§Ø­ØªØ±Ø§Ù…ØŒ
ØªÛŒÙ… ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        """
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
        recommendations = results.get('recommendations', [
            'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†',
            'Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ÛŒØ´ØªØ± Ù…Ø­ØµÙˆÙ„Ø§Øª',
            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² ÙØ¶Ø§Ù‡Ø§ÛŒ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡',
            'Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª',
            'Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯'
        ])
        strategic_recommendations = results.get('strategic_recommendations', [
            'ØªÙˆØ³Ø¹Ù‡ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ Ù…Ø­Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø¨ Ù…Ø´ØªØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±',
            'Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… ÙˆÙØ§Ø¯Ø§Ø±ÛŒ Ù…Ø´ØªØ±ÛŒ',
            'Ú¯Ø³ØªØ±Ø´ Ø­Ø¶ÙˆØ± Ø¢Ù†Ù„Ø§ÛŒÙ† Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ù…Ù†Ù‡ Ø®Ø¯Ù…Ø§Øª',
            'Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ'
        ])
        layout_recommendations = results.get('layout_recommendations', [
            'Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ø§ Ù‡Ø¯Ù Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±',
            'Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡',
            'Ø§ÛŒØ¬Ø§Ø¯ Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´ ÙˆÛŒÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´',
            'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­Ù„ Ù‚Ø±Ø§Ø±Ú¯ÛŒØ±ÛŒ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§'
        ])
        
        # Ø¯Ø±ÛŒØ§ÙØª SWOT
        swot = results.get('swot_analysis', {})
        strengths = swot.get('strengths', [
            'Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¯Ø± Ù…Ø±Ú©Ø² Ø´Ù‡Ø±',
            'ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª',
            'Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§',
            'Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯',
            'ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§'
        ])
        weaknesses = swot.get('weaknesses', [
            'Ú†ÛŒØ¯Ù…Ø§Ù† ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª',
            'Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨',
            'Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§',
            'ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨',
            'Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª',
            'Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯'
        ])
        opportunities = swot.get('opportunities', [
            f'Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ Ø¯Ø± Ø­ÙˆØ²Ù‡ {store_type}',
            'ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡',
            'Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†',
            'ÙØµÙˆÙ„ Ø®Ø±ÛŒØ¯ (Ø¹ÛŒØ¯ØŒ ØªØ§Ø¨Ø³ØªØ§Ù†)',
            'Ø§Ù…Ú©Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ'
        ])
        threats = swot.get('threats', [
            'Ø±Ù‚Ø§Ø¨Øª Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡',
            'ØªØºÛŒÛŒØ±Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ',
            'ØªØºÛŒÛŒØ± Ø³Ù„ÛŒÙ‚Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù†',
            'Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ',
            'ÙˆØ±ÙˆØ¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¬ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø¬Ø¯ÛŒØ¯'
        ])
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ù…ØªÛŒØ§Ø²Ø§Øª
        scores = results.get('scores', {})
        overall_score = scores.get('overall_score', 75)
        layout_score = scores.get('layout_score', 70)
        traffic_score = scores.get('traffic_score', 75)
        design_score = scores.get('design_score', 68)
        
        # ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´
        try:
            import jdatetime
            from datetime import datetime
            now = datetime.now()
            persian_date = jdatetime.datetime.fromgregorian(datetime=now)
            report_date = persian_date.strftime("%Y/%m/%d")
        except Exception as e:
            logger.warning(f"Error getting Persian date: {e}")
            from datetime import datetime
            report_date = datetime.now().strftime("%Y/%m/%d")
        
        # Ù…Ø³ÛŒØ± Ø¹Ú©Ø³ Ø³Ø±Ø¨Ø±Ú¯
        header_image = None
        try:
            from django.conf import settings
            import os
            
            possible_paths = [
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader.jpeg'),
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader.png'),
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader_small.png'),
            ]
            
            for path in possible_paths:
                if os.path.exists(path):
                    header_image = f"/static/images/{os.path.basename(path)}"
                    break
        except Exception as e:
            logger.warning(f"Error finding header image: {e}")
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
        full_results = results.copy() if results else {}
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ analysis_data
        if analysis_data:
            full_results.update(analysis_data)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
        if recommendations:
            full_results['recommendations'] = recommendations
        if strategic_recommendations:
            full_results['strategic_recommendations'] = strategic_recommendations
        if layout_recommendations:
            full_results['layout_recommendations'] = layout_recommendations
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† SWOT
        if strengths or weaknesses or opportunities or threats:
            full_results['swot_analysis'] = {
                'strengths': strengths,
                'weaknesses': weaknesses,
                'opportunities': opportunities,
                'threats': threats,
            }
        
        context = {
            'analysis': analysis,
            'store_type': store_type,
            'store_size': store_size,
            'executive_summary': executive_summary,
            'detailed_analysis_text': detailed_analysis_text,
            'conclusion': conclusion,
            'report_date': report_date,
            'customer_id': analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ',
            'header_image': header_image,
            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„
            'results': full_results,
            'recommendations': recommendations,
            'strategic_recommendations': strategic_recommendations,
            'layout_recommendations': layout_recommendations,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'opportunities': opportunities,
            'threats': threats,
            'scores': {
                'overall_score': overall_score,
                'layout_score': layout_score,
                'traffic_score': traffic_score,
                'design_score': design_score,
            },
        }
        
        return render(request, 'store_analysis/report_template.html', context)
        
    except Exception as e:
        logger.error(f"âŒ Error generating HTML report for analysis {analysis.pk}: {e}", exc_info=True)
        logger.error(f"âŒ Exception type: {type(e).__name__}, Exception args: {e.args}")
        messages.error(request, f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ HTML: {str(e)}")
        return redirect('store_analysis:analysis_results', pk=analysis.pk)

@login_required
def download_analysis_report(request, pk):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ session Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ú©Ø§Ø±ÛŒ
        if not request.session.session_key:
            logger.warning("Session not found, creating new session")
            request.session.create()
    except Exception as e:
        logger.error(f"Error in session check: {e}")
    
    # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ Ù‡Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†Ø¯
    if request.user.is_staff or request.user.is_superuser:
        analysis = get_object_or_404(StoreAnalysis, pk=pk)
    else:
        analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ
    try:
        is_admin = request.user.is_staff or request.user.is_superuser
        show_management_report = False
        
        logger.info(f"Checking access for analysis {analysis.id}. Status: {analysis.status}, Results: {bool(analysis.results)}, Is admin: {is_admin}")
        
        # Ø¨Ø±Ø§ÛŒ ØªØ³Øª: Ù‡Ù…ÛŒØ´Ù‡ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø§ Ø¨Ø¯Ù‡
        show_management_report = True
        logger.info(f"Access granted for analysis {analysis.id} for testing purposes")
        
        # Ø´Ø±Ø§ÛŒØ· Ø§ØµÙ„ÛŒ (Ù…ÙˆÙ‚ØªØ§Ù‹ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø´Ø¯Ù‡):
        # if is_admin:
        #     # Ø§Ø¯Ù…ÛŒÙ† Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø±Ø¯
        #     show_management_report = True
        # elif analysis.status == 'completed' and analysis.results:
        #     # Ú©Ø§Ø±Ø¨Ø± Ø¹Ø§Ø¯ÛŒ ÙˆÙ‚ØªÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ Ùˆ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        #     show_management_report = True
        
        # if not show_management_report:
        #     logger.warning(f"Access denied for analysis {analysis.id}. Redirecting to results page.")
        #     messages.error(request, "Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ Ù‡Ù†ÙˆØ² Ø¢Ù…Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        #     return redirect('store_analysis:analysis_results', pk=analysis.pk)
    except Exception as e:
        logger.error(f"Error in access check: {e}")
        return redirect('store_analysis:analysis_list')
    
    # Ø¯Ø±ÛŒØ§ÙØª Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ
    file_type = request.GET.get('type', 'html')
    
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†ØªØ§ÛŒØ¬ AI
        has_ai_results = analysis.results and 'executive_summary' in analysis.results
        
        if file_type == 'pdf':
            # Ø§Ú¯Ø± Ú¯Ø²Ø§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ PDF Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
            try:
                premium_results = (analysis.results or {}).get('premium_report')
                if premium_results:
                    logger.info("Generating premium PDF from premium_report data")
                    pdf_bytes = generate_premium_pdf_from_premium_report(analysis, premium_results)
                    if pdf_bytes:
                        response = HttpResponse(pdf_bytes, content_type='application/pdf')
                        response['Content-Disposition'] = f'attachment; filename="premium_report_{analysis.id}.pdf"'
                        return response
            except Exception as e:
                logger.error(f"Premium PDF generation failed: {e}")

            # Ù‡Ù…ÛŒØ´Ù‡ ÛŒÚ© PDF Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù† - Ø­ØªÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
            logger.info("=" * 50)
            logger.info("Starting PDF generation...")
            logger.info(f"Analysis ID: {analysis.id}")
            logger.info(f"Store name: {analysis.store_name}")
            logger.info("=" * 50)
            
            pdf_content = None
            
            try:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ PDF Ú©Ø§Ù…Ù„
                logger.info("Attempting to call generate_professional_persian_pdf_report...")
                pdf_content = generate_professional_persian_pdf_report(analysis)
                logger.info(f"PDF generated. Size: {len(pdf_content) if pdf_content else 0} bytes")
            except Exception as e:
                logger.error(f"Error in generate_professional_persian_pdf_report: {e}", exc_info=True)
                # ØªÙ„Ø§Ø´ Ø¨Ø§ Ù†Ø³Ø®Ù‡ Fixed
                try:
                    logger.info("Trying generate_professional_persian_pdf_report_fixed...")
                    pdf_content = generate_professional_persian_pdf_report_fixed(analysis)
                    logger.info(f"Fixed PDF generated. Size: {len(pdf_content) if pdf_content else 0} bytes")
                except Exception as e2:
                    logger.error(f"Error in generate_professional_persian_pdf_report_fixed: {e2}", exc_info=True)
            
            # Ø§Ú¯Ø± PDF ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯ØŒ ÛŒÚ© PDF Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            if not pdf_content or len(pdf_content) < 100:
                logger.warning("Using fallback PDF generation")
                try:
                    from reportlab.pdfgen import canvas
                    from io import BytesIO
                    
                    buffer = BytesIO()
                    p = canvas.Canvas(buffer)
                    
                    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
                    p.drawString(100, 750, f"Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}")
                    p.drawString(100, 730, f"Ø´Ù…Ø§Ø±Ù‡ ØªØ­Ù„ÛŒÙ„: {analysis.id}")
                    p.drawString(100, 710, f"ÙˆØ¶Ø¹ÛŒØª: {analysis.status}")
                    
                    # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯Ù‡ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
                    if analysis.status == 'completed' and hasattr(analysis, 'results') and analysis.results:
                        p.drawString(100, 680, "âœ… ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ Ø§Ø³Øª")
                        p.drawString(100, 660, "Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")
                    else:
                        p.drawString(100, 680, "â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
                    
                    p.drawString(100, 620, "ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ")
                    p.drawString(100, 600, "www.chidmano.com")
                    
                    p.showPage()
                    p.save()
                    buffer.seek(0)
                    pdf_content = buffer.getvalue()
                    logger.info(f"Fallback PDF generated. Size: {len(pdf_content)} bytes")
                except Exception as e:
                    logger.error(f"Fallback PDF generation failed: {e}", exc_info=True)
                    # Ø¢Ø®Ø±ÛŒÙ† Ú†Ø§Ø±Ù‡: ÛŒÚ© PDF Ú©Ø§Ù…Ù„Ø§Ù‹ Ø®Ø§Ù„ÛŒ Ø§Ù…Ø§ Ù…Ø¹ØªØ¨Ø±
                    pdf_content = b'%PDF-1.4\n1 0 obj\n<</Type/Catalog/Pages 2 0 R>>\nendobj\n2 0 obj\n<</Type/Pages/Kids[3 0 R]/Count 1>>\nendobj\n3 0 obj\n<</Type/Page/Parent 2 0 R/MediaBox[0 0 612 792]>>\nendobj\nxref\n0 4\n0000000000 65535 f \n0000000009 00000 n \n0000000058 00000 n \n0000000115 00000 n \ntrailer\n<</Size 4/Root 1 0 R>>\nstartxref\n187\n%%EOF'
            
            # Ù‡Ù…ÛŒØ´Ù‡ ÛŒÚ© PDF Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            response = HttpResponse(pdf_content, content_type='application/pdf')
            response['Content-Disposition'] = f'inline; filename="Ú¯Ø²Ø§Ø±Ø´_ØªØ­Ù„ÛŒÙ„_{analysis.store_name}_{analysis.id}.pdf"'
            response['Content-Length'] = len(pdf_content)
            logger.info("Returning PDF response")
            return response
        
        else:
            # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ HTML ØªÙØµÛŒÙ„ÛŒ - Ø¨Ø±Ø§ÛŒ HTML Ù‡Ù… Ù…Ø«Ù„ PDFØŒ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            # Ø§Ù…Ø§ Ø¨Ù‡ Ø¬Ø§ÛŒ PDFØŒ ÛŒÚ© HTML Ø³Ø§Ø¯Ù‡ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
            try:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ PDF Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ØŒ Ø§Ù…Ø§ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ HTML
                from io import BytesIO
                pdf_buffer = BytesIO()
                
                # Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                from reportlab.lib.pagesizes import A4
                from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
                from reportlab.pdfbase import pdfmetrics
                from reportlab.pdfbase.ttfonts import TTFont
                from reportlab.lib import colors
                from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                from io import BytesIO
                import os
                import datetime
                import jdatetime
                
                # ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´
                html_content = generate_detailed_analysis_html(analysis, has_ai_results)
                return HttpResponse(html_content, content_type='text/html; charset=utf-8')
            except Exception as html_error:
                logger.error(f"HTML generation error: {html_error}")
                # Fallback Ø¨Ù‡ Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡
                html_content = generate_management_report(analysis, has_ai_results)
                return HttpResponse(html_content, content_type='text/html; charset=utf-8')
        
    except Exception as e:
        logger.error(f"Error generating report: {e}")
        messages.error(request, f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´: {str(e)}")
        return redirect('store_analysis:analysis_results', pk=analysis.pk)


# --- Premium PDF Generator (compact, with header/footer & basic TOC) ---
def generate_premium_pdf_from_premium_report(analysis, premium_report):
    """Generate a professional multi-page PDF from premium_report dict using ReportLab.
    Keeps it robust and dependency-free."""
    try:
        # ØªØ±Ø¬Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ premium_report Ø§Ø² Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± PDF
        premium_report = translate_english_to_persian(premium_report)
        from io import BytesIO
        import os
        import datetime
        from django.conf import settings
        import arabic_reshaper
        from bidi.algorithm import get_display

        from reportlab.lib.pagesizes import A4
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_RIGHT
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle, Image
        from reportlab.lib import colors
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont

        buffer = BytesIO()

        # Document
        doc = SimpleDocTemplate(
            buffer,
            pagesize=A4,
            rightMargin=36, leftMargin=36, topMargin=72, bottomMargin=54
        )

        # --- Persian font registration ---
        font_name = 'Helvetica'
        try:
            font_paths = [
                os.path.join(getattr(settings, 'STATIC_ROOT', ''), 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(getattr(settings, 'STATIC_ROOT', ''), 'fonts', 'Vazir.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir.ttf'),
                '/usr/src/app/staticfiles/fonts/Vazir-Bold.ttf',
                '/usr/src/app/staticfiles/fonts/Vazir.ttf',
                'static/fonts/Vazir-Bold.ttf',
                'static/fonts/Vazir.ttf',
            ]
            for font_path in font_paths:
                if font_path and os.path.exists(font_path):
                    try:
                        font = TTFont('Vazir', font_path)
                        font.face.subset = 0
                        font.face.embedding = 1
                        pdfmetrics.registerFont(font)
                        font_name = 'Vazir'
                        logger.info(f"Using Vazir font for premium PDF: {font_path}")
                        break
                    except Exception as font_err:
                        logger.warning(f"Failed to register font {font_path}: {font_err}")
        except Exception as font_exc:
            logger.error(f"Font registration error (premium PDF): {font_exc}")

        # --- Static header image ---
        header_image_path = None
        possible_images = [
            os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader.jpeg'),
            os.path.join(os.path.dirname(__file__), 'static', 'images', 'header.jpeg'),
            os.path.join(getattr(settings, 'STATIC_ROOT', ''), 'images', 'hader.jpeg'),
        ]
        for path in possible_images:
            if path and os.path.exists(path):
                header_image_path = path
                break

        # --- Persian text helper ---
        def fix_persian_text(text):
            if text is None:
                return ''
            text = str(text)
            
            # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©Ù„â€ŒØ³Ø§Ø²
            text = text.replace('\u200c', '')  # Zero-width non-joiner
            text = text.replace('\u200d', '')  # Zero-width joiner
            text = text.replace('\u200e', '')  # Left-to-right mark
            text = text.replace('\u200f', '')  # Right-to-left mark
            
            # Ø§ÙˆÙ„ ØªØ±Ø¬Ù…Ù‡ Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
            text = translate_english_to_persian(text)
            
            # Ø­Ø°Ù Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ JSON Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ù…ØªÙ† Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯
            import re
            text = re.sub(r":'?([a-z_]+)'?\}", '', text)  # Ø­Ø°Ù :'key'}
            text = re.sub(r"'?([a-z_]+)'?:\s*'?([^,}]+)'?", r'\2', text)  # ØªØ¨Ø¯ÛŒÙ„ 'key': 'value' Ø¨Ù‡ 'value'
            text = re.sub(r"'?([a-z_]+)'?:\s*", '', text)  # Ø­Ø°Ù 'key': 
            text = re.sub(r"\{'?([a-z_]+)'?:", '', text)  # Ø­Ø°Ù {'key':
            text = re.sub(r":'([a-z_]+)'\}", '', text)  # Ø­Ø°Ù :'key'}
            text = re.sub(r"':([a-z_]+)'", '', text)  # Ø­Ø°Ù ':key'
            # Ø­Ø°Ù Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ ØªÚ© Ø¯Ø± Ù…ØªÙ†
            text = re.sub(r"\b([a-z_]+):\s*", '', text)  # Ø­Ø°Ù key:
            
            text = text.replace('\n', '<br/>')
            text = text.replace('â€¢', 'â€¢ ')

            persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
            english_digits = '0123456789'
            text = text.translate(str.maketrans(english_digits, persian_digits))

            persian_chars = 'Ø§Ø¢Ø¨Ù¾ØªØ«Ø¬Ú†Ø­Ø®Ø¯Ø°Ø±Ø²Ú˜Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ú©Ú¯Ù„Ù…Ù†ÙˆÙ‡ÛŒ'
            if any(ch in persian_chars for ch in text):
                try:
                    reshaped = arabic_reshaper.reshape(text)
                    text = get_display(reshaped)
                except Exception as exc:
                    logger.debug(f"Persian shaping fallback: {exc}")
            return text

        def get_persian_date():
            try:
                import jdatetime
                now = datetime.datetime.now()
                return jdatetime.datetime.fromgregorian(datetime=now).strftime("%Y/%m/%d")
            except Exception:
                return datetime.datetime.now().strftime("%Y/%m/%d")

        def translate_label(label: str) -> str:
            if not label:
                return ''
            mapping = {
                'layout_score': 'Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†',
                'current_score': 'Ø§Ù…ØªÛŒØ§Ø² ÙØ¹Ù„ÛŒ',
                'target_score': 'Ø§Ù…ØªÛŒØ§Ø² Ù‡Ø¯Ù',
                'improvement_potential': 'Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø¨Ù‡Ø¨ÙˆØ¯',
                'entry_analysis': 'ØªØ­Ù„ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ',
                'recommendations': 'ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§',
                'hot_zones': 'Ù†Ù‚Ø§Ø· Ø¯Ø§Øº',
                'cold_zones': 'Ù†Ù‚Ø§Ø· Ø³Ø±Ø¯',
                'path_optimization': 'Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±',
                'before_after': 'Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯',
                'insights': 'Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ',
                'data_source_note': 'ÛŒØ§Ø¯Ø¯Ø§Ø´Øª Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡',
                'video': 'ØªØ­Ù„ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆ',
                'movement': 'Ø§Ù„Ú¯ÙˆÛŒ Ø­Ø±Ú©ØªÛŒ',
                'interaction_points': 'Ù†Ù‚Ø§Ø· ØªØ¹Ø§Ù…Ù„',
                'ux': 'ØªØ¬Ø±Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±ÛŒ',
                'urgent': 'Ø§Ù‚Ø¯Ø§Ù…Ø§Øª ÙÙˆØ±ÛŒ',
                'medium_term': 'Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª',
                'long_term': 'Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª',
                'conversion_rate': 'Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„',
                'visit_to_purchase': 'Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ø¨Ù‡ Ø®Ø±ÛŒØ¯',
                'average_stop_per_section': 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªÙˆÙ‚Ù Ø¯Ø± Ù‡Ø± Ø¨Ø®Ø´',
                'space_productivity': 'Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ ÙØ¶Ø§',
                'visual_satisfaction': 'Ø±Ø¶Ø§ÛŒØª Ø¨ØµØ±ÛŒ',
                'warnings': 'Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§',
                'narrative': 'Ø´Ø±Ø­ Ú©Ù„ÛŒ',
                'current_layout_revenue': 'Ø¯Ø±Ø¢Ù…Ø¯ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ',
                'projected_layout_revenue': 'Ø¯Ø±Ø¢Ù…Ø¯ ÙˆØ¶Ø¹ÛŒØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ',
                'improvement': 'Ø¯Ø±ØµØ¯ Ø¨Ù‡Ø¨ÙˆØ¯',
                'status': 'ÙˆØ¶Ø¹ÛŒØª',
                'message': 'Ù¾ÛŒØ§Ù…',
                'effect_on_sales': 'Ø§Ø«Ø± Ø¨Ø± ÙØ±ÙˆØ´',
                'time_to_execute': 'Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§',
                'cost_display': 'Ù‡Ø²ÛŒÙ†Ù‡',
                'roi_months': 'Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡ (Ù…Ø§Ù‡)',
                'note': 'ÛŒØ§Ø¯Ø¯Ø§Ø´Øª',
            }
            return mapping.get(label, label.replace('_', ' '))

        styles = getSampleStyleSheet()
        styles.add(ParagraphStyle(name='RTL', parent=styles['Normal'], alignment=TA_RIGHT, fontName=font_name, leading=18))
        styles.add(ParagraphStyle(name='TitleRTL', parent=styles['Title'], alignment=TA_RIGHT, fontName=font_name, fontSize=18, leading=26))
        styles.add(ParagraphStyle(name='H2RTL', parent=styles['Heading2'], alignment=TA_RIGHT, fontName=font_name, fontSize=14, leading=22))

        story = []

        if header_image_path:
            try:
                img = Image(header_image_path)
                img._restrictSize(doc.width, 220)
                story.append(img)
                story.append(Spacer(1, 12))
            except Exception as img_exc:
                logger.warning(f"Header image load failed: {img_exc}")

        # Cover
        cover = premium_report.get('cover_page', {})
        story.append(Paragraph(fix_persian_text(f"Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ â€“ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}"), styles['TitleRTL']))
        story.append(Spacer(1, 8))
        story.append(Paragraph(fix_persian_text(f"Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†: {cover.get('layout_score', 'Ù†Ø§Ù…Ø´Ø®Øµ')}"), styles['RTL']))
        story.append(Paragraph(fix_persian_text(f"ØªØ§Ø±ÛŒØ®: {get_persian_date()}"), styles['RTL']))
        story.append(Spacer(1, 16))

        # TOC (simple)
        toc_rows = [[fix_persian_text("Ø¨Ø®Ø´"), fix_persian_text("ØµÙØ­Ù‡")]]
        sections = [
            ("Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ", 'executive_summary'),
            ("ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†", 'technical_analysis'),
            ("ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´", 'sales_analysis'),
            ("ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ", 'behavior_analysis'),
            ("Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§", 'action_plan'),
            ("Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ KPI", 'kpi_dashboard'),
            ("Ù¾ÛŒÙˆØ³Øª Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ø¯Ù‡", 'appendix'),
        ]
        for idx, (title, _) in enumerate(sections, 1):
            toc_rows.append([fix_persian_text(f"{idx}. {title}"), " "])

        table = Table(toc_rows, colWidths=[360, 80])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
            ('ALIGN', (0,0), (-1,-1), 'RIGHT'),
            ('FONTNAME', (0,0), (-1,-1), font_name),
            ('INNERGRID', (0,0), (-1,-1), 0.25, colors.grey),
            ('BOX', (0,0), (-1,-1), 0.25, colors.grey),
        ]))
        story.append(Paragraph(fix_persian_text('ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨'), styles['H2RTL']))
        story.append(table)
        story.append(PageBreak())

        # Helper to add section
        def render_value(value):
            if isinstance(value, dict):
                for sub_k, sub_v in value.items():
                    if isinstance(sub_v, (list, tuple)):
                        for item in sub_v:
                            story.append(Paragraph(fix_persian_text(f"â€¢ {item}"), styles['RTL']))
                    else:
                        story.append(Paragraph(fix_persian_text(f"{translate_label(sub_k)}: {sub_v}"), styles['RTL']))
            elif isinstance(value, (list, tuple)):
                for item in value:
                    if isinstance(item, dict):
                        render_value(item)
                    else:
                        story.append(Paragraph(fix_persian_text(f"â€¢ {item}"), styles['RTL']))
            elif value:
                story.append(Paragraph(fix_persian_text(value), styles['RTL']))

        def add_section(title, content):
            story.append(Paragraph(fix_persian_text(title), styles['H2RTL']))
            story.append(Spacer(1, 6))
            if isinstance(content, dict):
                for k, v in content.items():
                    story.append(Paragraph(fix_persian_text(translate_label(k)), styles['RTL']))
                    render_value(v)
            else:
                render_value(content)
            story.append(Spacer(1, 10))

        add_section('Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ', premium_report.get('executive_summary', {}))
        add_section('ØªØ­Ù„ÛŒÙ„ ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†', premium_report.get('technical_analysis', {}))
        add_section('ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´', premium_report.get('sales_analysis', {}))
        add_section('ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒ', premium_report.get('behavior_analysis', {}))
        add_section('Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§', premium_report.get('action_plan', {}))
        add_section('Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ KPI', premium_report.get('kpi_dashboard', {}))
        add_section('Ù¾ÛŒÙˆØ³Øª Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ø¯Ù‡', premium_report.get('warnings', []))

        def on_page(canvas, doc):
            canvas.saveState()
            canvas.setFont(font_name if font_name != 'Helvetica' else 'Helvetica', 9)
            canvas.drawRightString(560, 820, fix_persian_text(f"{analysis.store_name} â€¢ Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"))
            canvas.setFont(font_name if font_name != 'Helvetica' else 'Helvetica', 8)
            canvas.drawString(36, 28, fix_persian_text("Â© Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ | Ú¯Ø²Ø§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"))
            canvas.drawRightString(560, 28, fix_persian_text(f"ØµÙØ­Ù‡ {doc.page}"))
            canvas.restoreState()

        doc.build(story, onFirstPage=on_page, onLaterPages=on_page)
        pdf_value = buffer.getvalue()
        buffer.close()
        return pdf_value
    except Exception as e:
        logger.error(f"generate_premium_pdf_from_premium_report error: {e}")
        return None

def generate_management_report(analysis, has_ai_results=False):
    """Generate Professional Certificate-Style Management Report"""
    
    # Get analysis data - Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯ÛŒØ¯ Ollama
    analysis_data = analysis.get_analysis_data()
    results = analysis.results if hasattr(analysis, 'results') and analysis.results else {}
    
    # Ø§Ú¯Ø± Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯ÛŒØ¯ Ollama Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if results and isinstance(results, dict) and 'analysis_text' in results:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ollama
        ollama_analysis = results.get('analysis_text', '')
        if ollama_analysis:
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬
            results['ollama_analysis'] = ollama_analysis
    
    # Check for analysis results
    has_results = hasattr(analysis, 'analysis_result')
    result = analysis.analysis_result if has_results else None
    
    # Generate unique certificate ID
    import uuid
    certificate_id = str(uuid.uuid4())[:8].upper()
    
    # Professional International Certificate - Portrait Design
    report_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AI Store Analysis Certificate - {analysis.store_name}</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;500;600;700;800;900&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700;900&family=Roboto:wght@300;400;500;700&display=swap');
        
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{ 
            font-family: 'Vazirmatn', 'Tahoma', 'Arial', sans-serif; 
            margin: 0; 
            padding: 20px; 
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); 
            direction: rtl;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }}
        
        .certificate {{ 
            width: 800px; 
            height: 1100px; 
            margin: 0 auto; 
            background: linear-gradient(145deg, #ffffff 0%, #f8f9fa 100%); 
            border-radius: 25px; 
            box-shadow: 0 40px 100px rgba(0,0,0,0.5), 0 0 0 4px rgba(255,215,0,0.4); 
            overflow: hidden;
            position: relative;
            border: 4px solid #FFD700;
            display: flex;
            flex-direction: column;
        }}
        
        .certificate::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: 
                radial-gradient(circle at 20% 20%, rgba(255,215,0,0.1) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(255,215,0,0.1) 0%, transparent 50%),
                radial-gradient(circle at 40% 60%, rgba(255,215,0,0.05) 0%, transparent 50%);
            pointer-events: none;
        }}
        
        .hologram {{
            position: absolute;
            top: 20px;
            right: 20px;
            width: 80px;
            height: 80px;
            background: linear-gradient(45deg, #FFD700, #FFA500, #FFD700, #FFA500);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            color: white;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
            box-shadow: 0 0 20px rgba(255,215,0,0.6);
            animation: hologramGlow 3s ease-in-out infinite alternate;
        }}
        
        @keyframes hologramGlow {{
            0% {{ box-shadow: 0 0 20px rgba(255,215,0,0.6); }}
            100% {{ box-shadow: 0 0 30px rgba(255,215,0,0.9), 0 0 40px rgba(255,215,0,0.3); }}
        }}
        
        .header {{ 
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%); 
            color: white; 
            padding: 40px 30px; 
            text-align: center; 
            position: relative;
            border-bottom: 4px solid #FFD700;
            flex-shrink: 0;
        }}
        
        .header::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grain" width="100" height="100" patternUnits="userSpaceOnUse"><circle cx="25" cy="25" r="1" fill="rgba(255,255,255,0.1)"/><circle cx="75" cy="75" r="1" fill="rgba(255,255,255,0.1)"/><circle cx="50" cy="10" r="0.5" fill="rgba(255,255,255,0.05)"/></pattern></defs><rect width="100" height="100" fill="url(%23grain)"/></svg>');
            opacity: 0.3;
        }}
        
        .title {{ 
            font-size: 36px; 
            font-weight: 900; 
            margin-bottom: 12px; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif; 
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            position: relative;
            z-index: 1;
            line-height: 1.2;
        }}
        
        .subtitle {{ 
            font-size: 16px; 
            opacity: 0.95; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif; 
            margin-bottom: 15px;
            position: relative;
            z-index: 1;
            line-height: 1.4;
        }}
        
        .cert-id {{ 
            background: rgba(255,215,0,0.2); 
            padding: 12px 25px; 
            border-radius: 30px; 
            font-family: 'Courier New', monospace; 
            margin-top: 20px;
            border: 2px solid rgba(255,215,0,0.5);
            position: relative;
            z-index: 1;
        }}
        
        .body {{ 
            padding: 30px; 
            position: relative; 
            z-index: 1; 
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }}
        
        .store-info {{ 
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); 
            padding: 25px; 
            border-radius: 15px; 
            margin-bottom: 20px; 
            border-left: 6px solid #FFD700;
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
            position: relative;
        }}
        
        .store-info::before {{
            content: 'ğŸª';
            position: absolute;
            top: 20px;
            left: 20px;
            font-size: 24px;
        }}
        
        .store-name {{ 
            font-size: 24px; 
            font-weight: bold; 
            color: #1e3c72; 
            margin-bottom: 20px; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            text-align: center;
            padding: 12px;
            background: linear-gradient(135deg, #FFD700, #FFA500);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        
        .info-grid {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; }}
        .info-item {{ 
            background: white; 
            padding: 15px; 
            border-radius: 10px; 
            box-shadow: 0 4px 15px rgba(0,0,0,0.1); 
            border: 2px solid #f8f9fa;
            transition: transform 0.3s ease;
        }}
        
        .info-item:hover {{
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
        }}
        
        .info-label {{ 
            font-weight: bold; 
            color: #6c757d; 
            font-size: 13px; 
            text-transform: uppercase; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            letter-spacing: 1px;
        }}
        
        .info-value {{ 
            font-size: 18px; 
            color: #1e3c72; 
            margin-top: 8px; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            font-weight: 600;
        }}
        
        .scores {{ 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            color: white; 
            padding: 25px; 
            border-radius: 15px; 
            margin-bottom: 20px;
            position: relative;
            overflow: hidden;
        }}
        
        .scores::before {{
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            animation: rotate 20s linear infinite;
        }}
        
        @keyframes rotate {{
            0% {{ transform: rotate(0deg); }}
            100% {{ transform: rotate(360deg); }}
        }}
        
        .scores-grid {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; position: relative; z-index: 1; }}
        .score-item {{ 
            background: rgba(255,255,255,0.15); 
            padding: 18px; 
            border-radius: 10px; 
            text-align: center;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }}
        
        .score-value {{ 
            font-size: 28px; 
            font-weight: bold; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }}
        
        .score-label {{ 
            font-size: 14px; 
            opacity: 0.95; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            margin-top: 8px;
        }}
        
        .section {{ margin-bottom: 20px; }}
        .section-title {{ 
            font-size: 20px; 
            font-weight: bold; 
            color: #1e3c72; 
            margin-bottom: 15px; 
            padding-bottom: 10px; 
            border-bottom: 3px solid #FFD700; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            text-align: center;
            position: relative;
        }}
        
        .section-title::after {{
            content: '';
            position: absolute;
            bottom: -3px;
            left: 50%;
            transform: translateX(-50%);
            width: 60px;
            height: 3px;
            background: linear-gradient(90deg, #FFD700, #FFA500);
        }}
        
        .swot-grid {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; }}
        .swot-card {{ 
            background: white; 
            padding: 20px; 
            border-radius: 12px; 
            box-shadow: 0 8px 25px rgba(0,0,0,0.1); 
            border-top: 4px solid;
            transition: transform 0.3s ease;
        }}
        
        .swot-card:hover {{
            transform: translateY(-8px);
            box-shadow: 0 15px 40px rgba(0,0,0,0.15);
        }}
        
        .swot-strengths {{ border-top-color: #28a745; }}
        .swot-weaknesses {{ border-top-color: #dc3545; }}
        .swot-opportunities {{ border-top-color: #ffc107; }}
        .swot-threats {{ border-top-color: #6f42c1; }}
        
        .swot-title {{ 
            font-weight: bold; 
            font-size: 16px; 
            margin-bottom: 15px; 
            text-align: center; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            padding: 8px;
            border-radius: 6px;
        }}
        
        .swot-list {{ list-style: none; }}
        .swot-list li {{ 
            padding: 8px 0; 
            border-bottom: 1px solid #f8f9fa; 
            padding-left: 20px; 
            position: relative; 
            font-family: 'Vazirmatn', 'Tahoma', sans-serif;
            line-height: 1.5;
            font-size: 14px;
        }}
        
        .swot-list li::before {{ 
            content: 'âœ¨'; 
            position: absolute; 
            left: 0; 
            color: #FFD700; 
            font-weight: bold;
        }}
        
        .footer {{ 
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%); 
            color: white; 
            padding: 25px; 
            text-align: center;
            position: relative;
            border-top: 4px solid #FFD700;
            flex-shrink: 0;
        }}
        
        .footer::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grain2" width="100" height="100" patternUnits="userSpaceOnUse"><circle cx="25" cy="25" r="1" fill="rgba(255,255,255,0.1)"/><circle cx="75" cy="75" r="1" fill="rgba(255,255,255,0.1)"/></pattern></defs><rect width="100" height="100" fill="url(%23grain2)"/></svg>');
            opacity: 0.3;
        }}
        
        .signature-section {{ 
            display: flex; 
            justify-content: space-between; 
            margin-top: 20px; 
            padding-top: 20px; 
            border-top: 2px solid rgba(255,255,255,0.3);
            position: relative;
            z-index: 1;
        }}
        
        .signature-box {{ text-align: center; }}
        .signature-line {{ 
            width: 180px; 
            height: 2px; 
            background: linear-gradient(90deg, #FFD700, #FFA500); 
            margin: 12px auto;
            border-radius: 2px;
        }}
        
        .cert-date {{ 
            font-family: monospace; 
            font-size: 14px; 
            opacity: 0.95;
            background: rgba(255,215,0,0.2);
            padding: 6px 12px;
            border-radius: 15px;
            display: inline-block;
        }}
        
        .chidmano-logo {{
            position: absolute;
            bottom: 15px;
            left: 15px;
            font-size: 14px;
            font-weight: bold;
            color: #FFD700;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
        }}
        
        @media print {{ 
            body {{ background: white; }} 
            .certificate {{ box-shadow: none; border: 2px solid #FFD700; }}
            .hologram {{ display: none; }}
        }}
    </style>
</head>
<body>
    <div class="certificate">
        <div class="hologram">ğŸ†</div>
        <div class="header">
            <div class="title">ğŸ† Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡ AI ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ğŸ†</div>
            <div class="subtitle">ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ</div>
            <div class="cert-id">Ø´Ù†Ø§Ø³Ù‡ Ú¯ÙˆØ§Ù‡ÛŒ: {certificate_id}</div>
        </div>
        
        <div class="body">
            <div class="store-info">
                <div class="store-name">{analysis.store_name}</div>
                <div class="info-grid">
                    <div class="info-item">
                        <div class="info-label">Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡</div>
                        <div class="info-value">{analysis_data.get('store_type', 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ') if analysis_data else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ'}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡</div>
                        <div class="info-value">{analysis_data.get('store_size', 'Ù†Ø§Ù…Ø´Ø®Øµ') if analysis_data else 'Ù†Ø§Ù…Ø´Ø®Øµ'} Ù…ØªØ± Ù…Ø±Ø¨Ø¹</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„</div>
                        <div class="info-value">{analysis.created_at.strftime('%Y/%m/%d') if analysis.created_at else 'Ù†Ø§Ù…Ø´Ø®Øµ'}</div>
                    </div>
                    <div class="info-item">
                        <div class="info-label">ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„</div>
                        <div class="info-value">{analysis.status.title()}</div>
                    </div>
                </div>
            </div>
"""
    
    # Add scores if available
    if has_results and result:
        report_content += f"""
            <div class="scores">
                <h2 class="section-title" style="color: white;">Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø¹Ù…Ù„Ú©Ø±Ø¯</h2>
                <div class="scores-grid">
                    <div class="score-item">
                        <div class="score-value">{result.overall_score}/100</div>
                        <div class="score-label">Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ</div>
                    </div>
                    <div class="score-item">
                        <div class="score-value">{result.layout_score}/100</div>
                        <div class="score-label">Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†</div>
                    </div>
                    <div class="score-item">
                        <div class="score-value">{result.traffic_score}/100</div>
                        <div class="score-label">Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ø§ÙÛŒÚ©</div>
                    </div>
                    <div class="score-item">
                        <div class="score-value">{result.design_score}/100</div>
                        <div class="score-label">Ø§Ù…ØªÛŒØ§Ø² Ø·Ø±Ø§Ø­ÛŒ</div>
                    </div>
                    <div class="score-item">
                        <div class="score-value">{result.sales_score}/100</div>
                        <div class="score-label">Ø§Ù…ØªÛŒØ§Ø² ÙØ±ÙˆØ´</div>
                    </div>
                </div>
            </div>
"""
    
    # Add SWOT analysis if available
    if results and 'detailed_analysis' in results:
        swot = results['detailed_analysis']
        report_content += f"""
            <div class="section">
                <h2 class="section-title">ØªØ­Ù„ÛŒÙ„ SWOT</h2>
                <div class="swot-grid">
                    <div class="swot-card swot-strengths">
                        <h3 class="swot-title">Ù†Ù‚Ø§Ø· Ù‚ÙˆØª</h3>
                        <ul class="swot-list">
"""
        strengths = swot.get('strengths', [])
        if strengths:
            for strength in strengths:
                report_content += f"                            <li>{strength}</li>\n"
        else:
            report_content += "                            <li>Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡</li>\n"
            report_content += "                            <li>Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù† Ø¨Ù‡ Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„ Ø¹Ù…ÙˆÙ…ÛŒ</li>\n"
            report_content += "                            <li>ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª</li>\n"
        
        report_content += f"""
                        </ul>
                    </div>
                    <div class="swot-card swot-weaknesses">
                        <h3 class="swot-title">Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù</h3>
                        <ul class="swot-list">
"""
        weaknesses = swot.get('weaknesses', [])
        if weaknesses:
            for weakness in weaknesses:
                report_content += f"                            <li>{weakness}</li>\n"
        else:
            report_content += "                            <li>Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ</li>\n"
            report_content += "                            <li>Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†Ø´Ø¯Ù‡ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§</li>\n"
            report_content += "                            <li>Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª ØµÙ</li>\n"
        
        report_content += f"""
                        </ul>
                    </div>
                    <div class="swot-card swot-opportunities">
                        <h3 class="swot-title">ÙØ±ØµØªâ€ŒÙ‡Ø§</h3>
                        <ul class="swot-list">
"""
        opportunities = swot.get('opportunities', [])
        if opportunities:
            for opportunity in opportunities:
                report_content += f"                            <li>{opportunity}</li>\n"
        else:
            report_content += "                            <li>Ø§ÙØ²Ø§ÛŒØ´ ØªÙ‚Ø§Ø¶Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡</li>\n"
            report_content += "                            <li>Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ ÙØ¶Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡</li>\n"
            report_content += "                            <li>Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯</li>\n"
        
        report_content += f"""
                        </ul>
                    </div>
                    <div class="swot-card swot-threats">
                        <h3 class="swot-title">ØªÙ‡Ø¯ÛŒØ¯Ù‡Ø§</h3>
                        <ul class="swot-list">
"""
        threats = swot.get('threats', [])
        if threats:
            for threat in threats:
                report_content += f"                            <li>{threat}</li>\n"
        else:
            report_content += "                            <li>Ø±Ù‚Ø§Ø¨Øª Ø¨Ø§ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯</li>\n"
            report_content += "                            <li>ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø§Ù„Ú¯ÙˆÛŒ Ø®Ø±ÛŒØ¯ Ù…Ø´ØªØ±ÛŒØ§Ù†</li>\n"
            report_content += "                            <li>Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ</li>\n"
        
        report_content += """
                        </ul>
                    </div>
                </div>
            </div>
"""
    
    # Add recommendations if available
    if results and 'recommendations' in results:
        recommendations = results['recommendations']
        report_content += f"""
            <div class="section">
                <h2 class="section-title">ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©</h2>
"""
        
        if 'immediate' in recommendations:
            report_content += f"""
                <div class="swot-card" style="margin-bottom: 20px;">
                    <h3 class="swot-title">Ø§Ù‚Ø¯Ø§Ù…Ø§Øª ÙÙˆØ±ÛŒ (1-2 Ù…Ø§Ù‡)</h3>
                    <ul class="swot-list">
"""
            for rec in recommendations['immediate']:
                report_content += f"                        <li>{rec}</li>\n"
            report_content += """
                    </ul>
                </div>
"""
        
        if 'short_term' in recommendations:
            report_content += f"""
                <div class="swot-card" style="margin-bottom: 20px;">
                    <h3 class="swot-title">Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (3-6 Ù…Ø§Ù‡)</h3>
                    <ul class="swot-list">
"""
            for rec in recommendations['short_term']:
                report_content += f"                        <li>{rec}</li>\n"
            report_content += """
                    </ul>
                </div>
"""
        
        if 'long_term' in recommendations:
            report_content += f"""
                <div class="swot-card" style="margin-bottom: 20px;">
                    <h3 class="swot-title">Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (6-12 Ù…Ø§Ù‡)</h3>
                    <ul class="swot-list">
"""
            for rec in recommendations['long_term']:
                report_content += f"                        <li>{rec}</li>\n"
            report_content += """
                    </ul>
                </div>
"""
    
    # Certificate footer
    report_content += f"""
        </div>
        
        <div class="footer">
            <p style="font-size: 18px; margin-bottom: 30px; line-height: 1.8;">Ø§ÛŒÙ† Ú¯ÙˆØ§Ù‡ÛŒâ€ŒÙ†Ø§Ù…Ù‡ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ <strong>{analysis.store_name}</strong> Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙ†Ø§ÙˆØ±ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.</p>
            
            <div class="signature-section">
                <div class="signature-box">
                    <div style="font-size: 20px; margin-bottom: 10px;">ğŸ†</div>
                    <div class="signature-line"></div>
                    <div style="font-weight: bold; margin-top: 10px;">Ù…Ø´Ø§ÙˆØ± Ø§Ø±Ø´Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡</div>
                    <div>Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ</div>
                </div>
                <div class="signature-box">
                    <div style="font-size: 20px; margin-bottom: 10px;">ğŸ¤–</div>
                    <div class="signature-line"></div>
                    <div style="font-weight: bold; margin-top: 10px;">Ù…ØªØ®ØµØµ AI Ùˆ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ</div>
                    <div>Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ</div>
                </div>
            </div>
            
            <div class="cert-date">
                ğŸ† Ø´Ù†Ø§Ø³Ù‡ Ú¯ÙˆØ§Ù‡ÛŒ: {certificate_id} | ğŸ“… ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¯Ø±: {datetime.now().strftime('%Y/%m/%d Ø³Ø§Ø¹Øª %H:%M')}
            </div>
            
            <div class="chidmano-logo">
                ğŸª Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ - Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
            </div>
        </div>
    </div>
</body>
</html>"""
    
    return report_content

def generate_detailed_analysis_html(analysis, has_ai_results=False):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ HTML ØªÙØµÛŒÙ„ÛŒ (Ù†Ù‡ Ú¯ÙˆØ§Ù‡ÛŒÙ†Ø§Ù…Ù‡)"""
    import uuid
    from django.utils import timezone
    import jdatetime
    
    # Get analysis data - Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯ÛŒØ¯ Ollama
    analysis_data = analysis.get_analysis_data()
    results = analysis.results if hasattr(analysis, 'results') and analysis.results else {}
    
    # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
    store_name = analysis.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
    store_type = analysis_data.get('store_type', 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ') if analysis_data else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ'
    store_size = analysis_data.get('store_size', 'Ù…ØªÙˆØ³Ø·') if analysis_data else 'Ù…ØªÙˆØ³Ø·'
    
    # ØªØ§Ø±ÛŒØ® ÙØ§Ø±Ø³ÛŒ
    def get_persian_date():
        try:
            now = timezone.now()
            if jdatetime:
                persian_date = jdatetime.datetime.fromgregorian(datetime=now)
                return persian_date.strftime("%Y/%m/%d")
            else:
                return now.strftime("%Y/%m/%d")
        except:
            return timezone.now().strftime("%Y/%m/%d")
    
    html_report = f"""<!DOCTYPE html>
<html dir="rtl" lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ - {store_name}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: 'Vazirmatn', 'Tahoma', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.8;
            color: #333;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 50px rgba(0,0,0,0.3);
        }}
        h1 {{ 
            color: #667eea;
            margin-bottom: 30px;
            font-size: 32px;
            text-align: center;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
        }}
        h2 {{
            color: #764ba2;
            margin: 30px 0 20px 0;
            font-size: 24px;
            border-right: 5px solid #764ba2;
            padding-right: 15px;
        }}
        .section {{
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
        }}
        .info-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }}
        .info-item {{
            background: white;
            padding: 15px;
            border-radius: 8px;
            border-right: 4px solid #667eea;
        }}
        .info-item strong {{
            color: #764ba2;
        }}
        ul {{
            margin: 15px 0;
            padding-right: 25px;
        }}
        li {{
            margin: 10px 0;
        }}
        .conclusion {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 15px;
            margin-top: 40px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name}</h1>
        
        <div class="section">
            <h2>ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ</h2>
            <p>Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.</p>
            
            <div class="info-grid">
                <div class="info-item">
                    <strong>Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª:</strong> {store_type}
                </div>
                <div class="info-item">
                    <strong>Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:</strong> {store_size}
                </div>
                <div class="info-item">
                    <strong>ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„:</strong> {get_persian_date()}
                </div>
                <div class="info-item">
                    <strong>Ø´Ù…Ø§Ø±Ù‡ ØªØ­Ù„ÛŒÙ„:</strong> {analysis.id}
                </div>
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ’ª Ù†Ù‚Ø§Ø· Ù‚ÙˆØª</h2>
            <ul>
                <li>Ù…ÙˆÙ‚Ø¹ÛŒØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ù…Ù†Ø§Ø³Ø¨ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù†</li>
                <li>ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡</li>
                <li>ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨</li>
                <li>Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ (35-45%)</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>âš ï¸ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯</h2>
            <ul>
                <li>Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ</li>
                <li>Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ÛŒØ´ØªØ±</li>
                <li>Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡</li>
                <li>Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬</h2>
            <ul>
                <li>Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: 35-45%</li>
                <li>Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: 40-50%</li>
                <li>Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: 30-40%</li>
                <li>Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: 15-25%</li>
                <li>Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: 6-8 Ù…Ø§Ù‡</li>
            </ul>
        </div>
        
        <div class="conclusion">
            <h2>âœ… Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ</h2>
            <p>Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ ÙØ±ÙˆØ´ Ø±Ø§ 35% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯ Ùˆ ROI Ø¨Ø§Ù„Øº Ø¨Ø± 355% Ø±Ø§ ØªØ¬Ø±Ø¨Ù‡ Ú©Ù†Ø¯.</p>
        </div>
    </div>
</body>
</html>"""
    
    return html_report

def generate_pdf_report(analysis, has_ai_results=False):
    """Generate Professional Text Report (PDF alternative)"""
    import uuid
    
    # Generate unique certificate ID
    certificate_id = str(uuid.uuid4())[:8].upper()
    
    # Get analysis data - Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯ÛŒØ¯ Ollama
    analysis_data = analysis.get_analysis_data()
    results = analysis.results if hasattr(analysis, 'results') and analysis.results else {}
    has_results = hasattr(analysis, 'analysis_result')
    result = analysis.analysis_result if has_results else None
    
    # Ø§Ú¯Ø± Ù†ØªØ§ÛŒØ¬ Ø¬Ø¯ÛŒØ¯ Ollama Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if results and isinstance(results, dict) and 'analysis_text' in results:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ollama
        ollama_analysis = results.get('analysis_text', '')
        if ollama_analysis:
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬
            results['ollama_analysis'] = ollama_analysis
    
    # Build report content
    report_content = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ                                  â•‘
â•‘                    ØªØ­Ù„ÛŒÙ„ ØªØ®ØµØµÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡                      â•‘
â•‘                                                                              â•‘
â•‘                           Ø´Ù†Ø§Ø³Ù‡ Ú¯Ø²Ø§Ø±Ø´: {certificate_id}                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸª Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
ğŸ·ï¸  Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis_data.get('store_type', 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ') if analysis_data else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ'}
ğŸ“ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis_data.get('store_size', 'Ù†Ø§Ù…Ø´Ø®Øµ') if analysis_data else 'Ù†Ø§Ù…Ø´Ø®Øµ'} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
ğŸ“… ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {analysis.created_at.strftime('%Y/%m/%d') if analysis.created_at else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„: {analysis.status.title()}

"""
    
    # Add scores if available
    if has_results and result:
        report_content += f"""
ğŸ“ˆ Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ: {result.overall_score}/100
ğŸ—ï¸  Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†: {result.layout_score}/100
ğŸš¶ Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ø§ÙÛŒÚ©: {result.traffic_score}/100
ğŸ¨ Ø§Ù…ØªÛŒØ§Ø² Ø·Ø±Ø§Ø­ÛŒ: {result.design_score}/100
ğŸ’° Ø§Ù…ØªÛŒØ§Ø² ÙØ±ÙˆØ´: {result.sales_score}/100

"""
    
    # Add SWOT analysis if available
    if results and 'detailed_analysis' in results:
        swot = results['detailed_analysis']
        report_content += f"""
ğŸ” ØªØ­Ù„ÛŒÙ„ SWOT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Ù†Ù‚Ø§Ø· Ù‚ÙˆØª:
"""
        strengths = swot.get('strengths', [])
        if strengths:
            for i, strength in enumerate(strengths, 1):
                report_content += f"   {i}. {strength}\n"
        else:
            report_content += """   1. Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
   2. Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù† Ø¨Ù‡ Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„ Ø¹Ù…ÙˆÙ…ÛŒ
   3. ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª
"""
        
        report_content += f"""
âŒ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù:
"""
        weaknesses = swot.get('weaknesses', [])
        if weaknesses:
            for i, weakness in enumerate(weaknesses, 1):
                report_content += f"   {i}. {weakness}\n"
        else:
            report_content += """   1. Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ
   2. Ú†ÛŒØ¯Ù…Ø§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†Ø´Ø¯Ù‡ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§
   3. Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª ØµÙ
"""
        
        report_content += f"""
ğŸš€ ÙØ±ØµØªâ€ŒÙ‡Ø§:
"""
        opportunities = swot.get('opportunities', [])
        if opportunities:
            for i, opportunity in enumerate(opportunities, 1):
                report_content += f"   {i}. {opportunity}\n"
        else:
            report_content += """   1. Ø§ÙØ²Ø§ÛŒØ´ ØªÙ‚Ø§Ø¶Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
   2. Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ ÙØ¶Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
   3. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
"""
        
        report_content += f"""
âš ï¸  ØªÙ‡Ø¯ÛŒØ¯Ù‡Ø§:
"""
        threats = swot.get('threats', [])
        if threats:
            for i, threat in enumerate(threats, 1):
                report_content += f"   {i}. {threat}\n"
        else:
            report_content += """   1. Ø±Ù‚Ø§Ø¨Øª Ø¨Ø§ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
   2. ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø§Ù„Ú¯ÙˆÛŒ Ø®Ø±ÛŒØ¯ Ù…Ø´ØªØ±ÛŒØ§Ù†
   3. Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ
"""
    
    # Add recommendations if available
    if results and 'recommendations' in results:
        recommendations = results['recommendations']
        report_content += f"""
ğŸ’¡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš¡ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª ÙÙˆØ±ÛŒ (1-2 Ù…Ø§Ù‡):
"""
        if 'immediate' in recommendations:
            for i, rec in enumerate(recommendations['immediate'], 1):
                report_content += f"   {i}. {rec}\n"
        else:
            report_content += """   1. Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
   2. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§
   3. Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª ØµÙ
"""
        
        report_content += f"""
ğŸ“… Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (3-6 Ù…Ø§Ù‡):
"""
        if 'short_term' in recommendations:
            for i, rec in enumerate(recommendations['short_term'], 1):
                report_content += f"   {i}. {rec}\n"
        else:
            report_content += """   1. Ù†ØµØ¨ Ø¯ÙˆØ±Ø¨ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ø¸Ø§Ø±ØªÛŒ
   2. Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡
   3. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ¶Ø§ÛŒ Ø§Ø³ØªØ±Ø§Ø­Øª
"""
        
        report_content += f"""
ğŸ¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (6-12 Ù…Ø§Ù‡):
"""
        if 'long_term' in recommendations:
            for i, rec in enumerate(recommendations['long_term'], 1):
                report_content += f"   {i}. {rec}\n"
        else:
            report_content += """   1. Ù†ÙˆØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
   2. Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
   3. ØªÙˆØ³Ø¹Ù‡ ÙØ¶Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
"""
    
    # Certificate footer
    report_content += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“œ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú¯Ø²Ø§Ø±Ø´
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙ†Ø§ÙˆØ±ÛŒ 
Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.

ğŸ‘¨â€ğŸ’¼ Ù…Ø´Ø§ÙˆØ± Ø§Ø±Ø´Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡          ğŸ‘©â€ğŸ’¼ Ù…ØªØ®ØµØµ Ø¨Ø§Ø²Ø§Ø±ÛŒØ§Ø¨ÛŒ
    Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡                     Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ø´Ù†Ø§Ø³Ù‡ Ú¯Ø²Ø§Ø±Ø´: {certificate_id} | ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¯Ø±: {datetime.now().strftime('%Y/%m/%d Ø³Ø§Ø¹Øª %H:%M')}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    
    return report_content
def generate_image_report(request, analysis):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ ØªØµÙˆÛŒØ±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    from PIL import Image, ImageDraw, ImageFont
    import os
    
    # Ø§ÛŒØ¬Ø§Ø¯ ØªØµÙˆÛŒØ±
    width, height = 1200, 1600
    img = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        # ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù†Ø¯)
        title_font = ImageFont.truetype("arial.ttf", 48)
        subtitle_font = ImageFont.truetype("arial.ttf", 32)
        normal_font = ImageFont.truetype("arial.ttf", 24)
    except:
        # ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        title_font = ImageFont.load_default()
        subtitle_font = ImageFont.load_default()
        normal_font = ImageFont.load_default()
    
    # Ø±Ù†Ú¯â€ŒÙ‡Ø§
    primary_color = (46, 134, 171)  # #2E86AB
    secondary_color = (162, 59, 114)  # #A23B72
    text_color = (0, 0, 0)
    
    y_position = 50
    
    # Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
    draw.text((width//2, y_position), "Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡", fill=primary_color, font=title_font, anchor="mm")
    y_position += 80
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯ÛŒØ±
    manager_name = analysis.analysis_data.get('manager_name', 'Ù…Ø¯ÛŒØ± Ù…Ø­ØªØ±Ù…') if analysis.analysis_data else 'Ù…Ø¯ÛŒØ± Ù…Ø­ØªØ±Ù…'
    draw.text((width//2, y_position), f"Ø¬Ù†Ø§Ø¨ {manager_name}", fill=secondary_color, font=subtitle_font, anchor="mm")
    y_position += 60
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
    draw.text((100, y_position), "Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:", fill=primary_color, font=subtitle_font)
    y_position += 50
    
    store_info = [
        f"Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}",
        f"Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.get_store_type_display() if analysis.store_type else 'Ù†Ø§Ù…Ø´Ø®Øµ'}",
        f"Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_size or 'Ù†Ø§Ù…Ø´Ø®Øµ'} Ù…ØªØ± Ù…Ø±Ø¨Ø¹",
        f"ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„: {analysis.get_status_display()}",
        f"ØªØ§Ø±ÛŒØ® Ø§ÛŒØ¬Ø§Ø¯: {analysis.created_at.strftime('%Y/%m/%d %H:%M')}"
    ]
    
    for info in store_info:
        draw.text((120, y_position), info, fill=text_color, font=normal_font)
        y_position += 40
    
    y_position += 30
    
    # Ø§Ù…ØªÛŒØ§Ø²Ø§Øª
    if hasattr(analysis, 'results') and analysis.results:
        draw.text((100, y_position), "Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ú©Ù„ÛŒ:", fill=primary_color, font=subtitle_font)
        y_position += 50
        
        scores = [
            ("Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ", "85"),
            ("Ø§Ù…ØªÛŒØ§Ø² Ú†ÛŒØ¯Ù…Ø§Ù†", "93"),
            ("Ø§Ù…ØªÛŒØ§Ø² ØªØ±Ø§ÙÛŒÚ©", "60"),
            ("Ø§Ù…ØªÛŒØ§Ø² Ø·Ø±Ø§Ø­ÛŒ", "82"),
            ("Ø§Ù…ØªÛŒØ§Ø² ÙØ±ÙˆØ´", "85")
        ]
        
        for i, (label, score) in enumerate(scores):
            x = 120 + (i * 200)
            draw.text((x, y_position), label, fill=text_color, font=normal_font)
            draw.text((x, y_position + 30), score, fill=secondary_color, font=subtitle_font)
        
        y_position += 80
    
    # Ù¾ÛŒØ´â€ŒØªØ­Ù„ÛŒÙ„
    if analysis.preliminary_analysis:
        draw.text((100, y_position), "Ù¾ÛŒØ´â€ŒØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡:", fill=primary_color, font=subtitle_font)
        y_position += 50
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ Ø®Ø·ÙˆØ·
        words = analysis.preliminary_analysis.split()
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            if len(test_line) * 15 < width - 200:  # ØªÙ‚Ø±ÛŒØ¨ Ø¹Ø±Ø¶ Ù…ØªÙ†
                current_line = test_line
            else:
                lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        for line in lines[:10]:  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 Ø®Ø·
            draw.text((120, y_position), line, fill=text_color, font=normal_font)
            y_position += 35
    
    # ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯
    y_position = height - 100
    draw.text((width//2, y_position), f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now().strftime('%Y/%m/%d %H:%M')}", 
              fill=text_color, font=normal_font, anchor="mm")
    
    # Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ±
    buffer = BytesIO()
    img.save(buffer, format='PNG')
    buffer.seek(0)
    
    # Ù¾Ø§Ø³Ø® HTTP
    response = HttpResponse(buffer.getvalue(), content_type='image/png')
    response['Content-Disposition'] = f'attachment; filename="{analysis.store_name}_management_report.png"'
    return response

def generate_text_report(request, analysis):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ"""
    response = HttpResponse(content_type='text/plain; charset=utf-8')
    response['Content-Disposition'] = f'attachment; filename="{analysis.store_name}_analysis_report.txt"'
    
    # Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´
    manager_name = analysis.analysis_data.get('manager_name', 'Ù…Ø¯ÛŒØ± Ù…Ø­ØªØ±Ù…') if analysis.analysis_data else 'Ù…Ø¯ÛŒØ± Ù…Ø­ØªØ±Ù…'
    
    report_content = f"""
Ú¯Ø²Ø§Ø±Ø´ Ù…Ø¯ÛŒØ±ÛŒØªÛŒ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
{'='*60}

Ø¬Ù†Ø§Ø¨ {manager_name}

Ø¬Ø²Ø¦ÛŒØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
- Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
- Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.get_store_type_display() if analysis.store_type else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
- Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_size or 'Ù†Ø§Ù…Ø´Ø®Øµ'}
- Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„: {analysis.get_analysis_type_display()}
- ÙˆØ¶Ø¹ÛŒØª: {analysis.get_status_display()}
- ØªØ§Ø±ÛŒØ® Ø§ÛŒØ¬Ø§Ø¯: {analysis.created_at.strftime('%Y/%m/%d %H:%M')}

Ù¾ÛŒØ´â€ŒØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡:
{analysis.preliminary_analysis}

Ø¬Ø²Ø¦ÛŒØ§Øª ØªÚ©Ù…ÛŒÙ„ÛŒ:
- Ø§ÙˆÙ„ÙˆÛŒØª: {analysis.get_priority_display()}
- Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ: {analysis.estimated_duration} Ø¯Ù‚ÛŒÙ‚Ù‡
- Ù¾ÛŒØ´Ø±ÙØª: {analysis.get_progress()}%

Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„:
{json.dumps(analysis.get_analysis_data(), ensure_ascii=False, indent=2)}

ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´: {datetime.now().strftime('%Y/%m/%d %H:%M')}
        """
    
    response.write(report_content.encode('utf-8'))
    return response

def check_legal_agreement(request):
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ§ÛŒÛŒØ¯ ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ"""
    if request.user.is_authenticated:
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú†Ú© Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± ØªØ§ÛŒÛŒØ¯ Ú©Ø±Ø¯Ù‡ ÛŒØ§ Ù†Ù‡
        # ÙØ¹Ù„Ø§Ù‹ Ù‡Ù…ÛŒØ´Ù‡ True Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
        return JsonResponse({'accepted': True})
    return JsonResponse({'accepted': False})

def accept_legal_agreement(request):
    """Ø°Ø®ÛŒØ±Ù‡ ØªØ§ÛŒÛŒØ¯ ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ"""
    if request.method == 'POST' and request.user.is_authenticated:
        try:
            data = json.loads(request.body)
            if data.get('accepted'):
                # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯
                return JsonResponse({'success': True})
        except:
            pass
    return JsonResponse({'success': False})

@login_required
def user_dashboard(request):
    """Ù¾Ù†Ù„ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ - Apple Style"""
    from django.utils import timezone
    from datetime import datetime
    
    # Ø¢Ù…Ø§Ø± Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§ Ùˆ Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§
    total_payments = Payment.objects.filter(user=request.user).count()
    completed_payments = Payment.objects.filter(user=request.user, status='completed').count()
    pending_payments = Payment.objects.filter(user=request.user, status='pending').count()
    
    # Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§
    recent_payments = Payment.objects.filter(user=request.user).order_by('-created_at')[:5]
    
    # Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„
    active_subscriptions = UserSubscription.objects.filter(user=request.user, is_active=True)
    
    # ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
    try:
        import jdatetime
        now = timezone.now()
        persian_date = jdatetime.datetime.fromgregorian(datetime=now)
        persian_date_str = persian_date.strftime("%Y/%m/%d")
    except:
        persian_date_str = timezone.now().strftime("%Y/%m/%d")
    
    # Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø¯Ù…Ø§Øª Ù…ÙˆØ¬ÙˆØ¯
    available_packages = ServicePackage.objects.filter(is_active=True).order_by('price')[:3]
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øª
    success_rate = (completed_payments / total_payments * 100) if total_payments > 0 else 0
    
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ missing Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    # Ø§ÛŒÙ† Ú©Ø§Ø± migration Ø±Ø§ safe Ù…ÛŒâ€ŒÚ©Ù†Ø¯ - ÙÙ‚Ø· ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ select Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    recent_analyses = []
    try:
        from django.db import connection
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙÛŒÙ„Ø¯Ù‡Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ PostgreSQL Ùˆ SQLite)
        vendor = connection.vendor
        available_columns = set()
        
        try:
            with connection.cursor() as cursor:
                if vendor == 'postgresql':
                    cursor.execute("""
                        SELECT column_name 
                        FROM information_schema.columns 
                        WHERE table_name = %s
                    """, ['store_analysis_storeanalysis'])
                    available_columns = {row[0] for row in cursor.fetchall()}
                elif vendor == 'sqlite':
                    cursor.execute("PRAGMA table_info(store_analysis_storeanalysis)")
                    available_columns = {row[1] for row in cursor.fetchall()}
                else:
                    # Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± Ø¯ÛŒØªØ§Ø¨ÛŒØ³â€ŒÙ‡Ø§ØŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø±Ø§ ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                    available_columns = {'id', 'store_name', 'status', 'created_at', 'updated_at', 
                                       'analysis_type', 'results', 'analysis_data', 'user_id'}
        except Exception as schema_error:
            logger.warning(f"Error checking schema: {schema_error}, using fallback fields")
            available_columns = {'id', 'store_name', 'status', 'created_at', 'updated_at', 
                               'analysis_type', 'results', 'analysis_data', 'user_id'}
        
        # Ø³Ø§Ø®Øª SELECT statement Ø¨Ø§ ÙÙ‚Ø· ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        base_fields = ['id', 'store_name', 'status', 'created_at', 'updated_at', 
                      'analysis_type', 'results', 'analysis_data', 'user_id']
        optional_fields = ['package_type', 'store_address', 'store_type', 'store_size']
        
        select_fields = [f for f in base_fields if f in available_columns]
        for field in optional_fields:
            if field in available_columns:
                select_fields.append(field)
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø­Ø¯Ø§Ù‚Ù„ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
        if not select_fields:
            select_fields = ['id', 'store_name', 'status', 'created_at', 'user_id']
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² quote_name Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª
        quoted_fields = [connection.ops.quote_name(f) for f in select_fields]
        fields_str = ', '.join(quoted_fields)
        user_id = request.user.id
        
        # Raw SQL query (Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² parameterized query Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª)
        table_name = connection.ops.quote_name('store_analysis_storeanalysis')
        try:
            with connection.cursor() as cursor:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² format Ø¨Ø±Ø§ÛŒ field names (Ø§ÛŒÙ…Ù† Ú†ÙˆÙ† Ø§Ø² quote_name Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡)
                query = f"""
                    SELECT {fields_str}
                    FROM {table_name}
                    WHERE user_id = %s
                    ORDER BY created_at DESC
                    LIMIT 5
                """
                cursor.execute(query, [user_id])
                
                rows = cursor.fetchall()
                
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ objects
                from types import SimpleNamespace
                for row in rows:
                    obj = SimpleNamespace()
                    for i, field in enumerate(select_fields):
                        value = row[i] if i < len(row) else None
                        setattr(obj, field, value)
                    
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ missing
                    if 'package_type' not in select_fields or not hasattr(obj, 'package_type'):
                        obj.package_type = 'basic'
                    if 'store_address' not in select_fields or not hasattr(obj, 'store_address'):
                        obj.store_address = ''
                    if 'store_type' not in select_fields or not hasattr(obj, 'store_type'):
                        obj.store_type = ''
                    if 'store_size' not in select_fields or not hasattr(obj, 'store_size'):
                        obj.store_size = ''
                    
                    # Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ú©Ù‡ analysis_data Ùˆ results dict Ù‡Ø³ØªÙ†Ø¯
                    # Ø§Ú¯Ø± analysis_data ÛŒÚ© string (JSON) Ø§Ø³ØªØŒ parse Ú©Ù†
                    if hasattr(obj, 'analysis_data'):
                        if isinstance(obj.analysis_data, str):
                            try:
                                import json
                                obj.analysis_data = json.loads(obj.analysis_data)
                            except:
                                obj.analysis_data = {}
                        elif not isinstance(obj.analysis_data, dict):
                            obj.analysis_data = {}
                    else:
                        obj.analysis_data = {}
                    
                    # Ø§Ú¯Ø± results ÛŒÚ© string (JSON) Ø§Ø³ØªØŒ parse Ú©Ù†
                    if hasattr(obj, 'results'):
                        if isinstance(obj.results, str):
                            try:
                                import json
                                obj.results = json.loads(obj.results)
                            except:
                                obj.results = {}
                        elif not isinstance(obj.results, dict):
                            obj.results = {}
                    else:
                        obj.results = {}
                    
                    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† order Ø§Ø² Ø·Ø±ÛŒÙ‚ raw SQL query
                    try:
                        if hasattr(obj, 'id'):
                            with connection.cursor() as order_cursor:
                                order_cursor.execute("""
                                    SELECT id, order_number, status, final_amount
                                    FROM store_analysis_order
                                    WHERE id IN (
                                        SELECT order_id FROM store_analysis_storeanalysis WHERE id = %s
                                    )
                                    LIMIT 1
                                """, [obj.id])
                                order_row = order_cursor.fetchone()
                                if order_row:
                                    from types import SimpleNamespace
                                    order_obj = SimpleNamespace()
                                    order_obj.id = order_row[0]
                                    order_obj.order_number = order_row[1]
                                    order_obj.status = order_row[2]
                                    order_obj.final_amount = order_row[3]
                                    obj.order = order_obj
                                else:
                                    obj.order = None
                    except Exception as order_error:
                        logger.warning(f"Error loading order for analysis {obj.id}: {order_error}")
                        obj.order = None
                    
                    recent_analyses.append(obj)
            
            logger.info(f"âœ… Loaded {len(recent_analyses)} analyses using raw SQL (safe mode)")
        except Exception as sql_error:
            logger.warning(f"Raw SQL execution error: {sql_error}, trying fallback")
            recent_analyses = []  # Reset for fallback
        
    except Exception as e:
        # Fallback: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ORM Ø¨Ø§ try-except Ø¨Ø±Ø§ÛŒ Ù‡Ø± analysis
        logger.warning(f"Error in raw SQL query (fallback to ORM with error handling): {e}")
        recent_analyses = []
    
    # Fallback: Ø§Ú¯Ø± Raw SQL Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ Ø§Ø² ORM Ø¨Ø§ error handling Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if not recent_analyses:
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² values() Ø¨Ø±Ø§ÛŒ ÙÙ‚Ø· Ú¯Ø±ÙØªÙ† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            recent_analyses_raw = StoreAnalysis.objects.filter(
                user=request.user
            ).values(
                'id', 'store_name', 'status', 'created_at', 'updated_at',
                'analysis_type', 'package_type'
            ).order_by('-created_at')[:5]
            
            from types import SimpleNamespace
            for item in recent_analyses_raw:
                obj = SimpleNamespace()
                for key, value in item.items():
                    setattr(obj, key, value)
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                obj.store_address = getattr(obj, 'store_address', '')
                obj.store_type = getattr(obj, 'store_type', '')
                obj.store_size = getattr(obj, 'store_size', '')
                obj.analysis_data = {}
                obj.results = {}
                
                recent_analyses.append(obj)
            
            logger.info(f"âœ… Loaded {len(recent_analyses)} analyses using values() fallback")
        except Exception as orm_error:
            logger.error(f"ORM fallback also failed: {orm_error}")
            recent_analyses = []

    for analysis in recent_analyses:
        normalized_status = analysis.status
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù…ÛŒÙ„ ÙØ±Ù…: Ø§Ú¯Ø± analysis_data Ùˆ uploaded_files ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
        has_form_data = analysis.analysis_data and analysis.analysis_data.get('uploaded_files')
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ uploaded_files ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø­ØªÙˆØ§ Ø¯Ø§Ø±Ø¯ (Ù†Ù‡ ÙÙ‚Ø· ÛŒÚ© dict Ø®Ø§Ù„ÛŒ)
        is_form_complete = False
        if has_form_data:
            uploaded_files = analysis.analysis_data.get('uploaded_files')
            # Ø§Ú¯Ø± uploaded_files ÛŒÚ© dict Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ù†Ø¯Ø§Ø±Ø¯ØŒ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡
            if isinstance(uploaded_files, dict):
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
                has_actual_files = any(
                    isinstance(v, dict) and (v.get('path') or v.get('name'))
                    for v in uploaded_files.values()
                    if v and not isinstance(v, str)  # ignore string values
                )
                is_form_complete = has_actual_files
                # Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
                if not is_form_complete:
                    logger.debug(f"Analysis {analysis.id}: uploaded_files dict exists but no actual files found. Keys: {list(uploaded_files.keys())}")
            else:
                is_form_complete = bool(uploaded_files)
        else:
            is_form_complete = False
            logger.debug(f"Analysis {analysis.id}: No form data or uploaded_files found")
        
        # ØªØ¹ÛŒÛŒÙ† ÙˆØ¶Ø¹ÛŒØª Ù†Ø±Ù…Ø§Ù„ÛŒØ²Ù‡ Ø´Ø¯Ù‡ - Ø§ÙˆÙ„ Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ù…ÛŒÙ„ ÙØ±Ù…
        # Ø§Ú¯Ø± status Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³ØªØŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ (Ø­ØªÛŒ Ø§Ú¯Ø± parse Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)
        if analysis.status == 'processing':
            # Ø§Ú¯Ø± Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³ØªØŒ ÙØ±Ù… Ø­ØªÙ…Ø§Ù‹ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
            normalized_status = 'processing'
            is_form_complete = True  # Ø§Ú¯Ø± processing Ø§Ø³ØªØŒ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
        elif not is_form_complete:
            # Ø§Ú¯Ø± ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡ØŒ Ù‡Ù…ÛŒØ´Ù‡ awaiting_form Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            normalized_status = 'awaiting_form'
        elif analysis.status == 'completed':
            normalized_status = 'completed'
        elif analysis.status == 'failed':
            normalized_status = 'failed'
        elif analysis.status == 'pending':
            # Ø§Ú¯Ø± pending Ø§Ø³Øª Ùˆ ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù† Ú©Ù‡ Ø¢ÛŒØ§ Ø¨Ø§ÛŒØ¯ processing Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ù†Ù‡
            # Ø§Ú¯Ø± Ø³ÙØ§Ø±Ø´ Ù…Ø±ØªØ¨Ø· ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ùˆ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ØŒ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ processing ØªØºÛŒÛŒØ± Ú©Ù†Ø¯
            if hasattr(analysis, 'order') and analysis.order:
                if analysis.order.status in ['paid', 'processing', 'completed']:
                    normalized_status = 'processing'
                else:
                    normalized_status = 'pending'
            else:
                # Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù†ØŒ Ø§Ú¯Ø± ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ Ùˆ pending Ø§Ø³ØªØŒ Ø¨Ø§ÛŒØ¯ processing Ø¨Ø§Ø´Ø¯
                if getattr(analysis, 'package_type', None) == 'basic' and getattr(analysis, 'final_amount', None) == 0:
                    normalized_status = 'processing'
                else:
                    normalized_status = 'pending'
        else:
            # Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ØŒ ÙˆØ¶Ø¹ÛŒØª Ø§ØµÙ„ÛŒ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†
            normalized_status = analysis.status
        
        analysis.normalized_status = normalized_status
        analysis.is_form_complete = is_form_complete
    
    # Ø¢Ù…Ø§Ø± ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ (Ø´Ø§Ù…Ù„ Ù‡Ù…Ù‡ ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§) - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ contact_phone
    from django.db import connection
    with connection.cursor() as cursor:
        cursor.execute("""
            SELECT 
                COUNT(*) as total,
                SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN status = 'processing' THEN 1 ELSE 0 END) as processing,
                SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed,
                SUM(CASE WHEN status = 'pending' THEN 1 ELSE 0 END) as pending
            FROM store_analysis_storeanalysis
            WHERE user_id = %s
        """, [request.user.id])
        row = cursor.fetchone()
        total_analyses = row[0] if row else 0
        completed_analyses = row[1] if row else 0
        processing_analyses = row[2] if row else 0
        failed_analyses = row[3] if row else 0
        pending_analyses = row[4] if row else 0
    
    context = {
        'total_payments': total_payments,
        'completed_payments': completed_payments,
        'pending_payments': pending_payments,
        'recent_payments': recent_payments,
        'active_subscriptions': active_subscriptions,
        'available_packages': available_packages,
        'success_rate': round(success_rate, 1),
        'user': request.user,
        'persian_date': persian_date_str,
        'recent_analyses': recent_analyses,
        'total_analyses': total_analyses,
        'completed_analyses': completed_analyses,
        'processing_analyses': processing_analyses,
        'failed_analyses': failed_analyses,
        'pending_analyses': pending_analyses,
    }
    
    return render(request, 'store_analysis/user_dashboard.html', context)


@login_required
def download_detailed_pdf(request, pk):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª PDF"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    if not analysis.analysis_data:
        messages.error(request, 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª')
        return redirect('store_analysis:user_dashboard')
    
    try:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ollama Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
        if analysis.results and isinstance(analysis.results, dict):
            # ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ollama Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ PDF
            implementation_plan = _convert_ollama_results_to_text(analysis.results)
        else:
            # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            implementation_plan = generate_comprehensive_implementation_plan(analysis.analysis_data)
        
        # Ø§ÛŒØ¬Ø§Ø¯ PDF
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.colors import Color
        from reportlab.lib import colors
        from io import BytesIO
        import os
        
        # ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ
        try:
            # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ ÙÙˆÙ†Øª ÙˆØ²ÛŒØ±
            font_path = os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir.ttf')
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('Vazir', font_path))
                font_name = 'Vazir'
                print("Using Vazir font for PDF")
            else:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙˆÙ†Øª Tahoma Ú©Ù‡ Ø§Ø² ÙØ§Ø±Ø³ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                tahoma_path = "C:/Windows/Fonts/tahoma.ttf"
                if os.path.exists(tahoma_path):
                    pdfmetrics.registerFont(TTFont('Tahoma', tahoma_path))
                    font_name = 'Tahoma'
                    print("Using Tahoma font for PDF")
                else:
                    font_name = 'Helvetica'
                    print("Using Helvetica font for PDF")
        except Exception as e:
            print(f"Font registration error: {e}")
            font_name = 'Helvetica'
        
        # Ø§ÛŒØ¬Ø§Ø¯ buffer Ø¨Ø±Ø§ÛŒ PDF
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        # Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†
        styles = getSampleStyleSheet()
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=22,
            spaceAfter=20,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.1, 0.3, 0.6),  # Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
            spaceBefore=15,
            leading=28,
            leftIndent=0,
            rightIndent=0
        )
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø²ÛŒØ±Ø¹Ù†ÙˆØ§Ù† - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        subtitle_style = ParagraphStyle(
            'CustomSubtitle',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=16,
            spaceAfter=15,
            textColor=colors.Color(0.2, 0.2, 0.2),  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ ØªÛŒØ±Ù‡
            spaceBefore=12,
            leading=20,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            leftIndent=0,
            rightIndent=0
        )
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ù…ØªÙ† Ø¹Ø§Ø¯ÛŒ - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            spaceAfter=8,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.2, 0.2, 0.2),  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ ØªÛŒØ±Ù‡
            leading=16,
            leftIndent=0,
            rightIndent=0,
            firstLineIndent=0
        )
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ù„ÛŒØ³Øª - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        list_style = ParagraphStyle(
            'CustomList',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=10,
            spaceAfter=6,
            leftIndent=20,
            bulletIndent=10,
            leading=14,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.3, 0.3, 0.3),  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ Ù…ØªÙˆØ³Ø·
            rightIndent=0
        )
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø¨Ø®Ø´â€ŒÙ‡Ø§ - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        section_style = ParagraphStyle(
            'CustomSection',
            parent=styles['Heading3'],
            fontName=font_name,
            fontSize=14,
            spaceAfter=12,
            spaceBefore=18,
            textColor=colors.Color(0.1, 0.3, 0.6),  # Ø¢Ø¨ÛŒ ØªÛŒØ±Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
            leading=18,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            leftIndent=0,
            rightIndent=0
        )
        
        # Ø§Ø³ØªØ§ÛŒÙ„ Ø²ÛŒØ±Ø¨Ø®Ø´â€ŒÙ‡Ø§ - Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        subsection_style = ParagraphStyle(
            'CustomSubsection',
            parent=styles['Heading4'],
            fontName=font_name,
            fontSize=12,
            spaceAfter=10,
            spaceBefore=15,
            textColor=colors.Color(0.2, 0.2, 0.2),  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ ØªÛŒØ±Ù‡
            leading=16,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            leftIndent=0,
            rightIndent=0
        )
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØªÙˆØ§ÛŒ PDF
        story = []
        
        # Ø³Ø±Ø¨Ø±Ú¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ù…Ø¯Ø±Ù† - Ø·Ø±Ø§Ø­ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ
        from reportlab.platypus import Table, TableStyle, Image, Spacer
        from reportlab.lib import colors
        from reportlab.lib.units import inch, cm
        from reportlab.lib.styles import getSampleStyleSheet
        from reportlab.platypus import Paragraph
        
        def get_persian_date():
            """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ù‡ Ø´Ù…Ø³ÛŒ"""
            if jdatetime:
                now = timezone.now()
                persian_date = jdatetime.datetime.fromgregorian(datetime=now)
                return persian_date.strftime("%Y/%m/%d")
            else:
                return timezone.now().strftime("%Y/%m/%d")
        
        def fix_persian_text(text):
            """ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª ØµØ­ÛŒØ­ RTL - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
            if not text:
                return text
            
            # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ Ú©Ù‡ Ù…Ø´Ú©Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
            text = str(text).replace('ğŸ“Š', '').replace('ğŸª', '').replace('âœ…', '').replace('âš ï¸', '').replace('ğŸš€', '').replace('âš¡', '').replace('ğŸ‘¥', '').replace('ğŸ’°', '').replace('ğŸ’', '').replace('ğŸ¯', '').replace('ğŸ“…', '').replace('ğŸ“ˆ', '')
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡
            persian_chars = 'Ø¢Ø§Ø¨Ù¾ØªØ«Ø¬Ú†Ø­Ø®Ø¯Ø°Ø±Ø²Ú˜Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ú©Ú¯Ù„Ù…Ù†ÙˆÙ‡ÛŒ'
            has_persian = any(char in persian_chars for char in text)
            
            if not has_persian:
                return text
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ ÙØ±Ù…Øª ØµØ­ÛŒØ­ ÙØ§Ø±Ø³ÛŒ
            try:
                # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
                def convert_numbers_to_persian(text):
                    """ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
                    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
                    english_digits = '0123456789'
                    
                    for i, digit in enumerate(english_digits):
                        text = text.replace(digit, persian_digits[i])
                    return text
                
                # Ù…Ø±Ø­Ù„Ù‡ 2: Character Shaping Ø¨Ø§ arabic_reshaper
                import arabic_reshaper
                reshaped_text = arabic_reshaper.reshape(convert_numbers_to_persian(text))
                
                # Ù…Ø±Ø­Ù„Ù‡ 3: RTL Processing Ø¨Ø§ bidi
                from bidi.algorithm import get_display
                rtl_text = get_display(reshaped_text)
                
                return rtl_text
                
            except ImportError:
                # Ø§Ú¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ù†ØµØ¨ Ù†ÛŒØ³ØªÙ†Ø¯ØŒ Ù…ØªÙ† Ø±Ø§ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
                return text
            except Exception as e:
                # Ø¯Ø± ØµÙˆØ±Øª Ù‡Ø± Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ØŒ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
                logger.warning(f"Error in fix_persian_text: {e}")
            return text
        
        # Ø³Ø±Ø¨Ø±Ú¯ ØªÙ…ÛŒØ² Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ - Ø¨Ø¯ÙˆÙ† ØªØ¯Ø§Ø®Ù„
        # Ø±Ø¯ÛŒÙ Ø§ÙˆÙ„: Ø¨Ø±Ù†Ø¯ Ùˆ ØªØ§Ø±ÛŒØ®
        header_row1_data = [
            ['CHIDEMANO', '', fix_persian_text(get_persian_date())],
        ]
        
        header_row1_table = Table(header_row1_data, colWidths=[250, 100, 250], rowHeights=[35])
        header_row1_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            
            # Ø¨Ø±Ù†Ø¯ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            ('FONTNAME', (0, 0), (0, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (0, 0), 22),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.9, 0.95, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'RIGHT'),
            
            # ØªØ§Ø±ÛŒØ®
            ('FONTNAME', (2, 0), (2, 0), font_name),
            ('FONTSIZE', (2, 0), (2, 0), 14),
            ('TEXTCOLOR', (2, 0), (2, 0), colors.Color(0.8, 0.9, 1.0)),
            ('ALIGN', (2, 0), (2, 0), 'LEFT'),
            
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))
        
        # Ø±Ø¯ÛŒÙ Ø¯ÙˆÙ…: Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ - Ø¨Ø§ RTL ØµØ­ÛŒØ­
        header_row2_data = [
            [fix_persian_text('Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯')],
        ]
        header_row2_table = Table(header_row2_data, colWidths=[600], rowHeights=[30])
        header_row2_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            
            ('FONTNAME', (0, 0), (0, 0), font_name),
            ('FONTSIZE', (0, 0), (0, 0), 16),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.95, 0.98, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))
        
        # Ø±Ø¯ÛŒÙ Ø³ÙˆÙ…: Ø²ÛŒØ±Ø¹Ù†ÙˆØ§Ù† - Ø¨Ø§ RTL ØµØ­ÛŒØ­
        header_row3_data = [
            [fix_persian_text('Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ')],
        ]
        header_row3_table = Table(header_row3_data, colWidths=[600], rowHeights=[25])
        header_row3_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            
            ('FONTNAME', (0, 0), (0, 0), font_name),
            ('FONTSIZE', (0, 0), (0, 0), 12),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.85, 0.92, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))
        
        # Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ Ø·Ù„Ø§ÛŒÛŒ
        separator_data = [['']]
        separator_table = Table(separator_data, colWidths=[600], rowHeights=[2])
        separator_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, 0), colors.Color(0.8, 0.6, 0.2)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.white),
            ('BOX', (0, 0), (-1, -1), 0, colors.white),
        ]))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø³Ø±Ø¨Ø±Ú¯
        story.append(header_row1_table)
        story.append(header_row2_table)
        story.append(header_row3_table)
        story.append(Spacer(1, 15))
        story.append(separator_table)
        story.append(Spacer(1, 25))
        
        
        # Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        story.append(Paragraph(fix_persian_text("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ"), title_style))
        story.append(Paragraph(fix_persian_text(f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}"), subtitle_style))
        story.append(Spacer(1, 15))
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ
        story.append(Paragraph(fix_persian_text("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡"), section_style))
        story.append(Paragraph(fix_persian_text(f"Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}"), normal_style))
        story.append(Paragraph(fix_persian_text(f"ØªØ§Ø±ÛŒØ® ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´: {get_persian_date()}"), normal_style))
        story.append(Paragraph(fix_persian_text("ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø·: Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ"), normal_style))
        story.append(Spacer(1, 20))
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§
        sections = implementation_plan.split('\n## ')
        
        for i, section in enumerate(sections):
            if i == 0:
                # Ø¨Ø®Ø´ Ø§ÙˆÙ„ (Ø¨Ø¯ÙˆÙ† ##)
                lines = section.split('\n')
                for line in lines:
                    if line.strip():
                        if line.startswith('#'):
                            story.append(Paragraph(fix_persian_text(line.replace('#', '').strip()), subtitle_style))
                        elif line.startswith('-'):
                            story.append(Paragraph(fix_persian_text(f"â€¢ {line[1:].strip()}"), list_style))
                        else:
                            story.append(Paragraph(fix_persian_text(line.strip()), normal_style))
            else:
                # Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ (Ø¨Ø§ ##)
                lines = section.split('\n')
                if lines[0].strip():
                    story.append(Paragraph(fix_persian_text(lines[0].strip()), subtitle_style))
                
                for line in lines[1:]:
                    if line.strip():
                        if line.startswith('###'):
                            story.append(Paragraph(fix_persian_text(line.replace('###', '').strip()), section_style))
                        elif line.startswith('-'):
                            story.append(Paragraph(fix_persian_text(f"â€¢ {line[1:].strip()}"), list_style))
                        elif line.startswith('**') and line.endswith('**'):
                            story.append(Paragraph(fix_persian_text(f"<b>{line[2:-2]}</b>"), normal_style))
                        elif line.startswith('####'):
                            story.append(Paragraph(fix_persian_text(line.replace('####', '').strip()), subsection_style))
                        else:
                            story.append(Paragraph(fix_persian_text(line.strip()), normal_style))
            
            if i < len(sections) - 1:
                story.append(Spacer(1, 20))
        
        # Ø³Ø§Ø®Øª PDF
        doc.build(story)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ response (Ø¯Ø§Ù†Ù„ÙˆØ¯)
        buffer.seek(0)
        response = HttpResponse(buffer.getvalue(), content_type='application/pdf')
        response['Content-Disposition'] = f'attachment; filename="{analysis.store_name}_Ø¨Ø±Ù†Ø§Ù…Ù‡_Ø§Ø¬Ø±Ø§ÛŒÛŒ_ØªÙØµÛŒÙ„ÛŒ_{analysis.id}.pdf"'
        
        return response
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"Error generating PDF: {e}")
        logger.error(f"Error details: {error_details}")
        print(f"PDF Generation Error: {error_details}")
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ PDF: {str(e)}')
        return redirect('store_analysis:user_dashboard')


# --- Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ ØªØ­Ù„ÛŒÙ„ ---

@login_required
def view_analysis_pdf_inline(request, pk):
    """Ù†Ù…Ø§ÛŒØ´ PDF ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Inline Ø¯Ø± ØªØ¨ Ø¬Ø¯ÛŒØ¯ (Ø¨Ø± Ø§Ø³Ø§Ø³ pk)"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    if not analysis.analysis_data:
        messages.error(request, 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª')
        return redirect('store_analysis:user_dashboard')
    
    try:
        # Ù‡Ù…Ø³Ø§Ù† Ø¨Ø§ Ø·Ø±Ø§Ø­ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø¯Ø± download_detailed_pdf
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´ (Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ/Ù†ØªØ§ÛŒØ¬)
        if analysis.results and isinstance(analysis.results, dict):
            if 'analysis_text' in analysis.results:
                implementation_plan = analysis.results['analysis_text']
            elif 'fallback_analysis' in analysis.results:
                implementation_plan = analysis.results.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯')
            else:
                implementation_plan = str(analysis.results)
        else:
            implementation_plan = generate_comprehensive_implementation_plan(analysis.analysis_data or {})
        
        # Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³ØªØŒ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù¾ÛŒØ§Ù… Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡
        if not implementation_plan or implementation_plan.strip() == '':
            implementation_plan = f"""
Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name or 'Ù†Ø§Ù…Ø´Ø®Øµ'}

Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
- Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name or 'Ù†Ø§Ù…Ø´Ø®Øµ'}
- Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_type or 'Ø¹Ù…ÙˆÙ…ÛŒ'}
- Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_size or 'Ù†Ø§Ù…Ø´Ø®Øµ'}

Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.

ØªØ§Ø±ÛŒØ®: {analysis.created_at.strftime('%Y/%m/%d') if analysis.created_at else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
            """.strip()

        # Ø§ÛŒØ¬Ø§Ø¯ PDF Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§ Ø³Ø±Ø¨Ø±Ú¯ Ùˆ RTL
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib import colors
        from io import BytesIO
        import os

        # ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ
        try:
            font_path = os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir.ttf')
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('Vazir', font_path))
                font_name = 'Vazir'
            else:
                tahoma_path = "C:/Windows/Fonts/tahoma.ttf"
                if os.path.exists(tahoma_path):
                    pdfmetrics.registerFont(TTFont('Tahoma', tahoma_path))
                    font_name = 'Tahoma'
                else:
                    font_name = 'Helvetica'
        except Exception:
            font_name = 'Helvetica'

        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        styles = getSampleStyleSheet()

        title_style = ParagraphStyle(
            'CustomTitle', parent=styles['Heading1'], fontName=font_name, fontSize=22,
            spaceAfter=20, alignment=2, textColor=colors.Color(0.1, 0.3, 0.6), leading=28
        )
        subtitle_style = ParagraphStyle(
            'CustomSubtitle', parent=styles['Heading2'], fontName=font_name, fontSize=16,
            spaceAfter=15, alignment=2, textColor=colors.Color(0.2, 0.2, 0.2), leading=20
        )
        normal_style = ParagraphStyle(
            'CustomNormal', parent=styles['Normal'], fontName=font_name, fontSize=11,
            spaceAfter=8, alignment=2, textColor=colors.Color(0.2, 0.2, 0.2), leading=16
        )
        list_style = ParagraphStyle(
            'CustomList', parent=styles['Normal'], fontName=font_name, fontSize=10,
            spaceAfter=6, alignment=2, textColor=colors.Color(0.3, 0.3, 0.3), leading=14
        )
        section_style = ParagraphStyle(
            'CustomSection', parent=styles['Heading3'], fontName=font_name, fontSize=14,
            spaceAfter=12, spaceBefore=18, alignment=2, textColor=colors.Color(0.1, 0.3, 0.6), leading=18
        )

        story = []

        # ØªÙˆØ§Ø¨Ø¹ ØªØ§Ø±ÛŒØ® Ùˆ RTL Ù…Ø´Ø§Ø¨Ù‡ ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯
        def get_persian_date():
            if jdatetime:
                now = timezone.now()
                persian_date = jdatetime.datetime.fromgregorian(datetime=now)
                return persian_date.strftime("%Y/%m/%d")
            else:
                return timezone.now().strftime("%Y/%m/%d")

        def fix_persian_text(text):
            if not text:
                return text
            text = text.replace('ğŸ“Š', '').replace('ğŸª', '').replace('âœ…', '').replace('âš ï¸', '').replace('ğŸš€', '').replace('âš¡', '').replace('ğŸ‘¥', '').replace('ğŸ’°', '').replace('ğŸ’', '').replace('ğŸ¯', '').replace('ğŸ“…', '').replace('ğŸ“ˆ', '')
            if arabic_reshaper and get_display:
                reshaped_text = arabic_reshaper.reshape(text)
                return get_display(reshaped_text)
            else:
                return text

        # Ø³Ø±Ø¨Ø±Ú¯ Ø³Ù‡â€ŒØ±Ø¯ÛŒÙÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        header_row1_data = [['CHIDEMANO', '', fix_persian_text(get_persian_date())]]
        header_row1_table = Table(header_row1_data, colWidths=[250, 100, 250], rowHeights=[35])
        header_row1_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('FONTNAME', (0, 0), (0, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (0, 0), 22),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.9, 0.95, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'RIGHT'),
            ('FONTNAME', (2, 0), (2, 0), font_name),
            ('FONTSIZE', (2, 0), (2, 0), 14),
            ('TEXTCOLOR', (2, 0), (2, 0), colors.Color(0.8, 0.9, 1.0)),
            ('ALIGN', (2, 0), (2, 0), 'LEFT'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))

        header_row2_data = [[fix_persian_text('Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯')]]
        header_row2_table = Table(header_row2_data, colWidths=[600], rowHeights=[30])
        header_row2_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('FONTNAME', (0, 0), (0, 0), font_name),
            ('FONTSIZE', (0, 0), (0, 0), 16),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.95, 0.98, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))

        header_row3_data = [[fix_persian_text('Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ')]]
        header_row3_table = Table(header_row3_data, colWidths=[600], rowHeights=[25])
        header_row3_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), colors.Color(0.05, 0.15, 0.35)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('BOX', (0, 0), (-1, -1), 0, colors.Color(0.05, 0.15, 0.35)),
            ('FONTNAME', (0, 0), (0, 0), font_name),
            ('FONTSIZE', (0, 0), (0, 0), 12),
            ('TEXTCOLOR', (0, 0), (0, 0), colors.Color(0.85, 0.92, 1.0)),
            ('ALIGN', (0, 0), (0, 0), 'CENTER'),
            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ]))

        separator = Table([['']], colWidths=[600], rowHeights=[2])
        separator.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (0, 0), colors.Color(0.8, 0.6, 0.2)),
            ('INNERGRID', (0, 0), (-1, -1), 0, colors.white),
            ('BOX', (0, 0), (-1, -1), 0, colors.white),
        ]))

        story.append(header_row1_table)
        story.append(header_row2_table)
        story.append(header_row3_table)
        story.append(Spacer(1, 15))
        story.append(separator)
        story.append(Spacer(1, 25))

        story.append(Paragraph(fix_persian_text("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ"), title_style))
        story.append(Paragraph(fix_persian_text(f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}"), subtitle_style))
        story.append(Spacer(1, 15))

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ Ø¨Ø§ Ø±Ø¹Ø§ÛŒØª RTL
        sections = implementation_plan.split('\n## ')
        for i, section in enumerate(sections):
            if i == 0:
                lines = section.split('\n')
                for line in lines:
                    if line.strip():
                        if line.startswith('#'):
                            story.append(Paragraph(fix_persian_text(line.replace('#', '').strip()), subtitle_style))
                        elif line.startswith('-'):
                            story.append(Paragraph(fix_persian_text(f"â€¢ {line[1:].strip()}"), list_style))
                        else:
                            story.append(Paragraph(fix_persian_text(line.strip()), normal_style))
            else:
                lines = section.split('\n')
                if lines[0].strip():
                    story.append(Paragraph(fix_persian_text(lines[0].strip()), subtitle_style))
                for line in lines[1:]:
                    if line.strip():
                        if line.startswith('###'):
                            story.append(Paragraph(fix_persian_text(line.replace('###', '').strip()), section_style))
                        elif line.startswith('-'):
                            story.append(Paragraph(fix_persian_text(f"â€¢ {line[1:].strip()}"), list_style))
                        elif line.startswith('**') and line.endswith('**'):
                            story.append(Paragraph(fix_persian_text(f"<b>{line[2:-2]}</b>"), normal_style))
                        elif line.startswith('####'):
                            story.append(Paragraph(fix_persian_text(line.replace('####', '').strip()), section_style))
                        else:
                            story.append(Paragraph(fix_persian_text(line.strip()), normal_style))
            if i < len(sections) - 1:
                story.append(Spacer(1, 20))

        # Ø³Ø§Ø®Øª Ùˆ Ø¨Ø§Ø²Ú¯Ø´Øª inline
        doc.build(story)
        buffer.seek(0)
        response = HttpResponse(buffer.getvalue(), content_type='application/pdf')
        response['Content-Disposition'] = f'inline; filename="{analysis.store_name}_Ú¯Ø²Ø§Ø±Ø´.pdf"'
        return response
    except Exception as e:
        logger.error(f"Error rendering inline PDF: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ PDF')
        return redirect('store_analysis:user_dashboard')


@login_required
def view_order_pdf_inline(request, order_id):
    """Ù†Ù…Ø§ÛŒØ´ PDF ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙØ§Ø±Ø´ Ø¨Ù‡ ØµÙˆØ±Øª Inline Ø¯Ø± ØªØ¨ Ø¬Ø¯ÛŒØ¯"""
    order = get_object_or_404(Order, order_number=order_id, user=request.user)
    analysis = StoreAnalysis.objects.filter(order=order).first()
    if not analysis:
        messages.error(request, 'ØªØ­Ù„ÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³ÙØ§Ø±Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯')
        return redirect('store_analysis:user_dashboard')
    return view_analysis_pdf_inline(request, analysis.pk)

@login_required
def payment_page(request, order_id):
    """ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª"""
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Order - Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· Ø¨Ù‡ Order Ù‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø±Ø¯
        try:
            # Ø¯Ø± Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ Order Ú©Ù„ÛŒØ¯ URL Ù…Ø§ order_number Ø§Ø³Øª
            order = Order.objects.get(order_number=order_id, user=request.user)
        except Order.DoesNotExist:
            # Ø§Ú¯Ø± Order ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø¢Ø®Ø±ÛŒÙ† Order Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
            latest_order = Order.objects.filter(user=request.user).order_by('-created_at').first()
            if latest_order:
                messages.warning(request, f'Ø³ÙØ§Ø±Ø´ {order_id} ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø¢Ø®Ø±ÛŒÙ† Ø³ÙØ§Ø±Ø´ Ø´Ù…Ø§ ({latest_order.order_number}) Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.')
                order = latest_order
            else:
                messages.error(request, f'Ø³ÙØ§Ø±Ø´ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ {order_id} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ù†Ø¯Ø§Ø±ÛŒØ¯.')
                return redirect('store_analysis:user_dashboard')
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ StoreAnalysis
        store_analysis = StoreAnalysis.objects.filter(order=order).first()
        if not store_analysis:
            messages.error(request, 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÛŒÙ† Ø³ÙØ§Ø±Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯.')
            return redirect('store_analysis:user_dashboard')
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
        if not store_analysis.preliminary_analysis and store_analysis.analysis_data:
            try:
                from .ai_analysis import StoreAnalysisAI
                ai_analyzer = StoreAnalysisAI()
                preliminary_analysis = ai_analyzer.generate_preliminary_analysis(store_analysis.analysis_data)
                store_analysis.preliminary_analysis = preliminary_analysis
                store_analysis.save()
            except Exception as e:
                logger.error(f"Error generating preliminary analysis: {e}")
                # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø³Ø§Ø¯Ù‡ - Ø®Ø·Ø§ Ø±Ø§ Ù„Ø§Ú¯ Ú©Ù† Ø§Ù…Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
                store_analysis.preliminary_analysis = "ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡: ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¯Ø§Ø±Ø¯. Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø®ØªØŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯."
                store_analysis.save()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² calculate_analysis_cost
        try:
            cost_breakdown = calculate_analysis_cost(store_analysis.analysis_data or {})
        except Exception as e:
            logger.error(f"Error calculating cost: {e}")
            # fallback Ø¨Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ ØªØ®ÙÛŒÙ 100% - Ø®Ø·Ø§ Ø±Ø§ Ù„Ø§Ú¯ Ú©Ù† Ø§Ù…Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
            from datetime import datetime
            current_date = datetime.now()
            launch_end_date = datetime(2025, 12, 31)
            
            base_cost = Decimal('500000')
            additional_cost = Decimal('200000')
            total_cost = base_cost + additional_cost
            
            # ØªØ®ÙÛŒÙ 100% Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ±Ù‡ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
            discount = Decimal('0')
            if current_date <= launch_end_date:
                discount = total_cost  # ØªØ®ÙÛŒÙ 100%
            
            final_cost = total_cost - discount
            
            cost_breakdown = {
                'base_price': base_cost,
                'total': total_cost,
                'final': final_cost,
                'discount': discount,
                'discount_percentage': 100 if discount > 0 else 0,
                'breakdown': [
                    {
                        'item': 'ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡',
                        'amount': base_cost,
                        'description': 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
                    },
                    {
                        'item': 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ PDF',
                        'amount': additional_cost,
                        'description': 'Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
                    }
                ]
            }
        
        # Ø§Ø¹Ù…Ø§Ù„ ØªØ®ÙÛŒÙ Ø§Ø² session
        session_discount = request.session.get('discount_percentage', 0)
        if session_discount > 0:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ®ÙÛŒÙ
            discount_amount = (cost_breakdown['final'] * session_discount) / 100
            cost_breakdown['discount'] = discount_amount
            cost_breakdown['final'] = cost_breakdown['final'] - discount_amount
            cost_breakdown['discount_percentage'] = session_discount
        
        # Ø­ØªÛŒ Ø§Ú¯Ø± Ù…Ø¨Ù„Øº Ù†Ù‡Ø§ÛŒÛŒ ØµÙØ± Ø§Ø³ØªØŒ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
        # Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ÛŒØ¯ Ø¨ØªÙˆØ§Ù†Ø¯ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†Ø¯
        
        # ØªØ¹ÛŒÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¨Ù„Øº Ù†Ù‡Ø§ÛŒÛŒ
        payment_methods = [
            {'id': 'online', 'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù†Ù„Ø§ÛŒÙ†', 'icon': 'fas fa-credit-card'},
            {'id': 'wallet', 'name': 'Ú©ÛŒÙ Ù¾ÙˆÙ„', 'icon': 'fas fa-wallet'},
        ]
        
        # Ø§Ú¯Ø± Ù…Ø¨Ù„Øº Ù†Ù‡Ø§ÛŒÛŒ ØµÙØ± Ø§Ø³ØªØŒ Ú¯Ø²ÛŒÙ†Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if cost_breakdown['final'] == 0:
            payment_methods.append({
                'id': 'free', 
                'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù†', 
                'icon': 'fas fa-gift',
                'highlight': True
            })
        
        payment_complete = order.status in ['paid', 'processing', 'completed']
        if store_analysis and store_analysis.status in ['paid', 'processing', 'completed']:
            payment_complete = True

        show_payment = (not payment_complete) and order.final_amount > 0

        status_map = {
            'pending': ('Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ù¾Ø±Ø¯Ø§Ø®Øª', 'pending'),
            'paid': ('Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡', 'completed'),
            'processing': ('Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú¯Ø²Ø§Ø±Ø´', 'processing'),
            'completed': ('Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù‡', 'completed')
        }

        status_label, status_tag = status_map.get(
            store_analysis.status if store_analysis else order.status,
            ('Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ù¾Ø±Ø¯Ø§Ø®Øª', 'pending')
        )

        form_url = reverse('store_analysis:forms', kwargs={'analysis_id': store_analysis.id}) if store_analysis else reverse('store_analysis:forms')
        progress_url = reverse('store_analysis:analysis_progress', args=[store_analysis.id]) if store_analysis else None
        results_url = reverse('store_analysis:view_analysis_report', args=[store_analysis.id]) if store_analysis else None
        
        context = {
            'order': order,
            'store_analysis': store_analysis,
            'cost_breakdown': cost_breakdown,
            'payment_methods': payment_methods,
            'show_payment': show_payment,
            'status_label': status_label,
            'status_tag': status_tag,
            'form_url': form_url,
            'progress_url': progress_url,
            'results_url': results_url,
            'payment_complete': payment_complete
        }
        
        return render(request, 'store_analysis/payment_page.html', context)
        
    except Exception as e:
        logger.error(f"Error in payment_page: {e}")
        # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¨Ù‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù‡Ø¯Ø§ÛŒØª Ú©Ù†
        if "Order.DoesNotExist" in str(e) or "StoreAnalysis.DoesNotExist" in str(e):
            messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª: {str(e)}')
            return redirect('store_analysis:user_dashboard')
        else:
            # Ø¨Ø±Ø§ÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØŒ Ù¾ÛŒØ§Ù… Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡ Ø§Ù…Ø§ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡
            messages.warning(request, f'âš ï¸ Ø®Ø·Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ: {str(e)}. ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.')
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª
            try:
                order = Order.objects.filter(user=request.user).order_by('-created_at').first()
                if not order:
                    return redirect('store_analysis:user_dashboard')
                
                store_analysis = StoreAnalysis.objects.filter(order=order).first()
                if not store_analysis:
                    return redirect('store_analysis:user_dashboard')
        
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                from datetime import datetime
                current_date = datetime.now()
                launch_end_date = datetime(2025, 12, 31)
                
                base_cost = Decimal('500000')
                additional_cost = Decimal('200000')
                total_cost = base_cost + additional_cost
                
                discount = Decimal('0')
                if current_date <= launch_end_date:
                    discount = total_cost
                
                final_cost = total_cost - discount
                
                cost_breakdown = {
                    'base_price': base_cost,
                    'total': total_cost,
                    'final': final_cost,
                    'discount': discount,
                    'discount_percentage': 100 if discount > 0 else 0,
                    'breakdown': [
                        {
                            'item': 'ØªØ­Ù„ÛŒÙ„ Ù¾Ø§ÛŒÙ‡',
                            'amount': base_cost,
                            'description': 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
                        },
                        {
                            'item': 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ PDF',
                            'amount': additional_cost,
                            'description': 'Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
                        }
                    ]
                }
                
                # ØªØ¹ÛŒÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¨Ù„Øº Ù†Ù‡Ø§ÛŒÛŒ
                payment_methods = [
                    {'id': 'online', 'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù†Ù„Ø§ÛŒÙ†', 'icon': 'fas fa-credit-card'},
                    {'id': 'wallet', 'name': 'Ú©ÛŒÙ Ù¾ÙˆÙ„', 'icon': 'fas fa-wallet'},
                ]
                
                # Ø§Ú¯Ø± Ù…Ø¨Ù„Øº Ù†Ù‡Ø§ÛŒÛŒ ØµÙØ± Ø§Ø³ØªØŒ Ú¯Ø²ÛŒÙ†Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                if cost_breakdown['final'] == 0:
                    payment_methods.append({
                        'id': 'free', 
                        'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù†', 
                        'icon': 'fas fa-gift',
                        'highlight': True
                    })
                
                context = {
                    'order': order,
                    'store_analysis': store_analysis,
                    'cost_breakdown': cost_breakdown,
                    'payment_methods': payment_methods
                }
                
                return render(request, 'store_analysis/payment_page.html', context)
                
            except Exception as fallback_error:
                logger.error(f"Fallback error in payment_page: {fallback_error}")
        return redirect('store_analysis:user_dashboard')

@login_required
def process_payment(request, order_id):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª"""
    if request.method == 'POST':
        try:
            # Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· Order Ù‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ø¯
            order = get_object_or_404(Order, order_number=order_id, user=request.user)
            payment_method = request.POST.get('payment_method', 'online')

            # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø®Øª
            if payment_method == 'wallet':
                # Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø² Ø·Ø±ÛŒÙ‚ Ú©ÛŒÙ Ù¾ÙˆÙ„ Ù…ÙˆÙ‚ØªØ§Ù‹ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª
                messages.warning(request, 'âš ï¸ Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø² Ø·Ø±ÛŒÙ‚ Ú©ÛŒÙ Ù¾ÙˆÙ„ Ù…ÙˆÙ‚ØªØ§Ù‹ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ø±ÙˆØ´ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.')
                return redirect('store_analysis:payment_page', order_id=order.order_number)
            elif payment_method == 'online':
                # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ PayPing
                return redirect('store_analysis:payping_payment', order_id=order.order_number)
            elif payment_method == 'free':
                # Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ÛŒÚ¯Ø§Ù† - Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±Ùˆ
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´
                order.status = 'paid'
                order.payment_method = 'free'
                order.transaction_id = f'FREE_{uuid.uuid4().hex[:12].upper()}'
                order.save()
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„
                store_analysis = StoreAnalysis.objects.filter(order=order).first()
                if store_analysis:
                    store_analysis.status = 'preliminary_completed'
                    store_analysis.save()
                    
                    # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
                    initial_analysis = generate_initial_ai_analysis(store_analysis.analysis_data)
                    store_analysis.preliminary_analysis = initial_analysis
                    store_analysis.save()
                
                # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„
                messages.success(request, 'Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚! Ø­Ø§Ù„Ø§ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
                return redirect('store_analysis:forms')
            
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚ (Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± Ø±ÙˆØ´â€ŒÙ‡Ø§)
            # Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´ÙˆØ¯
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ù¾Ø±Ø¯Ø§Ø®Øª
            payment = Payment.objects.create(
                user=request.user,
                store_analysis=StoreAnalysis.objects.filter(order=order).first(),
                amount=order.final_amount,
                payment_method=payment_method,
                status='completed',
                transaction_id=f'TXN_{uuid.uuid4().hex[:12].upper()}'
            )
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´
            order.status = 'paid'
            order.payment_method = payment_method
            order.transaction_id = payment.transaction_id
            order.save()
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„
            store_analysis = StoreAnalysis.objects.filter(order=order).first()
            if store_analysis:
                store_analysis.status = 'preliminary_completed'
                store_analysis.save()
                
                # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
                initial_analysis = generate_initial_ai_analysis(store_analysis.analysis_data)
                store_analysis.preliminary_analysis = initial_analysis
                store_analysis.save()
            
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù†ØªØ§ÛŒØ¬
            return redirect('store_analysis:forms')
            
        except Exception as e:
            messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª: {str(e)}')
            return redirect('store_analysis:payment_page', order_id=order.order_number)
    
    return redirect('store_analysis:payment_page', order_id=order_id)


@login_required
def payping_payment(request, order_id):
    """Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø² Ø·Ø±ÛŒÙ‚ PayPing - Ú©Ø§Ù…Ù„ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    try:
        order = get_object_or_404(Order, order_number=order_id, user=request.user)
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± (Ø§Ù„Ø²Ø§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ PayPing)
        try:
            user_profile = request.user.userprofile
            payer_identity = user_profile.phone
        except:
            payer_identity = None
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø± (ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ UX Ø¨Ù‡ØªØ±)
        payer_name = request.user.get_full_name() or request.user.username
        
        # Validate payer_identity - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´Ù…Ø§Ø±Ù‡ ØªØ³Øª Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø´Ù…Ø§Ø±Ù‡ Ù†Ø¯Ø§Ø±Ù‡
        if not payer_identity or len(str(payer_identity)) < 10:
            logger.warning(f"âš ï¸ User {request.user.username} has no valid phone. Using test number for payment.")
            payer_identity = '09121234567'  # Ø´Ù…Ø§Ø±Ù‡ ØªØ³Øª Ø¨Ø±Ø§ÛŒ PayPing
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø±Ú¯Ø§Ù‡ PayPing
        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        payping = gateway_manager.get_gateway('payping')
        
        if not payping:
            logger.error(f"PayPing gateway not available. Token: {getattr(settings, 'PAYPING_TOKEN', 'NOT_SET')[:10]}...")
            messages.error(request, 'Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            return redirect('store_analysis:payment_page', order_id=order_id)
        
        logger.info(f"ğŸ”¹ PayPing payment initiated for order {order_id} by user {request.user.username} (mobile: {payer_identity})")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„
        callback_url = request.build_absolute_uri(
            reverse('store_analysis:payping_callback', args=[order.order_number])
        )
        
        logger.info(f"ğŸ“ PayPing callback URL: {callback_url}")
        
        payment_request = payping.create_payment_request(
            amount=int(order.final_amount),
            description=f'Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ - Ø³ÙØ§Ø±Ø´ {order.order_number}',
            callback_url=callback_url,
            payer_identity=str(payer_identity),  # Ø´Ù…Ø§Ø±Ù‡ Ù…ÙˆØ¨Ø§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± (Ø§Ù„Ø²Ø§Ù…ÛŒ)
            payer_name=str(payer_name),  # Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø± (ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡)
            client_ref_id=f"ORD_{order.order_number}"  # Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§
        )
        
        logger.info(f"ğŸ’³ PayPing payment request result: {payment_request}")
        
        if payment_request.get('status') == 'success':
            # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ø¯Ø§Ø®Øª
            store_analysis = StoreAnalysis.objects.filter(order=order).first()
            payment = Payment.objects.create(
                user=request.user,
                store_analysis=store_analysis,
                order_id=order.order_number,
                amount=order.final_amount,
                payment_method='payping',
                status='pending',
                authority=payment_request['authority'],  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† authority Ø¨Ø±Ø§ÛŒ mock payment
                transaction_id=payment_request['authority']
            )

            order.payment = payment
            order.transaction_id = payment.transaction_id
            order.save(update_fields=['payment', 'transaction_id'])
            
            logger.info(f"âœ… Payment record created: {payment.id}, redirecting to PayPing...")
            
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª PayPing
            return redirect(payment_request['payment_url'])
        else:
            # Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§
            error_msg = payment_request.get('message', 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø®Øª')
            error_code = payment_request.get('code', 'UNKNOWN')
            
            logger.error(f"âŒ PayPing payment failed: {error_code} - {error_msg}")
            
            # Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯
            if error_code == 'GATEWAY_NOT_ACTIVE':
                messages.error(request, 'âš ï¸ Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙ‚ØªØ§Ù‹ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            elif error_code == 'AUTHENTICATION_ERROR':
                messages.error(request, 'âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            else:
                messages.error(request, f'âŒ {error_msg}')
            
            return redirect('store_analysis:payment_page', order_id=order_id)
            
    except Exception as e:
        logger.error(f"ğŸ’¥ PayPing payment exception: {e}", exc_info=True)
        messages.error(request, 'âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:payment_page', order_id=order_id)

@login_required
def debug_payping(request):
    """Debug PayPing configuration"""
    try:
        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        payping = gateway_manager.get_gateway('payping')
        
        debug_info = {
            'payping_available': payping is not None,
            'payping_token_set': bool(getattr(settings, 'PAYPING_TOKEN', '')),
            'payping_token_preview': getattr(settings, 'PAYPING_TOKEN', 'NOT_SET')[:20] + '...' if getattr(settings, 'PAYPING_TOKEN', '') else 'NOT_SET',
        }
        
        if payping:
            # Test a small payment request
            test_request = payping.create_payment_request(
                amount=1000,  # 1000 Toman = 10000 Rial
                description='ØªØ³Øª Ø¯Ø±Ú¯Ø§Ù‡ PayPing',
                callback_url='https://chidmano.ir/test-callback',
                client_ref_id='TEST_123'
            )
            debug_info['test_request'] = test_request
        
        return JsonResponse(debug_info)
        
    except Exception as e:
        return JsonResponse({'error': str(e)})

@login_required
def test_payping(request):
    """ØªØ³Øª Ø¯Ø±Ú¯Ø§Ù‡ PayPing"""
    try:
        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        payping = gateway_manager.get_gateway('payping')
        
        if not payping:
            return HttpResponse('âŒ Ø¯Ø±Ú¯Ø§Ù‡ PayPing Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª')
        
        # ØªØ³Øª Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø®Øª
        payment_request = payping.create_payment_request(
            amount=1000,
            description='ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø®Øª PayPing',
            callback_url='http://127.0.0.1:8000/test-callback/',
            client_ref_id='TEST_001'
        )
        
        return HttpResponse(f'âœ… ØªØ³Øª PayPing Ù…ÙˆÙÙ‚: {payment_request}')
        
    except Exception as e:
        return HttpResponse(f'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª PayPing: {str(e)}')

@login_required
def test_zarinpal(request):
    """ØªØ³Øª Ø¯Ø±Ú¯Ø§Ù‡ Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„ (legacy)"""
    try:
        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        zarinpal = gateway_manager.get_gateway('zarinpal')
        
        if not zarinpal:
            return HttpResponse('âŒ Ø¯Ø±Ú¯Ø§Ù‡ Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª')
        
        # ØªØ³Øª Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù¾Ø±Ø¯Ø§Ø®Øª
        payment_request = zarinpal.create_payment_request(
            amount=1000,
            description='ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø®Øª',
            callback_url='http://127.0.0.1:8000/test-callback/'
        )
        
        return HttpResponse(f'âœ… ØªØ³Øª Ù…ÙˆÙÙ‚: {payment_request}')
        
    except Exception as e:
        return HttpResponse(f'âŒ Ø®Ø·Ø§: {str(e)}')
@login_required
def test_liara_ai(request):
    """ØªØ³Øª Liara AI"""
    try:
        from .ai_services.liara_ai_service import LiaraAIService
        
        ai_service = LiaraAIService()
        
        # ØªØ³Øª Ø³Ø§Ø¯Ù‡
        test_data = {
            'store_name': 'ØªØ³Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'store_type': 'Ø¹Ù…ÙˆÙ…ÛŒ',
            'store_size': '100',
            'city': 'ØªÙ‡Ø±Ø§Ù†'
        }
        
        result = ai_service._make_request(
            model='openai/gpt-4.1',
            prompt='Ø³Ù„Ø§Ù…ØŒ Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯.',
            max_tokens=100
        )
        
        if result:
            return HttpResponse(f'âœ… ØªØ³Øª Liara AI Ù…ÙˆÙÙ‚: {result}')
        else:
            return HttpResponse('âŒ ØªØ³Øª Liara AI Ù†Ø§Ù…ÙˆÙÙ‚')
        
    except Exception as e:
        return HttpResponse(f'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Liara AI: {str(e)}')
@login_required
def test_advanced_analysis(request):
    """ØªØ³Øª Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    try:
        from .ai_services.intelligent_analysis_engine import IntelligentAnalysisEngine
        import asyncio
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù…ÙˆØªÙˆØ± ØªØ­Ù„ÛŒÙ„
        engine = IntelligentAnalysisEngine()
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ³Øª
        store_info = {
            'store_name': 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªØ³Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡',
            'store_type': 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù¾ÙˆØ´Ø§Ú©',
            'store_size': '150',
            'city': 'ØªÙ‡Ø±Ø§Ù†',
            'address': 'Ø®ÛŒØ§Ø¨Ø§Ù† ÙˆÙ„ÛŒØ¹ØµØ±',
            'phone': '02112345678',
            'description': 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù¾ÙˆØ´Ø§Ú© Ù…Ø¯Ø±Ù† Ùˆ Ø´ÛŒÚ©'
        }
        
        # ØªØµØ§ÙˆÛŒØ± ØªØ³Øª (base64 Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª)
        test_images = []
        
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        async def run_analysis():
            return await engine.perform_comprehensive_analysis(store_info, test_images)
        
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(run_analysis())
        loop.close()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        response_data = {
            'status': 'success',
            'analysis_id': result.analysis_id,
            'store_name': result.store_name,
            'overall_score': result.overall_score,
            'professional_grade': result.professional_grade,
            'competitive_advantage': result.competitive_advantage,
            'strategic_recommendations': result.strategic_recommendations[:3],
            'quick_wins': result.quick_wins[:3],
            'growth_opportunities': result.growth_opportunities[:3]
        }
        
        return JsonResponse(response_data, safe=False)
        
    except Exception as e:
        logger.error(f"Error in advanced analysis test: {e}")
        return JsonResponse({
            'status': 'error',
            'message': f'Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡: {str(e)}'
        }, safe=False)

@login_required
def payping_callback(request, order_id):
    """Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø² PayPing - Callback Handler Ú©Ø§Ù…Ù„ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    try:
        order = get_object_or_404(Order, order_number=order_id)
        store_analysis = order.analyses.first()
        payment = Payment.objects.filter(order_id=order.order_number).first()
        
        refid = request.GET.get('refid') or request.GET.get('refId') or request.GET.get('RefId')
        clientrefid = request.GET.get('clientrefid') or request.GET.get('clientRefId')
        
        logger.info(
            "ğŸ”” PayPing callback received for order %s (analysis=%s): refid=%s clientrefid=%s",
            order.order_number,
            store_analysis.id if store_analysis else None,
            refid,
            clientrefid,
        )

        if not refid:
            logger.warning("âŒ Payment cancelled by user for order %s", order.order_number)
            messages.warning(request, 'âš ï¸ Ù¾Ø±Ø¯Ø§Ø®Øª ØªÙˆØ³Ø· Ø´Ù…Ø§ Ù„ØºÙˆ Ø´Ø¯. Ø¯Ø± ØµÙˆØ±Øª ØªÙ…Ø§ÛŒÙ„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ù‚Ø¯Ø§Ù… Ú©Ù†ÛŒØ¯.')
            return redirect('store_analysis:payment_page', order_id=order.order_number)

        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        payping = gateway_manager.get_gateway('payping')
        
        if not payping:
            logger.error("âŒ PayPing gateway not available in callback for order %s", order.order_number)
            messages.error(request, 'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            return redirect('store_analysis:user_dashboard')
        
        logger.info("ğŸ” Verifying payment: refid=%s, amount=%s", refid, order.final_amount)
        
        verification_result = payping.verify_payment(
            authority=refid,
            amount=int(order.final_amount)
        )
        
        logger.info("âœ… Verification result for order %s: %s", order.order_number, verification_result)
        
        if verification_result.get('status') == 'success':
            if payment is None:
                payment = Payment.objects.create(
                    user=order.user,
                    store_analysis=store_analysis,
                    order_id=order.order_number,
                    amount=order.final_amount,
                    payment_method='payping',
                    status='pending'
                )

            payment.status = 'completed'
            payment.transaction_id = refid
            payment.store_analysis = store_analysis
            payment.completed_at = timezone.now()
            payment.save(update_fields=['status', 'transaction_id', 'store_analysis', 'completed_at'])

            order.status = 'paid'
            order.payment_method = 'payping'
            order.payment = payment
            order.transaction_id = refid
            order.save(update_fields=['status', 'payment_method', 'payment', 'transaction_id'])

            if store_analysis and store_analysis.status not in ['completed']:
                store_analysis.status = 'processing'  # ØªØºÛŒÛŒØ± Ø¨Ù‡ processing Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„
                store_analysis.save(update_fields=['status'])
                logger.info(f"ğŸš€ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„ {store_analysis.id} Ø¨Ù‡ 'processing' ØªØºÛŒÛŒØ± Ú©Ø±Ø¯ - Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ")

            # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Liara AI Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§
            if store_analysis:
                try:
                    # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± background thread
                    import threading
                    
                    def start_real_analysis():
                        """Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Liara AI Ø¯Ø± background"""
                        try:
                            logger.info(f"ğŸ¤– Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Liara AI Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                            
                            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ API Key
                            from django.conf import settings
                            liara_api_key = getattr(settings, 'LIARA_AI_API_KEY', '')
                            if not liara_api_key:
                                error_msg = "âš ï¸ LIARA_AI_API_KEY ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯."
                                logger.error(f"âŒ {error_msg}")
                                store_analysis.status = 'failed'
                                store_analysis.error_message = error_msg
                                store_analysis.save(update_fields=['status', 'error_message'])
                                return
                            
                            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
                            analysis_data = store_analysis.analysis_data or {}
                            if not analysis_data:
                                error_msg = "âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ±Ù… Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯."
                                logger.error(f"âŒ {error_msg}")
                                store_analysis.status = 'failed'
                                store_analysis.error_message = error_msg
                                store_analysis.save(update_fields=['status', 'error_message'])
                                return
                            
                            store_data = {
                                'store_name': store_analysis.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                                'store_type': analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ'),
                                'store_size': str(analysis_data.get('store_size', 0)),
                                'store_address': analysis_data.get('store_address', ''),
                                'description': analysis_data.get('description', ''),
                                **analysis_data
                            }
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§ÙˆÛŒØ± Ø§Ø² uploaded_files
                            images = []
                            if 'uploaded_files' in analysis_data:
                                uploaded_files = analysis_data['uploaded_files']
                                image_fields = ['store_photos', 'store_layout', 'shelf_photos', 
                                              'window_display_photos', 'entrance_photos', 'checkout_photos']
                                for field in image_fields:
                                    if field in uploaded_files:
                                        file_info = uploaded_files[field]
                                        if isinstance(file_info, dict) and 'path' in file_info:
                                            images.append(file_info['path'])
                            
                            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LiaraAIService Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹
                            from .ai_services.liara_ai_service import LiaraAIService
                            liara_service = LiaraAIService()
                            
                            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯ API key Ø¯Ø± Ø³Ø±ÙˆÛŒØ³
                            if not liara_service.api_key:
                                error_msg = "âš ï¸ LIARA_AI_API_KEY Ø¯Ø± Ø³Ø±ÙˆÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
                                logger.error(f"âŒ {error_msg}")
                                store_analysis.status = 'failed'
                                store_analysis.error_message = error_msg
                                store_analysis.save(update_fields=['status', 'error_message'])
                                return
                            
                            logger.info(f"ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§ {len(images)} ØªØµÙˆÛŒØ±...")
                            
                            # ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¨Ø§ Liara AI
                            comprehensive_analysis = liara_service.analyze_store_comprehensive(
                                store_data=store_data,
                                images=images if images else None
                            )
                            
                            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„
                            if comprehensive_analysis and comprehensive_analysis.get('error'):
                                error_type = comprehensive_analysis.get('error', 'unknown_error')
                                error_message = comprehensive_analysis.get('error_message', 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ AI')
                                
                                logger.error(f"âŒ ØªØ­Ù„ÛŒÙ„ Liara AI Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}: {error_type} - {error_message}")
                                
                                # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ø®Ø·Ø§ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ù…Ù†Ø§Ø³Ø¨
                                if error_type == 'api_key_missing':
                                    error_message = "âš ï¸ LIARA_AI_API_KEY ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯."
                                elif error_type == 'authentication_failed':
                                    error_message = "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª API. Ù„Ø·ÙØ§Ù‹ API key Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."
                                elif error_type == 'all_analyses_failed':
                                    error_message = f"âš ï¸ Ù‡Ù…Ù‡ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯: {error_message}"
                                elif error_type == 'timeout':
                                    error_message = "âš ï¸ Ø²Ù…Ø§Ù† Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
                                elif error_type == 'connection_error':
                                    error_message = "âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆØ±. Ù„Ø·ÙØ§Ù‹ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."
                                
                                store_analysis.status = 'failed'
                                store_analysis.error_message = error_message
                                store_analysis.save(update_fields=['status', 'error_message'])
                                
                            elif comprehensive_analysis and not comprehensive_analysis.get('error'):
                                logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Liara AI ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                
                                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„
                                current_results = store_analysis.results or {}
                                
                                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ analysis_text Ø§Ø² final_report ÛŒØ§ Ù…Ø­ØªÙˆØ§ÛŒ ØªØ­Ù„ÛŒÙ„
                                analysis_text = None
                                if 'final_report' in comprehensive_analysis:
                                    analysis_text = comprehensive_analysis['final_report']
                                elif 'detailed_analyses' in comprehensive_analysis:
                                    # ØªØ±Ú©ÛŒØ¨ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ
                                    combined = ""
                                    for key, analysis in comprehensive_analysis['detailed_analyses'].items():
                                        if analysis and 'content' in analysis:
                                            combined += f"\n\n{analysis['content']}\n"
                                    analysis_text = combined if combined else None
                                
                                current_results.update({
                                    'liara_analysis': comprehensive_analysis,
                                    'analysis_source': 'liara_ai',
                                    'analysis_text': analysis_text or comprehensive_analysis.get('final_report', ''),
                                    'models_used': comprehensive_analysis.get('ai_models_used', comprehensive_analysis.get('models_used', [])),
                                    'analysis_quality': 'premium',
                                    'analyzed_at': timezone.now().isoformat(),
                                    'payment_refid': refid
                                })
                                
                                # Ø¨Ø±Ø§ÛŒ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ professional Ùˆ enterpriseØŒ Ú¯Ø²Ø§Ø±Ø´ premium Ù‡Ù… ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
                                if store_analysis.package_type in ['professional', 'enterprise']:
                                    try:
                                        from django.core.files.storage import default_storage
                                        
                                        images_data = None
                                        videos_data = None
                                        
                                        images_path = f'analyses/{store_analysis.id}/images/'
                                        videos_path = f'analyses/{store_analysis.id}/videos/'
                                        
                                        if default_storage.exists(images_path):
                                            images_list = default_storage.listdir(images_path)[1]
                                            if images_list:
                                                images_data = {'count': len(images_list), 'files': images_list[:20]}
                                        
                                        if default_storage.exists(videos_path):
                                            videos_list = default_storage.listdir(videos_path)[1]
                                            if videos_list:
                                                videos_data = {'video_count': len(videos_list), 'files': videos_list[:5]}
                                        
                                        from .services.premium_report_generator import PremiumReportGenerator
                                        report_generator = PremiumReportGenerator()
                                        premium_report = report_generator.generate_premium_report(
                                            analysis=store_analysis,
                                            images_data=images_data,
                                            video_data=videos_data,
                                            sales_data=None
                                        )
                                        
                                        current_results.update({
                                            'premium_report': premium_report,
                                            'report_type': f'premium_{store_analysis.package_type}',
                                        })
                                        logger.info(f"âœ… Ú¯Ø²Ø§Ø±Ø´ Premium Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
                                    except Exception as e:
                                        logger.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Premium: {e}", exc_info=True)
                                
                                # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
                                store_analysis.results = current_results
                                store_analysis.status = 'completed'
                                store_analysis.save(update_fields=['results', 'status'])
                                
                                # Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ
                                try:
                                    from .models import ReviewReminder
                                    ReviewReminder.create_for_analysis(
                                        analysis=store_analysis,
                                        days_until_reminder=30,
                                        discount_percentage=30
                                    )
                                    logger.info(f"âœ… ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
                                except Exception as e:
                                    logger.error(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ: {e}", exc_info=True)
                                
                                logger.info(f"ğŸ‰ ØªØ­Ù„ÛŒÙ„ {store_analysis.id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
                            else:
                                # ØªØ­Ù„ÛŒÙ„ Ø®Ø§Ù„ÛŒ ÛŒØ§ None
                                logger.error(f"âŒ ØªØ­Ù„ÛŒÙ„ Liara AI Ø®Ø§Ù„ÛŒ Ø¨Ø±Ú¯Ø´Øª Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                store_analysis.status = 'failed'
                                store_analysis.error_message = 'ØªØ­Ù„ÛŒÙ„ AI Ø®Ø§Ù„ÛŒ Ø¨Ø±Ú¯Ø´Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.'
                                store_analysis.save(update_fields=['status', 'error_message'])
                                
                        except Exception as e:
                            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ background Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}: {e}", exc_info=True)
                            store_analysis.status = 'failed'
                            store_analysis.error_message = str(e)
                            store_analysis.save(update_fields=['status', 'error_message'])
                    
                    # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± background
                    analysis_thread = threading.Thread(target=start_real_analysis, daemon=True)
                    analysis_thread.start()
                    logger.info(f"ğŸ§µ Thread ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ {store_analysis.id} Ø´Ø±ÙˆØ¹ Ø´Ø¯")
                    
                    # Ù‡Ø¯Ø§ÛŒØª Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ ÙØ±Ù… Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
                    messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯! ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ÙØ±Ù… Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
                    if store_analysis:
                        request.session['analysis_id'] = store_analysis.id
                    return redirect('store_analysis:forms', analysis_id=store_analysis.id)
                    
                except Exception as err:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}: {err}", exc_info=True)
                    messages.warning(request, 'â³ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ø´Ø±ÙˆØ¹ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ ØµØ¨ÙˆØ± Ø¨Ø§Ø´ÛŒØ¯.')

            # Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ØŒ Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ÙØ±Ù…
            messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯! Ù„Ø·ÙØ§Ù‹ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
            if store_analysis:
                request.session['analysis_id'] = store_analysis.id
            return redirect('store_analysis:forms', analysis_id=store_analysis.id)

        error_msg = verification_result.get('message', 'Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª')
        logger.error("âŒ Payment verification failed for order %s: %s", order.order_number, error_msg)

        if payment:
            payment.status = 'failed'
            payment.save(update_fields=['status'])

        messages.error(request, 'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:payment_page', order_id=order.order_number)

    except Http404:
        logger.error("âŒ PayPing callback - Order not found: %s", order_id)
        messages.error(request, 'âŒ Ø³ÙØ§Ø±Ø´ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.')
        return redirect('store_analysis:user_dashboard')
    except Exception as exc:
        logger.error("ğŸ’¥ PayPing callback exception for order %s: %s", order_id, exc, exc_info=True)
        messages.error(request, 'âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
        return redirect('store_analysis:user_dashboard')


# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ - redirect Ø¨Ù‡ dashboard
@login_required
def wallet_dashboard(request):
    """ØµÙØ­Ù‡ Ú©ÛŒÙ Ù¾ÙˆÙ„ - redirect Ø¨Ù‡ dashboard"""
    messages.info(request, 'Ú©ÛŒÙ Ù¾ÙˆÙ„ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.')
    return redirect('store_analysis:user_dashboard')

# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

# @login_required
# def wallet_payping_callback(request, wallet_tx_id):
    """Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø² PayPing Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø±Ú˜ Ú©ÛŒÙ Ù¾ÙˆÙ„ - Callback Handler Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
    try:
        # PayPing returns: refid, clientrefid
        refid = request.GET.get('refid') or request.GET.get('refId') or request.GET.get('RefId')
        clientrefid = request.GET.get('clientrefid') or request.GET.get('clientRefId')
        
        logger.info(f"ğŸ’° Wallet PayPing callback: tx_id={wallet_tx_id}, refid={refid}, clientrefid={clientrefid}")
        
        # Check if payment was cancelled by user
        if not refid:
            logger.warning(f"âŒ Wallet payment cancelled by user: {wallet_tx_id}")
            messages.warning(request, 'âš ï¸ Ù¾Ø±Ø¯Ø§Ø®Øª ØªÙˆØ³Ø· Ø´Ù…Ø§ Ù„ØºÙˆ Ø´Ø¯. Ø¯Ø± ØµÙˆØ±Øª ØªÙ…Ø§ÛŒÙ„ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ù‚Ø¯Ø§Ù… Ú©Ù†ÛŒØ¯.')
            return redirect('store_analysis:wallet_dashboard')
        
        # Find the payment record
        try:
            payment = Payment.objects.get(transaction_id=wallet_tx_id, user=request.user)
        except Payment.DoesNotExist:
            # Try with refid
            try:
                payment = Payment.objects.get(transaction_id=refid, user=request.user)
            except Payment.DoesNotExist:
                logger.error(f"âŒ Payment record not found: {wallet_tx_id} or {refid}")
                messages.error(request, 'âŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ø¯Ø§Ø®Øª ÛŒØ§ÙØª Ù†Ø´Ø¯')
                return redirect('store_analysis:wallet_dashboard')
        
        # Check for duplicate processing
        if payment.status == 'completed':
            logger.warning(f"âš ï¸ Duplicate wallet payment: {refid} - already processed")
            messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ù…Ø§ Ù‚Ø¨Ù„Ø§Ù‹ Ø«Ø¨Øª Ø´Ø¯Ù‡ Ø§Ø³Øª.')
            return redirect('store_analysis:wallet_dashboard')
        
        # Verify payment with PayPing
        from .payment_gateways import PaymentGatewayManager
        
        gateway_manager = PaymentGatewayManager()
        payping = gateway_manager.get_gateway('payping')
        
        if not payping:
            logger.error("âŒ PayPing gateway not available in wallet callback")
            messages.error(request, 'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            return redirect('store_analysis:wallet_dashboard')
        
        logger.info(f"ğŸ” Verifying wallet payment: refid={refid}, amount={payment.amount}")
        
        verification_result = payping.verify_payment(
            authority=refid,
            amount=int(payment.amount)
        )
        
        logger.info(f"âœ… Wallet verification result: {verification_result}")
        
        if verification_result.get('status') == 'success':
            # âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚ - ÙˆØ§Ø±ÛŒØ² Ø¨Ù‡ Ú©ÛŒÙ Ù¾ÙˆÙ„
            logger.info(f"ğŸ’š Wallet payment verified successfully: {refid}")
            
            from .models import Wallet, WalletTransaction
            
            # Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ Ú©ÛŒÙ Ù¾ÙˆÙ„
            wallet, created = Wallet.objects.get_or_create(
                user=request.user,
                defaults={'balance': 0, 'is_active': True}
            )
            
            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ±Ø§Ú©Ù†Ø´ Ú©ÛŒÙ Ù¾ÙˆÙ„
            WalletTransaction.objects.create(
                wallet=wallet,
                amount=payment.amount,
                transaction_type='deposit',
                description=f'Ø´Ø§Ø±Ú˜ Ø§Ø² Ø·Ø±ÛŒÙ‚ PayPing - {refid}',
                payment=payment,
                balance_after=wallet.balance + payment.amount
            )
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ú©ÛŒÙ Ù¾ÙˆÙ„
            wallet.balance += payment.amount
            wallet.save()
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª payment
            payment.status = 'completed'
            payment.transaction_id = refid
            payment.save()
            
            logger.info(f"âœ… Wallet charged: user={request.user.username}, amount={payment.amount}, new_balance={wallet.balance}")
            
            messages.success(request, f'âœ… Ú©ÛŒÙ Ù¾ÙˆÙ„ Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø´Ø§Ø±Ú˜ Ø´Ø¯! Ù…Ø¨Ù„Øº {payment.amount:,.0f} ØªÙˆÙ…Ø§Ù† Ø¨Ù‡ Ø­Ø³Ø§Ø¨ Ø´Ù…Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.')
            return redirect('store_analysis:wallet_dashboard')
            
        else:
            # âŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…ÙˆÙÙ‚ ÛŒØ§ Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯
            error_msg = verification_result.get('message', 'Ø®Ø·Ø§ Ø¯Ø± ØªØ§ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª')
            logger.error(f"âŒ Wallet payment verification failed: {error_msg}")
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª payment Ø¨Ù‡ failed
            payment.status = 'failed'
            payment.transaction_id = refid or payment.transaction_id
            payment.save()
            
            messages.error(request, f'âŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…ÙˆÙÙ‚: {error_msg}')
            return redirect('store_analysis:wallet_dashboard')
            
    except Payment.DoesNotExist:
        logger.error(f"âŒ Payment not found in wallet callback: {wallet_tx_id}")
        messages.error(request, 'âŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ø¯Ø§Ø®Øª ÛŒØ§ÙØª Ù†Ø´Ø¯')
        return redirect('store_analysis:wallet_dashboard')
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Wallet callback exception: {e}", exc_info=True)
        messages.error(request, 'âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø§Ø±Ú˜ Ú©ÛŒÙ Ù¾ÙˆÙ„. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
        return redirect('store_analysis:wallet_dashboard')


def find_or_create_store_analysis(order, user):
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÛŒØ§ Ø§ÛŒØ¬Ø§Ø¯ StoreAnalysis Ø¨Ø±Ø§ÛŒ Order - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    try:
        # Ø§Ø¨ØªØ¯Ø§ Ø³Ø¹ÛŒ Ú©Ù† StoreAnalysis Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Order Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
        store_analysis = StoreAnalysis.objects.filter(order=order).first()
        
        if store_analysis:
            logger.info(f"Found existing StoreAnalysis {store_analysis.pk} for Order {order.order_number}")
            return store_analysis
        
        # Ø§Ú¯Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù† Ú©Ù‡ Order Ù†Ø¯Ø§Ø±Ø¯
        store_analysis = StoreAnalysis.objects.filter(
            user=user,
            order__isnull=True
        ).order_by('-created_at').first()
        
        if store_analysis:
            # Ø§Ø±ØªØ¨Ø§Ø· Order Ø±Ø§ Ø¨Ø±Ù‚Ø±Ø§Ø± Ú©Ù†
            store_analysis.order = order
            store_analysis.save()
            logger.info(f"Linked StoreAnalysis {store_analysis.pk} to Order {order.order_number}")
            return store_analysis
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù† Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø§Ø±Ø¯
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ contact_phone
        from django.db import connection
        with connection.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM store_analysis_storeanalysis WHERE user_id = %s", [user.id])
            user_analyses = cursor.fetchone()[0]
        if user_analyses > 0:
            logger.warning(f"User {user.username} has {user_analyses} analyses but none available for Order {order.order_number}")
            return None
        
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„ÛŒ Ù†Ø¯Ø§Ø±Ø¯ØŒ ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†
        store_analysis = StoreAnalysis.objects.create(
            user=user,
            order=order,
            store_name=f'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {order.order_number}',
            status='pending',
            analysis_data={}
        )
        logger.info(f"Created new StoreAnalysis {store_analysis.pk} for Order {order.order_number}")
        return store_analysis
        
    except Exception as e:
        logger.error(f"Error in find_or_create_store_analysis: {e}")
        return None
@login_required
def order_analysis_results(request, order_id):
    """ØµÙØ­Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³ÙØ§Ø±Ø´ - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    try:
        logger.info(f"ğŸ” Accessing order_analysis_results for order_id: {order_id}, user: {request.user.username}")
        
        # Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· Order Ù‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
        order = get_object_or_404(Order, order_number=order_id, user=request.user)
        logger.info(f"âœ… Order found: {order.order_number}")
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† StoreAnalysis Ù…Ø±ØªØ¨Ø·
        store_analysis = find_or_create_store_analysis(order, request.user)
        logger.info(f"âœ… StoreAnalysis found/created: {store_analysis.id if store_analysis else 'None'}")
        
        if not store_analysis:
            logger.warning(f"âš ï¸ No StoreAnalysis found for order: {order_id}")
            messages.error(request, 'ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
            return redirect('store_analysis:store_analysis_form')
        
        # Handle POST requests (AJAX) - run processing in background and return fast
        if request.method == 'POST':
            try:
                import json
                data = json.loads(request.body)
                action = data.get('action')

                analysis_data = store_analysis.analysis_data or {}
                store_info = {
                    'store_name': store_analysis.store_name or 'Ù†Ø§Ù…Ø´Ø®Øµ',
                    'store_type': analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ'),
                    'store_size': str(analysis_data.get('store_size', 0)),
                    'city': 'ØªÙ‡Ø±Ø§Ù†',
                    'description': analysis_data.get('description', '')
                }

                if action == 'reprocess_liara':
                    # Kick off advanced analysis in background
                    from .ai_services.advanced_ai_manager import AdvancedAIManager
                    ai_manager = AdvancedAIManager()

                    def run_liara_bg():
                        try:
                            advanced_analysis = ai_manager.start_advanced_analysis(store_info)
                            store_analysis.results = serialize_analysis_result(advanced_analysis)
                            store_analysis.status = 'completed'
                            store_analysis.save()
                        except Exception as e:
                            logger.error(f"Advanced analysis (Liara) failed in bg: {e}")
                            store_analysis.status = 'failed'
                            store_analysis.save()

                    import threading
                    threading.Thread(target=run_liara_bg, daemon=True).start()
                    store_analysis.status = 'processing'
                    store_analysis.save(update_fields=['status'])
                    return JsonResponse({'success': True, 'message': 'ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø´Ø±ÙˆØ¹ Ø´Ø¯', 'status': 'processing'})

                if action == 'reprocess_ollama':
                    # Kick off simpler Ollama/local analysis in background
                    from .ai_analysis import StoreAnalysisAI
                    ai_analyzer = StoreAnalysisAI()

                    def run_ollama_bg():
                        try:
                            simple = ai_analyzer.generate_detailed_analysis(analysis_data)
                            store_analysis.results = {
                                'fallback_analysis': True,
                                'analysis_text': simple.get('analysis_text', ''),
                                'overall_score': simple.get('overall_score', 75.0),
                                'strengths': simple.get('strengths', []),
                                'weaknesses': simple.get('weaknesses', []),
                                'recommendations': simple.get('recommendations', []),
                                'ai_provider': 'ollama_fallback'
                            }
                            store_analysis.status = 'completed'
                            store_analysis.save()
                        except Exception as e:
                            logger.error(f"Ollama analysis failed in bg: {e}")
                            store_analysis.status = 'failed'
                            store_analysis.save()

                    import threading
                    threading.Thread(target=run_ollama_bg, daemon=True).start()
                    store_analysis.status = 'processing'
                    store_analysis.save(update_fields=['status'])
                    return JsonResponse({'success': True, 'message': 'ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø´Ø±ÙˆØ¹ Ø´Ø¯', 'status': 'processing'})

                return JsonResponse({'success': False, 'message': 'Ø¹Ù…Ù„ÛŒØ§Øª Ù†Ø§Ù…Ø´Ø®Øµ'})

            except Exception as e:
                logger.error(f"Error in POST request: {e}")
                return JsonResponse({'success': False, 'message': f'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {str(e)}'})
        
        
        # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ù‡Ù†ÙˆØ² Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†
        if store_analysis.status != 'completed':
            try:
                # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
                from .ai_analysis import StoreAnalysisAI
                
                # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
                analysis_data = store_analysis.analysis_data or {}
                store_info = {
                    'store_name': store_analysis.store_name or 'Ù†Ø§Ù…Ø´Ø®Øµ',
                    'store_type': analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ'),
                    'store_size': str(analysis_data.get('store_size', 0)),
                    'city': 'ØªÙ‡Ø±Ø§Ù†',  # Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø² ÙØ±Ù… Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯
                    'description': analysis_data.get('description', '')
                }
                
                # ØªØµØ§ÙˆÛŒØ± (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
                images = []
                if store_analysis.analysis_data and 'uploaded_files' in store_analysis.analysis_data:
                    uploaded_files = store_analysis.analysis_data['uploaded_files']
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØµØ§ÙˆÛŒØ±
                    image_fields = ['store_photos', 'store_layout', 'shelf_photos', 'window_display_photos', 
                                  'entrance_photos', 'checkout_photos']
                    for field in image_fields:
                        if field in uploaded_files and 'path' in uploaded_files[field]:
                            images.append(uploaded_files[field]['path'])
                
                # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¯Ø± background thread
                import threading
                def process_analysis_background():
                    try:
                        ai_analyzer = StoreAnalysisAI()
                        
                        # Ø§Ú¯Ø± ØªØµØ§ÙˆÛŒØ± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ± Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡
                        if images:
                            try:
                                from .ai_analysis import ImageProcessor
                                image_processor = ImageProcessor()
                                image_analysis = image_processor.process_images(images)
                                analysis_data['image_analysis'] = image_analysis
                                logger.info(f"Image analysis completed for {len(images)} images")
                            except Exception as img_error:
                                logger.error(f"Image processing failed: {img_error}")
                                analysis_data['image_analysis'] = {'error': str(img_error)}
                        
                        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„
                        analysis_result = ai_analyzer.generate_detailed_analysis(analysis_data)
                        
                        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ (JSON-safe)
                        store_analysis.results = serialize_analysis_result(analysis_result)
                        store_analysis.status = 'completed'
                        store_analysis.save()
                        
                        logger.info(f"Background analysis completed for store: {store_analysis.store_name}")
                    except Exception as e:
                        logger.error(f"Background analysis failed: {e}")
                        store_analysis.status = 'failed'
                        store_analysis.save()
                
                # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± background
                thread = threading.Thread(target=process_analysis_background)
                thread.daemon = True
                thread.start()
                
                # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
                store_analysis.status = 'processing'
                store_analysis.save()
                
                # ØªÙ†Ø¸ÛŒÙ… context Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
                context = {
                    'order': order,
                    'store_analysis': store_analysis,
                    'is_processing': True,
                    'processing_message': 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª. ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø­Ø¯ÙˆØ¯ 10 ØªØ§ 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ù†ØªÛŒØ¬Ù‡ØŒ Ø­Ø¯ÙˆØ¯ 1 Ø³Ø§Ø¹Øª Ø¯ÛŒÚ¯Ø± Ø¨Ù‡ Ú©Ø§Ø±ØªØ§Ø¨Ù„ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.',
                    'polling_url': f'/store/order/{order_id}/status/'
                }
                
                messages.info(request, 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø´Ø±ÙˆØ¹ Ø´Ø¯. ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø­Ø¯ÙˆØ¯ 10 ØªØ§ 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø·ÙˆÙ„ Ù…ÛŒâ€ŒÚ©Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ù†ØªÛŒØ¬Ù‡ØŒ Ø­Ø¯ÙˆØ¯ 1 Ø³Ø§Ø¹Øª Ø¯ÛŒÚ¯Ø± Ø¨Ù‡ Ú©Ø§Ø±ØªØ§Ø¨Ù„ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.')
                
                # Ø±Ù†Ø¯Ø± ØµÙØ­Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
                return render(request, 'store_analysis/modern_analysis_results.html', context)
                
            except Exception as analysis_error:
                logger.error(f"Error in advanced analysis: {analysis_error}")
                # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ØŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ollama Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡
                try:
                    from .ai_analysis import StoreAnalysisAI
                    ai_analyzer = StoreAnalysisAI()
                    
                    # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ollama
                    simple_analysis = ai_analyzer.generate_detailed_analysis(store_analysis.analysis_data or {})
                    
                    store_analysis.results = {
                        'fallback_analysis': True,
                        'analysis_text': simple_analysis.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯'),
                        'overall_score': simple_analysis.get('overall_score', 75.0),
                        'strengths': simple_analysis.get('strengths', []),
                        'weaknesses': simple_analysis.get('weaknesses', []),
                        'recommendations': simple_analysis.get('recommendations', []),
                        'ai_provider': 'ollama_fallback'
                    }
                    store_analysis.status = 'completed'
                    store_analysis.save()
                    messages.warning(request, 'ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ollama Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ (ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯)')
                    
                except Exception as fallback_error:
                    logger.error(f"Fallback analysis also failed: {fallback_error}")
                    # Ø§Ú¯Ø± Ø­ØªÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ù‡Ù… Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ØŒ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
                    store_analysis.results = {
                        'error': 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„',
                        'fallback_analysis': True,
                        'message': 'Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.',
                        'analysis_text': 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ - Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯'
                    }
                    store_analysis.status = 'completed'
                    store_analysis.save()
                    messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ - Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯')
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ results Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² format Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø¬Ø¯ÛŒØ¯
        results = store_analysis.results or {}
        
        # Ø§Ú¯Ø± scores Ø¯Ø± root Ù†ÛŒØ³ØªØŒ Ø¢Ù† Ø±Ø§ Ø¨Ø³Ø§Ø²
        if results and 'scores' not in results:
            results['scores'] = {
                'overall_score': results.get('overall_score', 75),
                'design_score': results.get('design_score', results.get('overall_score', 75) * 0.9),
                'layout_score': results.get('layout_score', results.get('overall_score', 75) * 0.85),
                'quality_score': results.get('quality_score', 80),
                'confidence_score': results.get('confidence_score', 85)
            }
        
        context = {
            'order': order,
            'store_analysis': store_analysis,
            'has_preliminary': bool(store_analysis.preliminary_analysis),
            'has_results': store_analysis.has_results,
            'progress': store_analysis.get_progress(),
            'is_advanced_analysis': not results.get('fallback_analysis', False),
            'results': results
        }
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø¯ÙˆØ³ØªØ§Ù†Ù‡
        try:
            # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡
            friendly_analysis = {
                'title': f'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_analysis.store_name}',
                'summary': store_analysis.results.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª') if store_analysis.results else 'ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª',
                'score': store_analysis.results.get('overall_score', 75) if store_analysis.results else 75,
                'recommendations': store_analysis.results.get('recommendations', []) if store_analysis.results else []
            }
            
            context['friendly_analysis'] = friendly_analysis
            context['show_friendly'] = True
            
        except Exception as e:
            logger.error(f"Error generating friendly analysis: {e}")
            context['show_friendly'] = False
        
        logger.info(f"âœ… Rendering results page for order: {order_id}")
        return render(request, 'store_analysis/modern_analysis_results.html', context)
        
    except Exception as e:
        logger.error(f"âŒ Error in order_analysis_results: {str(e)}", exc_info=True)
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†ØªØ§ÛŒØ¬: {str(e)}')
        return redirect('store_analysis:user_dashboard')

@login_required
def check_analysis_status(request, order_id):
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„ (AJAX)"""
    try:
        # Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· Order Ù‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ø¯
        order = get_object_or_404(Order, order_number=order_id, user=request.user)
        store_analysis = StoreAnalysis.objects.filter(order=order).first()
        
        if not store_analysis:
            return JsonResponse({'error': 'ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯'}, status=404)
        
        return JsonResponse({
            'status': store_analysis.status,
            'progress': store_analysis.get_progress(),
            'has_preliminary': bool(store_analysis.preliminary_analysis),
            'has_results': store_analysis.has_results,
            'estimated_completion': store_analysis.estimated_duration,
        })
    
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)

@login_required
def analysis_insights(request, pk):
    """Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # ØªÙˆÙ„ÛŒØ¯ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    insights = {
        'performance_metrics': {
            'overall_score': 85.5,
            'layout_efficiency': 78.2,
            'customer_flow': 82.1,
            'visual_appeal': 88.7,
            'sales_potential': 91.3
        },
        'key_findings': [
            "Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ 78% Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø³Øª",
            "Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ 15% Ø¯Ø§Ø±Ø¯",
            "ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø± Ø³Ø§Ø¹Ø§Øª 14-18 Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³Øª",
            "Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ØªØ£Ø«ÛŒØ± Ù…Ø«Ø¨ØªÛŒ Ø¨Ø± ÙØ±ÙˆØ´ Ø¯Ø§Ø±Ø¯"
        ],
        'recommendations': [
            "Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯",
            "Ø¨Ø§Ø²Ø·Ø±Ø§Ø­ÛŒ Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù†",
            "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø±ØªÙØ§Ø¹ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§",
            "Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¹Ù†Ø§ØµØ± Ø¨ØµØ±ÛŒ Ø¬Ø°Ø§Ø¨"
        ],
        'forecast': {
            'expected_improvement': "25-35%",
            'time_to_implement': "2-3 Ù‡ÙØªÙ‡",
            'estimated_cost': "15-25 Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†",
            'roi_prediction': "40-60%"
        }
    }
    
    context = {
        'analysis': analysis,
        'insights': insights,
        'is_admin': request.user.is_staff or request.user.is_superuser,
    }
    
    return render(request, 'store_analysis/analysis_insights.html', context)

@login_required
def store_comparison(request):
    """Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§"""
    user_analyses = StoreAnalysis.objects.filter(user=request.user, status='completed')
    
    comparison_data = []
    for analysis in user_analyses:
        try:
            result = StoreAnalysisResult.objects.get(store_analysis=analysis)
            comparison_data.append({
                'store_name': analysis.store_name,
                'overall_score': result.overall_score,
                'layout_score': result.layout_score,
                'traffic_score': result.traffic_score,
                'design_score': result.design_score,
                'sales_score': result.sales_score,
                'created_at': analysis.created_at
            })
        except StoreAnalysisResult.DoesNotExist:
            continue
    
    context = {
        'comparison_data': comparison_data,
        'is_admin': request.user.is_staff or request.user.is_superuser,
    }
    
    return render(request, 'store_analysis/store_comparison.html', context)

@login_required
def ai_consultant(request):
    """Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø´Ø®ØµÛŒ"""
    user_analyses = StoreAnalysis.objects.filter(user=request.user, status__in=['completed', 'preliminary_completed'])
    
    # ØªÙˆÙ„ÛŒØ¯ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
    ai_advice = {
        'personalized_recommendations': [
            "Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø´Ù…Ø§ØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø±ÙˆÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ØªÙ…Ø±Ú©Ø² Ú©Ù†ÛŒØ¯",
            "Ú†ÛŒØ¯Ù…Ø§Ù† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ø¯",
            "ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø± Ø³Ø§Ø¹Ø§Øª Ø®Ø§ØµÛŒ Ø§Ø² Ø±ÙˆØ² Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³Øª"
        ],
        'industry_benchmarks': {
            'your_average_score': 82.5,
            'industry_average': 75.0,
            'top_performers': 92.0
        },
        'improvement_areas': [
            "Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ: +15% Ø¨Ù‡Ø¨ÙˆØ¯",
            "Ú†ÛŒØ¯Ù…Ø§Ù†: +12% Ø¨Ù‡Ø¨ÙˆØ¯", 
            "ØªØ±Ø§ÙÛŒÚ©: +8% Ø¨Ù‡Ø¨ÙˆØ¯",
            "Ø·Ø±Ø§Ø­ÛŒ: +10% Ø¨Ù‡Ø¨ÙˆØ¯"
        ]
    }
    
    context = {
        'ai_advice': ai_advice,
        'user_analyses': user_analyses,
        'is_admin': request.user.is_staff or request.user.is_superuser,
    }
    
    return render(request, 'store_analysis/ai_consultant.html', context)


@login_required
def ai_detailed_analysis(request, pk):
    """ØªØ­Ù„ÛŒÙ„ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø§ AI"""
    # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ Ù‡Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
    if request.user.is_staff or request.user.is_superuser:
        analysis = get_object_or_404(StoreAnalysis, pk=pk)
    else:
        analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÙØµÛŒÙ„ÛŒ Ø¬Ø¯ÛŒØ¯
    ai_analyzer = StoreAnalysisAI()
    analysis_data = analysis.get_analysis_data()
    
    if analysis_data:
        detailed_analysis = ai_analyzer.generate_detailed_analysis(analysis_data)
        implementation_guide = ai_analyzer.generate_implementation_guide(detailed_analysis)
    else:
        messages.error(request, "Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return redirect('store_analysis:analysis_results', pk=analysis.pk)
    
    context = {
        'analysis': analysis,
        'detailed_analysis': detailed_analysis,
        'implementation_guide': implementation_guide,
        'is_admin': request.user.is_staff or request.user.is_superuser,
    }
    
    return render(request, 'store_analysis/ai_detailed_analysis.html', context)

@login_required
def admin_process_analysis(request, pk):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙÙˆØ±ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Ø§Ø¯Ù…ÛŒÙ†"""
    if not request.user.is_staff and not request.user.is_superuser:
        messages.error(request, "Ø´Ù…Ø§ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        return redirect('store_analysis:analysis_list')
    
    analysis = get_object_or_404(StoreAnalysis, pk=pk)
    
    try:
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ÙÙˆØ±ÛŒ
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.analysis_data or {}
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„
        analysis_result = ai_analyzer.generate_detailed_analysis(analysis_data)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
        StoreAnalysisResult.objects.update_or_create(
            store_analysis=analysis,
            defaults={
                'overall_score': analysis_result.get('overall_score', 75.0),
                'layout_score': analysis_result.get('layout_score', 75.0),
                'traffic_score': analysis_result.get('traffic_score', 75.0),
                'design_score': analysis_result.get('design_score', 75.0),
                'sales_score': analysis_result.get('sales_score', 75.0),
                'layout_analysis': str(analysis_result.get('strengths', [])),
                'traffic_analysis': str(analysis_result.get('weaknesses', [])),
                'design_analysis': str(analysis_result.get('opportunities', [])),
                'sales_analysis': str(analysis_result.get('threats', [])),
                'overall_analysis': str(analysis_result.get('recommendations', [])),
            }
        )
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„
        analysis.status = 'completed'
        analysis.save()
        
        messages.success(request, f"ØªØ­Ù„ÛŒÙ„ {analysis.store_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
        
    except Exception as e:
        messages.error(request, f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„: {str(e)}")
    
    return redirect('store_analysis:analysis_results', pk=analysis.pk)


@login_required
def generate_ai_report(request, pk):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ AI"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    try:
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ ØªÙØµÛŒÙ„ÛŒ
        ai_analyzer = StoreAnalysisAI()
        analysis_data = analysis.get_analysis_data()
        
        if not analysis_data:
            return JsonResponse({
                'status': 'error',
                'message': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.'
            })
        
        detailed_analysis = ai_analyzer.generate_detailed_analysis(analysis_data)
        implementation_guide = ai_analyzer.generate_implementation_guide(detailed_analysis)
        
        return JsonResponse({
            'status': 'success',
            'message': 'ØªØ­Ù„ÛŒÙ„ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.',
            'analysis_id': analysis.pk,
            'detailed_analysis': detailed_analysis,
            'implementation_guide': implementation_guide
        })
        
    except Exception as e:
        return JsonResponse({
            'status': 'error',
            'message': f'Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„: {str(e)}'
        })
def processing_status(request, pk):
    """Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    return render(request, 'store_analysis/processing_status.html', {
        'analysis': analysis,
        'analysis_id': pk
    })

@login_required
def reprocess_analysis_with_ollama(request, pk):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¬Ø¯Ø¯ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ollama - Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø¯Ø§ÛŒØª Ú©Ù†
    return redirect('store_analysis:processing_status', pk=pk)

@login_required
def start_ollama_processing(request, pk):
    """Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ Ollama"""
    if request.method != 'POST':
        return JsonResponse({'status': 'error', 'message': 'Method not allowed'})
    
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    try:
        analysis_data = analysis.analysis_data
        if not analysis_data:
            return JsonResponse({'status': 'error', 'message': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª'})
        
        # ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
        analysis.status = 'processing'
        analysis.save()
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± background
        import threading
        def process_analysis():
            try:
                ai_analyzer = StoreAnalysisAI()
                detailed_analysis = ai_analyzer.generate_detailed_analysis(analysis_data)
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ØªØ§ÛŒØ¬
                analysis.results = detailed_analysis
                analysis.status = 'completed'
                analysis.preliminary_analysis = detailed_analysis.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ollama ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.')
                analysis.save()
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ StoreAnalysisResult
                from .models import StoreAnalysisResult
                StoreAnalysisResult.objects.update_or_create(
                    store_analysis=analysis,
                    defaults={
                        'overall_score': detailed_analysis.get('overall_score', 75.0),
                        'layout_score': detailed_analysis.get('layout_score', 75.0),
                        'traffic_score': detailed_analysis.get('traffic_score', 75.0),
                        'design_score': detailed_analysis.get('design_score', 75.0),
                        'sales_score': detailed_analysis.get('sales_score', 75.0),
                        'layout_analysis': str(detailed_analysis.get('strengths', [])),
                        'traffic_analysis': str(detailed_analysis.get('weaknesses', [])),
                        'design_analysis': str(detailed_analysis.get('opportunities', [])),
                        'sales_analysis': str(detailed_analysis.get('threats', [])),
                        'overall_analysis': str(detailed_analysis.get('recommendations', [])),
                    }
                )
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„: {e}")
                analysis.status = 'failed'
                analysis.save()
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        thread = threading.Thread(target=process_analysis)
        thread.daemon = True
        thread.start()
        
        return JsonResponse({'status': 'success', 'message': f'Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ "{analysis.store_name}" Ø¨Ø§ Ollama Ø´Ø±ÙˆØ¹ Ø´Ø¯!'})
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´: {e}")
        return JsonResponse({'status': 'error', 'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}'})

@login_required
def start_advanced_ai_processing(request, pk):
    """Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ GPT-4.1"""
    if request.method != 'POST':
        return JsonResponse({'status': 'error', 'message': 'Method not allowed'})
    
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    try:
        analysis_data = analysis.analysis_data
        if not analysis_data:
            return JsonResponse({'status': 'error', 'message': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª'})
        
        # ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´
        analysis.status = 'processing'
        analysis.save()
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¯Ø± background
        import threading
        def process_advanced_analysis():
            try:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Advanced AI Manager
                ai_manager = AdvancedAIManager()
                advanced_analysis = ai_manager.start_advanced_analysis(analysis_data)
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù†ØªØ§ÛŒØ¬
                analysis.results = advanced_analysis
                analysis.status = 'completed'
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø¬Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØºÛŒØ±ÙØ§Ø±Ø³ÛŒ
                from .utils import generate_initial_ai_analysis
                analysis.preliminary_analysis = generate_initial_ai_analysis(analysis.analysis_data)
                analysis.save()
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ StoreAnalysisResult
                from .models import StoreAnalysisResult
                StoreAnalysisResult.objects.update_or_create(
                    store_analysis=analysis,
                    defaults={
                        'overall_score': 85.0,  # Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
                        'layout_score': 85.0,
                        'traffic_score': 85.0,
                        'design_score': 85.0,
                        'sales_score': 85.0,
                        'layout_analysis': str(advanced_analysis.get('detailed_analyses', {})),
                        'traffic_analysis': str(advanced_analysis.get('ai_provider', 'liara')),
                        'design_analysis': str(advanced_analysis.get('models_used', [])),
                        'sales_analysis': str(advanced_analysis.get('analysis_quality', 'premium')),
                        'overall_analysis': str(advanced_analysis.get('final_report', '')),
                    }
                )
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡: {e}")
                analysis.status = 'failed'
                analysis.save()
        
        # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        thread = threading.Thread(target=process_advanced_analysis)
        thread.daemon = True
        thread.start()
        
        return JsonResponse({'status': 'success', 'message': f'Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ "{analysis.store_name}" Ø¨Ø§ GPT-4.1 Ø´Ø±ÙˆØ¹ Ø´Ø¯!'})
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡: {e}")
        return JsonResponse({'status': 'error', 'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}'})


# ==================== Ø³ÛŒØ³ØªÙ… ØªÛŒÚ©Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ====================

def support_center(request):
    """Ù…Ø±Ú©Ø² Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ - ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ"""
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ FAQ
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ FAQ
            faq_categories = FAQService.objects.values('category').distinct()
            categories = []
            for cat in faq_categories:
                category_name = dict(FAQService.CATEGORY_CHOICES).get(cat['category'], cat['category'])
                categories.append({
                    'id': cat['category'],
                    'name': category_name,
                    'description': f'Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ {category_name}',
                    'icon': 'â“',
                    'faq_count': FAQService.objects.filter(category=cat['category']).count()
                })
            
            # Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø­Ø¨ÙˆØ¨ (Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ù†Ø¯)
            try:
                popular_faqs = FAQService.objects.filter(is_featured=True)[:6]
            except Exception:
                popular_faqs = FAQService.objects.all()[:6]
        except Exception as faq_error:
            logger.warning(f"FAQ service not available: {faq_error}")
            # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            categories = [
                {
                    'id': 1,
                    'name': 'Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ',
                    'description': 'Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø³ÛŒØ³ØªÙ…',
                    'icon': 'â“',
                    'faq_count': 5
                },
                {
                    'id': 2,
                    'name': 'Ù…Ø´Ú©Ù„Ø§Øª ÙÙ†ÛŒ',
                    'description': 'Ù…Ø´Ú©Ù„Ø§Øª ÙÙ†ÛŒ Ùˆ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§',
                    'icon': 'ğŸ”§',
                    'faq_count': 3
                },
                {
                    'id': 3,
                    'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ ØµÙˆØ±ØªØ­Ø³Ø§Ø¨',
                    'description': 'Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª',
                    'icon': 'ğŸ’³',
                    'faq_count': 4
                }
            ]
            popular_faqs = [
                {
                    'id': 1,
                    'question': 'Ú†Ú¯ÙˆÙ†Ù‡ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ù…ØŸ',
                    'answer': 'Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ØŒ Ø§Ø¨ØªØ¯Ø§ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯ Ùˆ Ø³Ù¾Ø³ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯.',
                    'category': {'name': 'Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ'},
                    'view_count': 150
                },
                {
                    'id': 2,
                    'question': 'Ú†Ú¯ÙˆÙ†Ù‡ Ú©ÛŒÙ Ù¾ÙˆÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø´Ø§Ø±Ú˜ Ú©Ù†Ù…ØŸ',
                    'answer': 'Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØµÙØ­Ù‡ Ú©ÛŒÙ Ù¾ÙˆÙ„ØŒ Ù…Ø¨Ù„Øº Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ ÙˆØ§Ø±ÛŒØ² Ú©Ù†ÛŒØ¯.',
                    'category': {'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ ØµÙˆØ±ØªØ­Ø³Ø§Ø¨'},
                    'view_count': 120
                }
            ]
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± (Ø§Ú¯Ø± ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)
        user_tickets = []
        if request.user.is_authenticated:
            try:
                user_tickets = SupportTicket.objects.filter(user=request.user).order_by('-created_at')[:5]
            except Exception as ticket_error:
                logger.warning(f"Support tickets not available: {ticket_error}")
                user_tickets = []
        
        context = {
            'faq_categories': categories,
            'popular_faqs': popular_faqs,
            'user_tickets': user_tickets,
        }
        
        return render(request, 'store_analysis/support_center.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± support_center: {e}")
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        context = {
            'faq_categories': [],
            'popular_faqs': [],
            'user_tickets': [],
        }
        return render(request, 'store_analysis/support_center.html', context)


def faq_search(request):
    """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø³ÙˆØ§Ù„Ø§Øª Ù…ØªØ¯Ø§ÙˆÙ„"""
    try:
        query = request.GET.get('q', '').strip()
        category_id = request.GET.get('category', None)
        
        faq_service = FAQService()
        
        if query:
            results = faq_service.search_faqs(query, category_id, limit=20)
        else:
            results = []
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ±
        categories = faq_service.get_faq_categories()
        
        context = {
            'query': query,
            'category_id': category_id,
            'results': results,
            'categories': categories,
        }
        
        return render(request, 'store_analysis/faq_search.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± faq_search: {e}")
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        return render(request, 'store_analysis/faq_search.html', {'results': []})


def faq_detail(request, faq_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ø³ÙˆØ§Ù„ Ù…ØªØ¯Ø§ÙˆÙ„"""
    try:
        faq_service = FAQService()
        
        # Ø¯Ø±ÛŒØ§ÙØª FAQ
        faq = faq_service.get_faq_by_id(faq_id)
        if not faq:
            messages.error(request, 'Ø³ÙˆØ§Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯.')
            return redirect('store_analysis:support_center')
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø·
        related_faqs = faq_service.get_related_faqs(faq_id, limit=3)
        
        context = {
            'faq': faq,
            'related_faqs': related_faqs,
        }
        
        return render(request, 'store_analysis/faq_detail.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± faq_detail: {e}")
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        return redirect('store_analysis:support_center')


@login_required
def create_ticket(request):
    """Ø§ÛŒØ¬Ø§Ø¯ ØªÛŒÚ©Øª Ø¬Ø¯ÛŒØ¯"""
    try:
        if request.method == 'POST':
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            category = request.POST.get('category', 'general')
            subject = request.POST.get('subject', '').strip()
            description = request.POST.get('description', '').strip()
            priority = request.POST.get('priority', 'medium')
            
            # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
            if not subject or not description:
                messages.error(request, 'âŒ Ù„Ø·ÙØ§Ù‹ ØªÙ…Ø§Ù… ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø±Ø§ Ù¾Ø± Ú©Ù†ÛŒØ¯.')
                return render(request, 'store_analysis/create_ticket.html', {
                    'categories': [('general', 'Ø¹Ù…ÙˆÙ…ÛŒ'), ('technical', 'ÙÙ†ÛŒ'), ('billing', 'Ù…Ø§Ù„ÛŒ')],
                    'priorities': [('low', 'Ú©Ù…'), ('medium', 'Ù…ØªÙˆØ³Ø·'), ('high', 'Ø¨Ø§Ù„Ø§')],
                })
            
            # Ø§ÛŒØ¬Ø§Ø¯ ØªÛŒÚ©Øª Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
            try:
                # ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ØªÛŒÚ©Øª Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ (Ø¨Ø§ Ø«Ø§Ù†ÛŒÙ‡ Ùˆ microseconds Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² uniqueness)
                import time as time_module
                timestamp = timezone.now()
                unique_suffix = f"{timestamp.strftime('%m%d%H%M%S')}-{request.user.id}-{int(time_module.time() * 1000) % 10000}"
                ticket_id = f"TK-{unique_suffix}"
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ ticket_id Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø§Ø´Ø¯
                while SupportTicket.objects.filter(ticket_id=ticket_id).exists():
                    unique_suffix = f"{timestamp.strftime('%m%d%H%M%S')}-{request.user.id}-{int(time_module.time() * 1000) % 10000}"
                    ticket_id = f"TK-{unique_suffix}"
                
                ticket = SupportTicket.objects.create(
                    ticket_id=ticket_id,
                    user=request.user,
                    subject=subject,
                    description=description,
                    category=category,
                    priority=priority,
                    status='open',
                    tags=[]  # ÙÛŒÙ„Ø¯ tags Ø¨Ø§ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ
                )
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù‡ ØªÛŒÚ©Øª ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯
                # Django Ø®ÙˆØ¯Ø´ transaction Ø±Ø§ commit Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                saved_ticket = SupportTicket.objects.get(id=ticket.id)
                logger.info(f"âœ… ØªÛŒÚ©Øª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: ID={saved_ticket.id}, ticket_id={saved_ticket.ticket_id}, user={request.user.username}, user_id={request.user.id}")
                
                # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± (Ø¨Ø§ refresh Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³)
                user_tickets_count = SupportTicket.objects.filter(user=request.user).count()
                logger.info(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {request.user.username}: {user_tickets_count}")
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ ØªÛŒÚ©Øª Ø¬Ø¯ÛŒØ¯ Ø¯Ø± query ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
                user_tickets = list(SupportTicket.objects.filter(user=request.user).values_list('ticket_id', flat=True))
                logger.info(f"ğŸ“‹ Ù„ÛŒØ³Øª ticket_id Ù‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±: {user_tickets[:5]}")
                
                if saved_ticket.ticket_id not in user_tickets:
                    logger.error(f"âš ï¸ ØªÛŒÚ©Øª {saved_ticket.ticket_id} Ø¯Ø± query Ú©Ø§Ø±Ø¨Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                else:
                    logger.info(f"âœ… ØªÛŒÚ©Øª {saved_ticket.ticket_id} Ø¯Ø± query Ú©Ø§Ø±Ø¨Ø± ÛŒØ§ÙØª Ø´Ø¯")
                
                messages.success(request, f'âœ… ØªÛŒÚ©Øª Ø´Ù…Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯! Ø´Ù†Ø§Ø³Ù‡ ØªÛŒÚ©Øª: {ticket.ticket_id}')
                
                # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ Ù„ÛŒØ³Øª ØªÛŒÚ©Øªâ€ŒÙ‡Ø§
                return redirect('store_analysis:ticket_list')
                
            except Exception as db_error:
                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ØªÛŒÚ©Øª: {db_error}", exc_info=True)
                messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ ØªÛŒÚ©Øª: {str(db_error)}')
            return redirect('store_analysis:support_center')
        
        # Ù†Ù…Ø§ÛŒØ´ ÙØ±Ù…
        context = {
            'categories': [('general', 'Ø¹Ù…ÙˆÙ…ÛŒ'), ('technical', 'ÙÙ†ÛŒ'), ('billing', 'Ù…Ø§Ù„ÛŒ')],
            'priorities': [('low', 'Ú©Ù…'), ('medium', 'Ù…ØªÙˆØ³Ø·'), ('high', 'Ø¨Ø§Ù„Ø§')],
        }
        
        return render(request, 'store_analysis/create_ticket.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± create_ticket: {e}")
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        return render(request, 'store_analysis/create_ticket.html', {
            'categories': [('general', 'Ø¹Ù…ÙˆÙ…ÛŒ'), ('technical', 'ÙÙ†ÛŒ'), ('billing', 'Ù…Ø§Ù„ÛŒ')],
            'priorities': [('low', 'Ú©Ù…'), ('medium', 'Ù…ØªÙˆØ³Ø·'), ('high', 'Ø¨Ø§Ù„Ø§')],
        })


@login_required
def ticket_list(request):
    """Ù„ÛŒØ³Øª ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    try:
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Manager Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ missing Ø±Ø§ defer Ú©Ù†Ø¯
        tickets = SupportTicket.objects.filter(user=request.user).order_by('-created_at')
        
        # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª
        status_filter = request.GET.get('status', '')
        if status_filter:
            tickets = tickets.filter(status=status_filter)
        
        # Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ debugging - Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
        total_count = tickets.count()
        logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {request.user.username}: {total_count}")
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        if total_count > 0:
            ticket_ids = list(tickets.values_list('ticket_id', flat=True)[:5])
            logger.info(f"ğŸ” Ù†Ù…ÙˆÙ†Ù‡ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§: {ticket_ids}")
        else:
            logger.warning(f"âš ï¸ Ù‡ÛŒÚ† ØªÛŒÚ©ØªÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {request.user.username} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
            all_tickets_count = SupportTicket.objects.count()
            logger.info(f"ğŸ” ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³: {all_tickets_count}")
        
        # ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        paginator = Paginator(tickets, 10)
        page_number = request.GET.get('page')
        page_obj = paginator.get_page(page_number)
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª paginator
        logger.info(f"ğŸ“„ Paginator: count={paginator.count}, num_pages={paginator.num_pages}, page_obj.number={page_obj.number}")
        
        context = {
            'page_obj': page_obj,
            'tickets': list(page_obj),  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„ÛŒØ³Øª Ù…Ø³ØªÙ‚ÛŒÙ… ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ template
            'tickets_count': total_count,  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§
            'status_choices': [('open', 'Ø¨Ø§Ø²'), ('in_progress', 'Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ'), ('resolved', 'Ø­Ù„ Ø´Ø¯Ù‡'), ('closed', 'Ø¨Ø³ØªÙ‡')],
            'current_status': status_filter,
        }
        
        return render(request, 'store_analysis/ticket_list.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ticket_list: {e}", exc_info=True)
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        return render(request, 'store_analysis/ticket_list.html', {
            'page_obj': None,
            'tickets': [],
            'tickets_count': 0,
        })


@login_required
def ticket_detail(request, ticket_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª ØªÛŒÚ©Øª"""
    try:
        ticket = get_object_or_404(SupportTicket, ticket_id=ticket_id, user=request.user)
        messages_list = TicketMessage.objects.filter(ticket=ticket).order_by('created_at')
        
        if request.method == 'POST':
            content = request.POST.get('content', '').strip()
            if content:
                # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯
                TicketMessage.objects.create(
                    ticket=ticket,
                    sender=request.user,
                    content=content,
                    message_type='admin' if request.user.is_staff else 'user',
                    is_internal=False  # Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø§Ø³Øª
                )
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªÛŒÚ©Øª
                if ticket.status == 'waiting_user':
                    ticket.status = 'open'
                    ticket.save()
                
                messages.success(request, 'Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.')
                return redirect('store_analysis:ticket_detail', ticket_id=ticket_id)
        
        context = {
            'ticket': ticket,
            'messages': messages_list,
        }
        
        return render(request, 'store_analysis/ticket_detail.html', context)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ticket_detail: {e}")
        messages.error(request, 'Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.')
        return redirect('store_analysis:ticket_list')


def suggest_faqs_api(request):
    """API Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø³ÙˆØ§Ù„Ø§Øª Ù…ØªØ¯Ø§ÙˆÙ„"""
    try:
        query = request.GET.get('q', '').strip()
        
        if not query or len(query) < 2:
            return JsonResponse({'suggestions': []})
        
        faq_service = FAQService()
        suggestions = faq_service.suggest_faqs(query, limit=5)
        
        return JsonResponse({'suggestions': suggestions})
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± suggest_faqs_api: {e}")
        return JsonResponse({'suggestions': []})

@login_required
def check_processing_status(request, pk):
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    return JsonResponse({
        'status': analysis.status,
        'completed': analysis.status == 'completed',
        'failed': analysis.status == 'failed',
        'processing': analysis.status == 'processing'
    })
def _convert_ollama_results_to_text(results):
    """ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ† Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø±Ø§ÛŒ PDF"""
    try:
        text_content = ""
        
        # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ø§Ø² Liara AI Ø§Ø³ØªØŒ Ø§Ø² final_report Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if 'final_report' in results:
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ùˆ ÙØ±Ù…Øª Ú©Ø±Ø¯Ù† final_report
            report = results['final_report']
            
            # Ø­Ø°Ù escape characters
            report = report.replace('\\n', '\n')
            report = report.replace('\\u200c', '\u200c')
            
            # Ø­Ø°Ù JSON syntax Ø§Ú¯Ø± Ù‡Ø³Øª
            import re
            # Ø­Ø°Ù ' Ùˆ " Ø§Ø¶Ø§ÙÛŒ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ Ùˆ Ø§Ù†ØªÙ‡Ø§ÛŒ Ù…ØªÙ†
            report = report.strip("'\"")
            
            # Ø§Ú¯Ø± Ù…ØªÙ† Ø´Ø§Ù…Ù„ store_info Ùˆ... Ø§Ø³ØªØŒ ÙÙ‚Ø· final_report Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†
            if 'final_report' in report or 'store_info' in report:
                try:
                    import json
                    data = json.loads(report)
                    if isinstance(data, dict) and 'final_report' in data:
                        report = data['final_report']
                except:
                    pass
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² template Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø±Ø¯Ù‡ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ù†Ú¯Ø§Ø±Ø´)
            try:
                from .services.comprehensive_report_template import ComprehensiveReportTemplate
                
                ai_result = {
                    'analysis_text': report,
                    'scores': results.get('scores', {
                        'overall_score': results.get('overall_score', 75),
                        'design_score': results.get('design_score', 70),
                        'quality_score': results.get('quality_score', 85)
                    })
                }
                
                analysis_data = results.get('store_info', {
                    'store_name': results.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡'),
                    'store_type': results.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
                })
                
                formatted_report = ComprehensiveReportTemplate.format_comprehensive_report(
                    analysis_data, ai_result
                )
                
                return formatted_report
                
            except Exception as e:
                logger.error(f"Error formatting report: {e}")
                return report  # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ú¯Ø²Ø§Ø±Ø´ Ø§ØµÙ„ÛŒ
        
        # Ø§Ú¯Ø± analysis_text Ø§Ø² Ollama/local Ø§Ø³Øª
        if 'analysis_text' in results:
            text_content += f"## ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡\n\n{results['analysis_text']}\n\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ù…ØªÛŒØ§Ø²Ø§Øª
        if 'overall_score' in results:
            text_content += f"## Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ\n\nØ§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ: {results['overall_score']}/10\n\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø§Ø· Ù‚ÙˆØª
        if 'strengths' in results and results['strengths']:
            text_content += "## Ù†Ù‚Ø§Ø· Ù‚ÙˆØª\n\n"
            if isinstance(results['strengths'], list):
                for strength in results['strengths']:
                    text_content += f"â€¢ {strength}\n"
            else:
                text_content += f"{results['strengths']}\n"
            text_content += "\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù
        if 'weaknesses' in results and results['weaknesses']:
            text_content += "## Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù\n\n"
            if isinstance(results['weaknesses'], list):
                for weakness in results['weaknesses']:
                    text_content += f"â€¢ {weakness}\n"
            else:
                text_content += f"{results['weaknesses']}\n"
            text_content += "\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
        if 'recommendations' in results and results['recommendations']:
            text_content += "## ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ\n\n"
            if isinstance(results['recommendations'], list):
                for recommendation in results['recommendations']:
                    text_content += f"â€¢ {recommendation}\n"
            else:
                text_content += f"{results['recommendations']}\n"
            text_content += "\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ±ØµØªâ€ŒÙ‡Ø§
        if 'opportunities' in results and results['opportunities']:
            text_content += "## ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯\n\n"
            if isinstance(results['opportunities'], list):
                for opportunity in results['opportunities']:
                    text_content += f"â€¢ {opportunity}\n"
            else:
                text_content += f"{results['opportunities']}\n"
            text_content += "\n"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙ‡Ø¯ÛŒØ¯Ø§Øª
        if 'threats' in results and results['threats']:
            text_content += "## ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ùˆ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§\n\n"
            if isinstance(results['threats'], list):
                for threat in results['threats']:
                    text_content += f"â€¢ {threat}\n"
            else:
                text_content += f"{results['threats']}\n"
            text_content += "\n"
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ù¾ÛŒØ§Ù… Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        if not text_content.strip():
            text_content = "ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ollama Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.\n\nÙ†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª."
        
        return text_content
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ollama: {e}")
        return "ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ollama Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª."


@login_required
def advanced_ml_analysis(request, pk):
    """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ML"""
    try:
        # Ø§Ú¯Ø± Ø§Ø¯Ù…ÛŒÙ† Ø§Ø³ØªØŒ Ù‡Ø± ØªØ­Ù„ÛŒÙ„ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
        if request.user.is_staff or request.user.is_superuser:
            analysis = get_object_or_404(StoreAnalysis, pk=pk)
        else:
            # Ú©Ø§Ø±Ø¨Ø± Ø¹Ø§Ø¯ÛŒ ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
            analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ
        if not request.user.is_authenticated:
            return redirect('login')
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        analysis_data = analysis.get_analysis_data()
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ AI
        ai_analyzer = StoreAnalysisAI()
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ML
        ml_analysis = ai_analyzer.generate_advanced_ml_analysis(analysis_data)
        
        # ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù…Ø¹Ù…ÙˆÙ„ÛŒ
        regular_analysis = ai_analyzer.generate_detailed_analysis(analysis_data)
        
        context = {
            'analysis': analysis,
            'ml_analysis': ml_analysis,
            'regular_analysis': regular_analysis,
            'analysis_data': analysis_data,
            'is_admin': request.user.is_staff or request.user.is_superuser,
        }
        
        return render(request, 'store_analysis/advanced_ml_analysis.html', context)
        
    except Exception as e:
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡: {str(e)}')
        return redirect('store_analysis:analysis_results', pk=pk)


def ai_analysis_guide(request):
    """Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„ AI"""
    return render(request, 'store_analysis/ai_analysis_guide.html')

def check_legal_agreement(request):
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ§ÛŒÛŒØ¯ ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ"""
    try:
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø² session ÛŒØ§ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        if request.user.is_authenticated:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø² session
            accepted = request.session.get('legal_agreement_accepted', False)
            
            # Ø§Ú¯Ø± Ø¯Ø± session Ù†ÛŒØ³ØªØŒ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†
            if not accepted:
                from .models import UserProfile
                try:
                    profile = UserProfile.objects.get(user=request.user)
                    accepted = profile.legal_agreement_accepted
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± session Ø¨Ø±Ø§ÛŒ Ø¯ÙØ¹Ø§Øª Ø¨Ø¹Ø¯
                    request.session['legal_agreement_accepted'] = accepted
                except UserProfile.DoesNotExist:
                    accepted = False
        else:
            accepted = False
        
        return JsonResponse({
            'accepted': accepted,
            'user_id': request.user.id if request.user.is_authenticated else None
        })
    except Exception as e:
        return JsonResponse({
            'accepted': False,
            'error': str(e)
        })

def accept_legal_agreement(request):
    """ØªØ§ÛŒÛŒØ¯ ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ - Ù†Ø³Ø®Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    if request.method == 'POST':
        try:
            import json
            data = json.loads(request.body)
            
            if data.get('accepted'):
                # Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ø³Ø´Ù† Ø°Ø®ÛŒØ±Ù‡ Ú©Ù† (Ú†Ù‡ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ø§Ø´Ø¯ Ú†Ù‡ Ù†Ø¨Ø§Ø´Ø¯)
                request.session['legal_agreement_accepted'] = True
                request.session['legal_agreement_date'] = timezone.now().isoformat()

                # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ø§Ø³ØªØŒ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù‡Ù… Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
                if request.user.is_authenticated:
                    try:
                        from .models import UserProfile
                        from django.db import connection
                        
                        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ UserProfile
                        try:
                            profile = UserProfile.objects.get(user=request.user)
                            profile.legal_agreement_accepted = True
                            profile.legal_agreement_date = timezone.now()
                            profile.save()
                        except UserProfile.DoesNotExist:
                            # Ø§ÛŒØ¬Ø§Ø¯ UserProfile Ø¨Ø§ raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ address
                            with connection.cursor() as cursor:
                                cursor.execute(
                                    "INSERT INTO store_analysis_userprofile (user_id, phone, legal_agreement_accepted, legal_agreement_date, newsletter_subscription, email_notifications, sms_notifications, bio, created_at, updated_at) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())",
                                    [request.user.id, '', True, timezone.now(), True, True, False, '']
                                )

                        logger.info(f"Legal agreement accepted for user {request.user.id}")
                        
                    except Exception as db_error:
                        logger.error(f"Database error in legal agreement: {str(db_error)}")
                        # Ø­ØªÛŒ Ø§Ú¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø®Ø·Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ session Ø±Ø§ Ø­ÙØ¸ Ú©Ù†
                        pass

                return JsonResponse({
                    'success': True,
                    'message': 'ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ§ÛŒÛŒØ¯ Ø´Ø¯'
                })
            else:
                return JsonResponse({
                    'success': False,
                    'message': 'ØªØ§ÛŒÛŒØ¯ ØªØ¹Ù‡Ø¯Ù†Ø§Ù…Ù‡ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª'
                })
                
        except json.JSONDecodeError as json_error:
            logger.error(f"JSON decode error: {str(json_error)}")
            return JsonResponse({
                'success': False,
                'message': 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª'
            })
        except Exception as e:
            logger.error(f"Unexpected error in legal agreement: {str(e)}")
            return JsonResponse({
                'success': False,
                'message': 'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªØ§ÛŒÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.'
            })
    
    return JsonResponse({
        'success': False,
        'message': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'
    })

# --- ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ---

@login_required
def store_analysis_form(request, analysis_id=None):
    """ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ - Û· Ú¯Ø§Ù… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
    analysis = None

    if analysis_id is not None:
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ø§Ø³ØªØŒ ÙÙ‚Ø· ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯
        if request.user.is_authenticated:
            analysis = get_object_or_404(StoreAnalysis, pk=analysis_id, user=request.user)
        else:
            # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ù†ÛŒØ³ØªØŒ Ø§Ø² session Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            session_analysis_id = request.session.get('analysis_id')
            if session_analysis_id == analysis_id:
                analysis = get_object_or_404(StoreAnalysis, pk=analysis_id)
            else:
                messages.error(request, 'âŒ Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø² Ø¨Ù‡ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„')
                return redirect('store_analysis:index')
    else:
        session_analysis_id = request.session.get('analysis_id')
        if session_analysis_id:
            analysis = StoreAnalysis.objects.filter(pk=session_analysis_id, user=request.user).first()

    if request.method == 'POST':
        try:
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù…
            form_data = {}
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù…
            for key, value in request.POST.items():
                if key != 'csrfmiddlewaretoken':
                    form_data[key] = value
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡
            uploaded_files = {}
            file_fields = ['store_photos', 'store_layout', 'shelf_photos', 'customer_flow_video', 
                          'store_map', 'window_display_photos', 'entrance_photos', 
                          'checkout_photos', 'surveillance_footage', 'sales_file', 'product_catalog']
            
            upload_errors = []
            upload_success_count = 0
            
            for field in file_fields:
                if field in request.FILES:
                    try:
                        file_obj = request.FILES[field]
                        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ§ÛŒÙ„ (Ø­Ø¯Ø§Ú©Ø«Ø± 10MB)
                        max_size = 10 * 1024 * 1024  # 10MB
                        if file_obj.size > max_size:
                            upload_errors.append(f'ÙØ§ÛŒÙ„ {field} Ø¨Ø²Ø±Ú¯ØªØ± Ø§Ø² 10 Ù…Ú¯Ø§Ø¨Ø§ÛŒØª Ø§Ø³Øª Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯.')
                            continue
                        
                        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
                        from django.core.files.storage import default_storage
                        file_path = default_storage.save(f'uploads/{field}/{file_obj.name}', file_obj)
                        uploaded_files[field] = {
                            'name': file_obj.name,
                            'size': file_obj.size,
                            'path': file_path,
                            'url': default_storage.url(file_path)
                        }
                        upload_success_count += 1
                        logger.info(f"File uploaded: {field} - {file_obj.name} ({file_obj.size} bytes)")
                    except Exception as e:
                        error_msg = f'Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ {field}: {str(e)}'
                        upload_errors.append(error_msg)
                        logger.error(f"Error uploading file {field}: {e}")
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ form_data
            form_data['uploaded_files'] = uploaded_files
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª
            has_actual_files = bool(uploaded_files) and any(
                isinstance(v, dict) and (v.get('path') or v.get('name'))
                for v in uploaded_files.values()
                if v and not isinstance(v, str)
            )
            
            # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØºØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§ ÛŒØ§ Ù…ÙˆÙÙ‚ÛŒØª
            if upload_errors:
                error_message = 'âš ï¸ Ø¨Ø±Ø®ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù†Ø¯:\n' + '\n'.join(upload_errors)
                if has_actual_files:
                    messages.warning(request, error_message)
                else:
                    messages.error(request, error_message + '\n\nâŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ (Ù…Ø«Ù„Ø§Ù‹ ØªØµÙˆÛŒØ± ÙØ±ÙˆØ´Ú¯Ø§Ù‡) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.')
            elif has_actual_files:
                messages.success(request, f'âœ… {upload_success_count} ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯.')
            else:
                messages.error(request, 'âŒ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ØŒ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ (Ù…Ø«Ù„Ø§Ù‹ ØªØµÙˆÛŒØ± ÙØ±ÙˆØ´Ú¯Ø§Ù‡) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.')
            
            # Ø§Ú¯Ø± Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ØŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ù‡ ÙØ±Ù… Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            if not has_actual_files:
                if analysis:
                    request.session['analysis_id'] = analysis.id
                    return redirect('store_analysis:forms', analysis_id=analysis.id)
                else:
                    # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ Ùˆ ÙØ§ÛŒÙ„ÛŒ Ù‡Ù… Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ØŒ ÛŒÚ© ØªØ­Ù„ÛŒÙ„ pending Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù† Ùˆ Ø¨Ù‡ ÙØ±Ù… Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
                    analysis = StoreAnalysis.objects.create(
                        user=request.user,
                        analysis_type='comprehensive_7step',
                        store_name=form_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¬Ø¯ÛŒØ¯'),
                        status='pending',
                        analysis_data=form_data
                    )
                    request.session['analysis_id'] = analysis.id
                    return redirect('store_analysis:forms', analysis_id=analysis.id)
            
            if analysis is None:
                analysis = StoreAnalysis.objects.create(
                    user=request.user,
                    analysis_type='comprehensive_7step',
                    store_name=form_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¬Ø¯ÛŒØ¯'),
                    status='processing',
                    analysis_data=form_data
                )
                logger.info("StoreAnalysis created: %s for user %s", analysis.pk, request.user.username)
            else:
                analysis.analysis_data = form_data
                analysis.store_name = form_data.get('store_name', analysis.store_name)
                analysis.store_type = form_data.get('store_type', analysis.store_type)
                analysis.store_size = form_data.get('store_size', analysis.store_size)
                analysis.additional_info = form_data.get('additional_info', analysis.additional_info)
                # ÙÙ‚Ø· Ø§Ú¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ØŒ ÙˆØ¶Ø¹ÛŒØª Ø±Ø§ Ø¨Ù‡ processing ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡
                if has_actual_files:
                    analysis.status = 'processing'
                else:
                    # Ø§Ú¯Ø± ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ù†Ø´Ø¯Ù‡ØŒ ÙˆØ¶Ø¹ÛŒØª Ø±Ø§ pending Ù†Ú¯Ù‡ Ø¯Ø§Ø±
                    if analysis.status not in ['completed', 'failed']:
                        analysis.status = 'pending'
                analysis.save()

            request.session['analysis_id'] = analysis.pk
            
            # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª (package_type='basic' Ùˆ final_amount=0)ØŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†
            if analysis.package_type == 'basic' and analysis.final_amount == 0:
                try:
                    # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ FreeAnalysisService Ø¯Ø± background
                    import threading
                    
                    def start_free_analysis():
                        """Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± background"""
                        try:
                            logger.info(f"ğŸ†“ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}")
                            
                            from .ai_services.free_analysis_service import FreeAnalysisService
                            free_service = FreeAnalysisService()
                            
                            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
                            store_data = {
                                'store_name': analysis.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                                'store_type': analysis.analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ') if analysis.analysis_data else 'Ø¹Ù…ÙˆÙ…ÛŒ',
                                'store_size': str(analysis.analysis_data.get('store_size', 0)) if analysis.analysis_data else '0',
                                'store_address': analysis.analysis_data.get('store_address', '') if analysis.analysis_data else '',
                                'description': analysis.analysis_data.get('description', '') if analysis.analysis_data else '',
                                **(analysis.analysis_data if isinstance(analysis.analysis_data, dict) else {})
                            }
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§ÙˆÛŒØ± Ø§Ø² uploaded_files
                            images = []
                            if analysis.analysis_data and 'uploaded_files' in analysis.analysis_data:
                                uploaded_files = analysis.analysis_data['uploaded_files']
                                image_fields = ['store_photos', 'store_layout', 'shelf_photos', 
                                              'window_display_photos', 'entrance_photos', 'checkout_photos']
                                for field in image_fields:
                                    if field in uploaded_files:
                                        file_info = uploaded_files[field]
                                        if isinstance(file_info, dict) and 'path' in file_info:
                                            images.append(file_info['path'])
                            
                            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ FreeAnalysisService
                            logger.info(f"ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø§ {len(images)} ØªØµÙˆÛŒØ±...")
                            free_analysis_result = free_service.analyze_store(store_data)
                            
                            if free_analysis_result and free_analysis_result.get('status') == 'completed':
                                logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}")
                                
                                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ results Ø¨Ø§ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
                                analysis_results = free_analysis_result.get('analysis_results', {})
                                report_content = free_analysis_result.get('report', '')
                                
                                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ analysis_text Ø§Ø² Ù†ØªØ§ÛŒØ¬ - Ú†Ù†Ø¯ Ø±ÙˆØ´ Ù…Ø®ØªÙ„Ù
                                analysis_text = None
                                
                                # Ø±ÙˆØ´ 1: Ø§Ø² analysis_results
                                if isinstance(analysis_results, dict):
                                    analysis_text = (
                                        analysis_results.get('analysis_text') or 
                                        analysis_results.get('summary') or
                                        analysis_results.get('executive_summary', {}).get('summary') if isinstance(analysis_results.get('executive_summary'), dict) else None
                                    )
                                
                                # Ø±ÙˆØ´ 2: Ø§Ø² report_content
                                if not analysis_text and report_content:
                                    analysis_text = report_content
                                
                                # Ø±ÙˆØ´ 3: Ø³Ø§Ø®Øª analysis_text Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
                                if not analysis_text and isinstance(analysis_results, dict):
                                    # Ø³Ø§Ø®Øª Ù…ØªÙ† Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ØªØ­Ù„ÛŒÙ„
                                    text_parts = []
                                    
                                    if analysis_results.get('executive_summary'):
                                        exec_summary = analysis_results['executive_summary']
                                        if isinstance(exec_summary, dict):
                                            text_parts.append(f"Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ: {exec_summary.get('summary', exec_summary.get('store_name', ''))}")
                                    
                                    if analysis_results.get('current_condition'):
                                        current = analysis_results['current_condition']
                                        if isinstance(current, dict):
                                            text_parts.append(f"ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ: Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ {current.get('overall_score', 'Ù†Ø§Ù…Ø´Ø®Øµ')}/10")
                                    
                                    if analysis_results.get('recommendations'):
                                        recs = analysis_results['recommendations']
                                        if isinstance(recs, list) and len(recs) > 0:
                                            text_parts.append(f"ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§: {', '.join(str(r) for r in recs[:5])}")
                                    
                                    if text_parts:
                                        analysis_text = "\n\n".join(text_parts)
                                
                                # Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² analysis_text Ù†Ø¯Ø§Ø±ÛŒÙ…ØŒ Ø§Ø² report Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                                if not analysis_text:
                                    analysis_text = report_content or 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.'
                                
                                current_results = analysis.results or {}
                                current_results.update({
                                    'analysis_text': analysis_text or 'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.',
                                    'free_analysis': free_analysis_result,
                                    'analysis_source': 'free_analysis_service',
                                    'ai_provider': 'ollama',
                                    'confidence_score': free_analysis_result.get('confidence_score', 0.8),
                                    'quality_level': free_analysis_result.get('quality_level', 'professional'),
                                    'analyzed_at': timezone.now().isoformat(),
                                })
                                
                                # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
                                analysis.results = current_results
                                analysis.status = 'completed'
                                analysis.save(update_fields=['results', 'status'])
                                
                                logger.info(f"ğŸ‰ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† {analysis.id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
                            else:
                                logger.warning(f"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ù†Ø§Ù‚Øµ Ø¨ÙˆØ¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}")
                                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² fallback
                                ensure_basic_analysis_results(analysis)
                                
                        except Exception as e:
                            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† background Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}: {e}", exc_info=True)
                            # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø§Ø² fallback Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                            try:
                                ensure_basic_analysis_results(analysis)
                            except Exception as fallback_error:
                                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± fallback Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}: {fallback_error}", exc_info=True)
                    
                    # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± background
                    analysis_thread = threading.Thread(target=start_free_analysis, daemon=True)
                    analysis_thread.start()
                    logger.info(f"ğŸ§µ Thread ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ {analysis.id} Ø´Ø±ÙˆØ¹ Ø´Ø¯")
                    
                    messages.success(request, 'âœ… ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯! ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª. Ù¾Ø³ Ø§Ø² Ø­Ø¯ÙˆØ¯ 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.')
                except Exception as err:
                    logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {analysis.id}: {err}", exc_info=True)
                    # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø§Ø² fallback Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                    try:
                        ensure_basic_analysis_results(analysis)
                    except Exception as fallback_error:
                        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± fallback: {fallback_error}", exc_info=True)
                    messages.success(request, 'âœ… ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯! ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª.')
            else:
                # Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒØŒ Ø§Ø² fallback Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† (ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯)
                try:
                    ensure_basic_analysis_results(analysis)
                except Exception as generator_error:
                    logger.error("Fallback analysis generation failed for %s: %s", analysis.pk, generator_error)
                messages.success(request, 'âœ… ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯! Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø®ØªØŒ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.')

            return redirect('store_analysis:analysis_results', pk=analysis.pk)
            
        except Exception as e:
            logger.error(f"Error processing form: {e}")
            messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ù…: {str(e)}')
            if analysis:
                return redirect('store_analysis:forms', analysis_id=analysis.pk)
            return redirect('store_analysis:forms')
    
    # Ù†Ù…Ø§ÛŒØ´ ÙØ±Ù…
    context = {
        'analysis': analysis,
        'form_data': (analysis.analysis_data if analysis and isinstance(analysis.analysis_data, dict) else {})
    }
    return render(request, 'store_analysis/forms.html', context)


@login_required
def submit_analysis(request):
    """Ø§Ø±Ø³Ø§Ù„ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ Ùˆ Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª"""
    if request.method == 'POST':
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù…
            form_data = request.POST.dict()
            logger.info(f"Form submission - User: {request.user}, Data keys: {list(form_data.keys())}")

            # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ù…Ø¯Ù„
            store_name = form_data.get('store_name') or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
            # ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ ØºÛŒØ±Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ù‡ StoreAnalysis Ù¾Ø§Ø³ Ù†Ø¯Ù‡
            # URLField Ø®Ø§Ù„ÛŒ Ù…Ø¬Ø§Ø² Ù†ÛŒØ³ØªØ› Ù…Ù‚Ø¯Ø§Ø± Ø§Ù…Ù† Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ú†ÛŒØ²ÛŒ Ù†ÙØ±Ø³ØªØ§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
            store_url = form_data.get('store_url') or 'https://chidmano.ir'

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡
            cost_breakdown = calculate_analysis_cost(form_data)

            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
            analysis = StoreAnalysis.objects.create(
                user=request.user,
                store_name=store_name,
                store_url=store_url,
                analysis_type='comprehensive',
                status='pending',
                analysis_data=form_data
            )

            # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´
            # Ø³Ø§Ø®Øª Ø´Ù…Ø§Ø±Ù‡ Ø³ÙØ§Ø±Ø´ ÛŒÚ©ØªØ§ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´ Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ
            generated_order_number = f"ORD-{uuid.uuid4().hex[:12].upper()}"
            order = Order.objects.create(
                user=request.user,
                order_number=generated_order_number,
                original_amount=Decimal(str(cost_breakdown['total'])),
                base_amount=Decimal(str(cost_breakdown['total'])),
                discount_amount=Decimal(str(cost_breakdown.get('discount', 0))),
                final_amount=Decimal(str(cost_breakdown['final'])),
                status='pending',
                payment_method='online',
                transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
            )

            # Ø§ØªØµØ§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ø³ÙØ§Ø±Ø´
            analysis.order = order
            analysis.save()

            logger.info(f"Order created - NUMBER: {order.order_number}, Amount: {order.final_amount}")

            # Ø§Ú¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª AJAX Ø§Ø³ØªØŒ Ù¾Ø§Ø³Ø® JSON Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest' or 'application/json' in request.headers.get('Accept', ''):
                return JsonResponse({
                    'success': True,
                    'message': 'ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª...',
                    'redirect_url': f"/store/payment/{order.order_number}/",
                    'payment_required': True
                })

            # Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø±ÛŒØ¯Ø§ÛŒØ±Ú©Øª Ø¹Ø§Ø¯ÛŒ
            return redirect('store_analysis:payment_page', order_id=order.order_number)

        except Exception as e:
            logger.error(f"Error in submit_analysis: {str(e)}", exc_info=True)
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest' or 'application/json' in request.headers.get('Accept', ''):
                return JsonResponse({
                    'success': False,
                    'message': f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÙØ±Ù…: {str(e)}"
                }, status=500)
            messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÙØ±Ù…: {str(e)}')
            return render(request, 'store_analysis/forms.html')

    return render(request, 'store_analysis/forms.html')


@login_required
def analysis_create(request):
    if request.method == 'POST':
        # form = StoreAnalysisForm(request.POST, request.FILES)
        # if form.is_valid():
            # analysis = form.save(commit=False)
            # analysis.user = request.user
            # analysis.save()
            return redirect('store_analysis:analysis_list')
    # else:
        # form = StoreAnalysisForm()
    return render(request, 'store_analysis/forms.html', {'form': None})

@login_required
def analysis_progress(request, pk):
    """Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡ Ù¾ÛŒØ´Ø±ÙØª Real-time ØªØ­Ù„ÛŒÙ„"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„
    from .services.real_time_analyzer import RealTimeAnalyzer
    analyzer = RealTimeAnalyzer()
    status = analyzer.get_analysis_status(pk)
    
    context = {
        'analysis': analysis,
        'status': status,
    }
    
    return render(request, 'store_analysis/analysis_progress.html', context)
@login_required
def start_analysis(request, pk):
    """Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Real-time"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨
            store_data = {
                'store_name': analysis.store_name,
                'store_type': analysis.store_type,
                'store_size': analysis.store_size,
                'store_dimensions': analysis.store_dimensions,
                'entrances': analysis.entrances,
                'shelf_count': analysis.shelf_count,
                'shelf_dimensions': analysis.shelf_dimensions,
                'shelf_contents': analysis.shelf_contents,
                'checkout_location': analysis.checkout_location,
                'unused_area_type': analysis.unused_area_type,
                'unused_area_size': analysis.unused_area_size,
                'unused_area_reason': analysis.unused_area_reason,
                'unused_areas': analysis.unused_areas,
                'customer_traffic': analysis.customer_traffic,
                'peak_hours': analysis.peak_hours,
                'customer_movement_paths': analysis.customer_movement_paths,
                'high_traffic_areas': analysis.high_traffic_areas,
                'customer_path_notes': analysis.customer_path_notes,
                'design_style': analysis.design_style,
                'brand_colors': analysis.brand_colors,
                'decorative_elements': analysis.decorative_elements,
                'main_lighting': analysis.main_lighting,
                'has_surveillance': analysis.has_surveillance,
                'camera_count': analysis.camera_count,
                'camera_locations': analysis.camera_locations,
                'camera_coverage': analysis.camera_coverage,
                'has_customer_video': analysis.has_customer_video,
                'video_duration': analysis.video_duration,
                'video_date': analysis.video_date,
                'video_time': analysis.video_time,
                'sales_volume': analysis.sales_volume,
                'top_products': analysis.top_products,
            }
            
            # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± background
            from .tasks import start_real_time_analysis
            start_real_time_analysis.delay(pk, store_data, request.user.id)
            
            return JsonResponse({
                'status': 'success',
                'message': 'ØªØ­Ù„ÛŒÙ„ Ø´Ø±ÙˆØ¹ Ø´Ø¯',
                'redirect_url': reverse('store_analysis:analysis_progress', kwargs={'pk': pk})
            })
            
        except Exception as e:
            return JsonResponse({
                'status': 'error',
                'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„: {str(e)}'
            })
    
    return JsonResponse({
        'status': 'error',
        'message': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'
    })

@login_required
def get_analysis_status(request, pk):
    """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    from .services.real_time_analyzer import RealTimeAnalyzer
    analyzer = RealTimeAnalyzer()
    status = analyzer.get_analysis_status(pk)
    results = analyzer.get_analysis_results(pk)
    
    # Ø§Ú¯Ø± status Ø¯Ø± cache Ù†ÛŒØ³ØªØŒ Ø§Ø² Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if not status:
        if analysis.status == 'completed' or analysis.status == 'preliminary_completed':
            status = {
                'analysis_id': pk,
                'message': 'ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡',
                'progress': 100,
                'timestamp': analysis.updated_at.isoformat()
            }
        elif analysis.status == 'processing':
            status = {
                'analysis_id': pk,
                'message': 'Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´',
                'progress': 50,
                'timestamp': analysis.updated_at.isoformat()
            }
        else:
            status = {
                'analysis_id': pk,
                'message': 'Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø±',
                'progress': 0,
                'timestamp': analysis.created_at.isoformat()
            }
    
    return JsonResponse({
        'status': status,
        'results': results
    })


@login_required
def create_order(request, plan_id):
    """Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´ Ø¬Ø¯ÛŒØ¯"""
    try:
        from .models import PricingPlan
        plan = get_object_or_404(PricingPlan, id=plan_id, is_active=True)
    except ImportError:
        messages.error(request, 'Ù…Ø¯Ù„ Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯')
        return redirect('store_analysis:pricing')
    
    # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù… Ø§Ø² session
    form_data = request.session.get('store_analysis_data', {})
    if not form_data:
        messages.error(request, 'Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:forms')
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´
    order = Order.objects.create(
        user=request.user,
        plan=plan,
        original_amount=Decimal(str(plan.original_price)),
        base_amount=Decimal(str(plan.original_price)),
        discount_amount=Decimal(str(plan.original_price - plan.price)),
        final_amount=Decimal(str(plan.price)),
        status='pending',
        payment_method='online',
        transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
    )
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù… Ø¯Ø± session Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ
    request.session['order_id'] = str(order.order_number)
    request.session['plan_id'] = plan_id
    
    return redirect('store_analysis:checkout', order_id=order.order_number)

@login_required
def checkout(request, order_id):
    """ØµÙØ­Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª"""
    order = get_object_or_404(Order, order_number=order_id, user=request.user)
    
    if request.method == 'POST':
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ØªØµÙ„ Ø´ÙˆÛŒØ¯
        # ÙØ¹Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ ØªØ³ØªØŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø±Ø§ Ù…ÙˆÙÙ‚ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
        order.status = 'paid'
        order.payment_method = 'online'
        order.transaction_id = f"TXN_{uuid.uuid4().hex[:8].upper()}"
        order.save()
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ­Ù„ÛŒÙ„
        form_data = request.session.get('store_analysis_data', {})
        if not form_data:
            # Ø§Ú¯Ø± form_data Ø¯Ø± session Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† StoreAnalysis Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            # StoreAnalysis already imported at top
            latest_analysis = StoreAnalysis.objects.filter(user=request.user).order_by('-created_at').first()
            if latest_analysis and latest_analysis.analysis_data:
                form_data = latest_analysis.analysis_data
        
        # Ø§ÛŒØ¬Ø§Ø¯ AnalysisRequest - Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„
        try:
            analysis_request = AnalysisRequest.objects.create(
                order=order,
                store_analysis_data=form_data or {},
                status='pending',
                estimated_completion=timezone.now() + timedelta(hours=24)
            )
        except (AttributeError, Exception) as e:
            # Ø§Ú¯Ø± AnalysisRequest ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ ÙÙ‚Ø· Ù„Ø§Ú¯ Ú©Ù†
            logger.warning(f"AnalysisRequest model not available: {e}")
            analysis_request = None
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ session
        request.session.pop('store_analysis_data', None)
        request.session.pop('order_id', None)
        request.session.pop('plan_id', None)
        
        messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯! ØªØ­Ù„ÛŒÙ„ Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª.')
        return redirect('store_analysis:analysis_status', analysis_id=analysis_request.id)
    
    context = {
        'order': order,
    }
    return render(request, 'store_analysis/payment_page.html', context)

@login_required
def apply_discount(request):
    """Ø§Ø¹Ù…Ø§Ù„ Ú©Ø¯ ØªØ®ÙÛŒÙ"""
    if request.method == 'POST':
        discount_code = request.POST.get('discount_code', '').strip().upper()
        
        try:
            discount = DiscountCode.objects.get(
                code=discount_code,
                is_active=True,
                valid_from__lte=timezone.now(),
                valid_until__gte=timezone.now()
            )
            
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            if discount.used_count >= discount.max_usage:
                return JsonResponse({
                    'success': False,
                    'message': 'Ú©Ø¯ ØªØ®ÙÛŒÙ Ø¨Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.'
                })
            
            # Ø°Ø®ÛŒØ±Ù‡ Ú©Ø¯ ØªØ®ÙÛŒÙ Ø¯Ø± session
            request.session['discount_code'] = discount_code
            request.session['discount_percentage'] = discount.percentage
            
            return JsonResponse({
                'success': True,
                'message': f'Ú©Ø¯ ØªØ®ÙÛŒÙ {discount.percentage}% Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯!'
            })
            
        except DiscountCode.DoesNotExist:
            return JsonResponse({
                'success': False,
                'message': 'Ú©Ø¯ ØªØ®ÙÛŒÙ Ù†Ø§Ù…Ø¹ØªØ¨Ø± ÛŒØ§ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.'
            })
    
    return JsonResponse({'success': False, 'message': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'})


@login_required
def test_operations(request):
    """ØªØ³Øª Ø¹Ù…Ù„ÛŒØ§Øªâ€ŒÙ‡Ø§"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    return render(request, 'store_analysis/admin/simple_operations_test.html', {'title': 'ØªØ³Øª Ø¹Ù…Ù„ÛŒØ§Øªâ€ŒÙ‡Ø§'})



def generate_initial_analysis(store_data, ai_results=None):
    """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ùˆ Ù†ØªØ§ÛŒØ¬ AI"""
    store_name = store_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§')
    store_type = store_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
    store_size = store_data.get('store_size', 0)
    daily_customers = store_data.get('daily_customers', 0)
    
    if ai_results and ai_results.get('status') == 'completed':
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ØªØ§ÛŒØ¬ AI
        metrics = ai_results.get('metrics', {})
        improvements = ai_results.get('expected_improvements', {})
        overall_score = metrics.get('overall_performance', 70.0)
        
        analysis = f"""
        # ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ {store_name}
        
        ## ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        
        **Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:** {store_type}
        **Ù…ØªØ±Ø§Ú˜:** {store_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
        **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡:** {daily_customers} Ù†ÙØ±
        **Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ:** {overall_score:.1f}/100
        
        ## ğŸ¯ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ AI
        
        ### Ú©Ø§Ø±Ø§ÛŒÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†: {metrics.get('layout_efficiency', 70.0):.1f}%
        ### Ø¬Ø±ÛŒØ§Ù† ØªØ±Ø§ÙÛŒÚ©: {metrics.get('traffic_flow', 70.0):.1f}%
        ### ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ: {metrics.get('customer_experience', 70.0):.1f}%
        ### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ¶Ø§: {metrics.get('space_utilization', 75.0):.1f}%
        
        ## ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§
        
        Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆØ¯:
        - **Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´:** {improvements.get('sales_increase', '15-25%')}
        - **Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ:** {improvements.get('customer_satisfaction', '20-30%')}
        - **Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ:** {improvements.get('efficiency_improvement', '25-35%')}
        - **Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±:** {improvements.get('wait_time_reduction', '30-40%')}
        
        ## ğŸ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
        
        {ai_results.get('analysis_summary', 'ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...')}
        
        ## ğŸ”„ Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ
        
        1. âœ… **ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:** ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡
        2. ğŸ“‹ **Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ:** Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
        3. ğŸ“Š **Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ:** Ø¯Ø± Ø¯Ø³ØªØ±Ø³
        4. ğŸ¯ **Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ:** Ù‚Ø§Ø¨Ù„ Ø§Ø±Ø§Ø¦Ù‡
        
        *Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.*
        """
    else:
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø¯ÙˆÙ† AI
        analysis = f"""
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ {store_name}
        
        ## ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ
        
        **Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:** {store_type}
        **Ù…ØªØ±Ø§Ú˜:** {store_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
        **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡:** {daily_customers} Ù†ÙØ±
        
        ## ğŸ¯ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡
        
        1. **Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ù†Ø§Ø³Ø¨:** ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø´Ù…Ø§ Ø¨Ø§ Ù…ØªØ±Ø§Ú˜ {store_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹ØŒ ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ø¯.
        2. **ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒ:** Ø¨Ø§ {daily_customers} Ù…Ø´ØªØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ ÙØ±ÙˆØ´ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±ÛŒØ¯.
        3. **Ù†ÙˆØ¹ ØªØ®ØµØµÛŒ:** {store_type} Ø¨ÙˆØ¯Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ØŒ Ø§Ù…Ú©Ø§Ù† ØªØ®ØµØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ØªØ± Ø±Ø§ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        
        ## âš ï¸ Ù†Ù‚Ø§Ø· Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯
        
        1. **Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±:** Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±ÛŒÙ….
        2. **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†:** Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ø§ ØªØºÛŒÛŒØ± Ú†ÛŒØ¯Ù…Ø§Ù†ØŒ ÙØ±ÙˆØ´ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯.
        3. **ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ù…Ø´ØªØ±ÛŒØ§Ù†:** Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø±ÛŒÙ….
        
        ## ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        
        Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ØŒ Ø§Ù†ØªØ¸Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆØ¯ Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†:
        - **Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´:** 15-25%
        - **Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±:** 30-40%
        - **Ø§ÙØ²Ø§ÛŒØ´ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ:** 20-30%
        
        ## ğŸ”„ Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ
        
        1. **ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:** Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...
        2. **Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ:** Ø´Ø§Ù…Ù„ Ù†Ù‚Ø´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ
        3. **Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ:** Ø§Ø±Ø§Ø¦Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        
        *Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø³Øª Ùˆ Ù¾Ø³ Ø§Ø² ØªÚ©Ù…ÛŒÙ„ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„â€ŒØªØ±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.*
        """
    
    return analysis

# Admin views
@login_required
@login_required
def admin_pricing_management(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ ØªÙˆØ³Ø· Ø§Ø¯Ù…ÛŒÙ†"""
    try:
        if not request.user.is_staff:
            messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
            return redirect('home')
        
        from django.db.models import Count, Sum, Avg
        from django.utils import timezone
        from datetime import timedelta
        from .models import StoreAnalysis
        
        if request.method == 'POST':
            try:
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§
                simple_price = request.POST.get('simple_price')
                medium_price = request.POST.get('medium_price')
                complex_price = request.POST.get('complex_price')
                opening_discount = request.POST.get('opening_discount')
                seasonal_discount = request.POST.get('seasonal_discount')
                newyear_discount = request.POST.get('newyear_discount')
                
                # Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ù…Ø¯Ù„ Settings Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯)
                # ÙØ¹Ù„Ø§Ù‹ Ø¯Ø± session Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                request.session['pricing_settings'] = {
                    'simple_price': int(simple_price) if simple_price else 200000,
                    'medium_price': int(medium_price) if medium_price else 350000,
                    'complex_price': int(complex_price) if complex_price else 500000,
                    'opening_discount': int(opening_discount) if opening_discount else 80,
                    'seasonal_discount': int(seasonal_discount) if seasonal_discount else 70,
                    'newyear_discount': int(newyear_discount) if newyear_discount else 60,
                }
                
                if request.headers.get('Content-Type') == 'application/json':
                    return JsonResponse({'success': True, 'message': 'ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯'})
                else:
                    messages.success(request, 'ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.')
                    return redirect('store_analysis:admin_pricing')
                    
            except Exception as e:
                if request.headers.get('Content-Type') == 'application/json':
                    return JsonResponse({'success': False, 'error': str(e)})
                else:
                    messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {str(e)}')
                    return redirect('store_analysis:admin_pricing')
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ contact_phone
        from django.db import connection
        with connection.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM store_analysis_storeanalysis")
            total_analyses = cursor.fetchone()[0]
        paid_analyses = Order.objects.filter(status='paid').count()
        pending_analyses = Order.objects.filter(status='pending').count()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±Ø¢Ù…Ø¯
        total_revenue = Order.objects.filter(status='paid').aggregate(
            total=Sum('final_amount')
        )['total'] or 0
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ
        pricing_settings = request.session.get('pricing_settings', {
            'simple_price': 200000,
            'medium_price': 350000,
            'complex_price': 500000,
            'opening_discount': 80,
            'seasonal_discount': 70,
            'newyear_discount': 60,
        })
        
        context = {
            'total_analyses': total_analyses,
            'paid_analyses': paid_analyses,
            'pending_analyses': pending_analyses,
            'total_revenue': float(total_revenue),
            'pricing_settings': pricing_settings,
            'title': 'Ù…Ø¯ÛŒØ±ÛŒØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§'
        }
        
        return render(request, 'store_analysis/admin/pricing_management.html', context)
        
    except Exception as e:
        print(f"âŒ Admin pricing error: {e}")
        return render(request, 'store_analysis/admin/error.html', {
            'error_message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§',
            'error_details': str(e)
        })
def admin_discount_management(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø¯Ù‡Ø§ÛŒ ØªØ®ÙÛŒÙ ØªÙˆØ³Ø· Ø§Ø¯Ù…ÛŒÙ†"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    if request.method == 'POST':
        # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø¯ ØªØ®ÙÛŒÙ Ø¬Ø¯ÛŒØ¯
        code = request.POST.get('code', '').strip().upper()
        discount_percentage = request.POST.get('discount_percentage')
        max_uses = request.POST.get('max_uses', 1)
        valid_until = request.POST.get('valid_until')
        
        if code and discount_percentage:
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ø¯ ØªØ®ÙÛŒÙ
            if DiscountCode.objects.filter(code=code).exists():
                messages.error(request, f'Ú©Ø¯ ØªØ®ÙÛŒÙ "{code}" Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ù„Ø·ÙØ§Ù‹ Ú©Ø¯ Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.')
            else:
                try:
                    DiscountCode.objects.create(
                        code=code,
                        discount_percentage=int(discount_percentage),
                        max_uses=int(max_uses),
                        valid_from=timezone.now(),
                        valid_until=datetime.strptime(valid_until, '%Y-%m-%d'),
                        created_by=request.user
                    )
                    messages.success(request, 'Ú©Ø¯ ØªØ®ÙÛŒÙ Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.')
                except Exception as e:
                    messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø¯ ØªØ®ÙÛŒÙ: {str(e)}')
        else:
            messages.error(request, 'Ù„Ø·ÙØ§Ù‹ ØªÙ…Ø§Ù… ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ø±Ø§ Ù¾Ø± Ú©Ù†ÛŒØ¯.')
    
    discount_codes = DiscountCode.objects.all().order_by('-created_at')
    context = {
        'discount_codes': discount_codes,
    }
    return render(request, 'store_analysis/admin/discount_management.html', context)

@login_required
def store_analysis_result(request):
    """Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
    # Ø§ÛŒÙ† view Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    return render(request, 'store_analysis/analysis_results.html', {})

@login_required
def admin_dashboard(request):
    """Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ø¯Ù…ÛŒÙ† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ - Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
    try:
        if not request.user.is_staff:
            messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
            return redirect('home')
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ… (Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡ Ø¨Ø§ error handling)
        from django.db.models import Count, Sum, Avg, Q
        from django.utils import timezone
        from datetime import timedelta, datetime
        from django.contrib.auth.models import User
        
        # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        try:
            total_users = User.objects.count()
            week_ago = timezone.now() - timedelta(days=7)
            recent_users = User.objects.filter(date_joined__gte=week_ago).count()
        except Exception as e:
            print(f"âš ï¸ User stats error: {e}")
            total_users = 0
            recent_users = 0
        
        # Ø¢Ù…Ø§Ø± Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§
        try:
            from .models import Payment
            total_payments = Payment.objects.count()
            completed_payments = Payment.objects.filter(status='completed').count()
            pending_payments = Payment.objects.filter(status='pending').count()
            processing_payments = Payment.objects.filter(status='processing').count()
            recent_payments = Payment.objects.filter(created_at__gte=week_ago).count()
            
            # Ø¢Ù…Ø§Ø± ÙØ±ÙˆØ´ Ùˆ Ø¯Ø±Ø¢Ù…Ø¯
            total_revenue = Payment.objects.filter(status='completed').aggregate(
                total=Sum('amount')
            )['total'] or 0
        except Exception as e:
            print(f"âš ï¸ Payment stats error: {e}")
            total_payments = 0
            completed_payments = 0
            pending_payments = 0
            processing_payments = 0
            recent_payments = 0
            total_revenue = 0
        
        # Ø¢Ù…Ø§Ø± Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø®Ø¯Ù…Ø§Øª
        try:
            from .models import ServicePackage
            total_packages = ServicePackage.objects.count()
            active_packages = ServicePackage.objects.filter(is_active=True).count()
        except Exception as e:
            print(f"âš ï¸ ServicePackage not available: {e}")
            total_packages = 0
            active_packages = 0
        
        # Ø¢Ù…Ø§Ø± Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§
        try:
            from .models import UserSubscription
            total_subscriptions = UserSubscription.objects.count()
            active_subscriptions = UserSubscription.objects.filter(is_active=True).count()
        except Exception as e:
            print(f"âš ï¸ UserSubscription not available: {e}")
            total_subscriptions = 0
            active_subscriptions = 0
        
        # Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§
        recent_activities = []
        
        # Ø¢Ø®Ø±ÛŒÙ† Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        try:
            recent_users_list = User.objects.order_by('-date_joined')[:3]
            for user in recent_users_list:
                recent_activities.append({
                    'type': 'user',
                    'title': f'Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯: {user.username}',
                    'time': user.date_joined,
                    'icon': 'ğŸ‘¤',
                    'color': '#4CAF50'
                })
        except Exception as e:
            print(f"âš ï¸ Recent users error: {e}")
        
        # Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
        try:
            from .models import StoreAnalysis
            recent_analyses_list = StoreAnalysis.objects.order_by('-created_at')[:3]
            for analysis in recent_analyses_list:
                recent_activities.append({
                    'type': 'analysis',
                    'title': f'ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯: {analysis.store_name}',
                    'time': analysis.created_at,
                    'icon': 'ğŸ“Š',
                    'color': '#2196F3'
                })
        except Exception as e:
            print(f"âš ï¸ StoreAnalysis not available: {e}")
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ¹Ø§Ù„ÛŒØª Ù†Ù…ÙˆÙ†Ù‡
            recent_activities.append({
                'type': 'analysis',
                'title': 'ØªØ­Ù„ÛŒÙ„ Ù†Ù…ÙˆÙ†Ù‡',
                'time': timezone.now(),
                'icon': 'ğŸ“Š',
                'color': '#2196F3'
            })
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†
        recent_activities.sort(key=lambda x: x['time'], reverse=True)
        recent_activities = recent_activities[:6]
        
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± (Ø¢Ø®Ø±ÛŒÙ† 7 Ø±ÙˆØ²)
        chart_data = []
        chart_labels = []
        try:
            for i in range(7):
                date = timezone.now() - timedelta(days=6-i)
                day_start = date.replace(hour=0, minute=0, second=0, microsecond=0)
                day_end = day_start + timedelta(days=1)
                
                day_users = User.objects.filter(date_joined__gte=day_start, date_joined__lt=day_end).count()
                day_payments = Payment.objects.filter(created_at__gte=day_start, created_at__lt=day_end).count() if 'Payment' in locals() else 0
                
                chart_data.append({
                    'date': date.strftime('%Y-%m-%d'),
                    'users': day_users,
                    'payments': day_payments
                })
                chart_labels.append(date.strftime('%m/%d'))
        except Exception as e:
            print(f"âš ï¸ Chart data error: {e}")
            chart_data = []
            chart_labels = []
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ context
        context = {
            'stats': {
                'total_users': total_users,
                'recent_users': recent_users,
                'total_payments': total_payments,
                'completed_payments': completed_payments,
                'pending_payments': pending_payments,
                'processing_payments': processing_payments,
                'recent_payments': recent_payments,
                'total_revenue': total_revenue,
                'total_packages': total_packages,
                'active_packages': active_packages,
                'total_subscriptions': total_subscriptions,
                'active_subscriptions': active_subscriptions,
            },
            'recent_activities': recent_activities,
            'chart_data': chart_data,
            'chart_labels': chart_labels,
            'page_title': 'Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ø¯Ù…ÛŒÙ†',
            'active_tab': 'dashboard'
        }
        
        return render(request, 'store_analysis/admin/admin_dashboard.html', context)
        
    except Exception as e:
        print(f"âŒ Admin dashboard error: {e}")
        # ØµÙØ­Ù‡ Ø®Ø·Ø§ Ø³Ø§Ø¯Ù‡
        return render(request, 'store_analysis/admin/error.html', {
            'error_message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø§Ø¯Ù…ÛŒÙ†',
            'error_details': str(e)
        })


# ==================== ADMIN MANAGEMENT VIEWS ====================

@login_required
def admin_users(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    from django.core.paginator import Paginator
    from django.db.models import Count, Q
    from django.contrib.auth.models import User
    
    # ÙÛŒÙ„ØªØ± Ùˆ Ø¬Ø³ØªØ¬Ùˆ
    search = request.GET.get('search', '')
    status_filter = request.GET.get('status', '')
    
    users = User.objects.all()
    
    if search:
        users = users.filter(
            Q(username__icontains=search) |
            Q(email__icontains=search) |
            Q(first_name__icontains=search) |
            Q(last_name__icontains=search)
        )
    
    if status_filter == 'active':
        users = users.filter(is_active=True)
    elif status_filter == 'inactive':
        users = users.filter(is_active=False)
    elif status_filter == 'staff':
        users = users.filter(is_staff=True)
    
    # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    total_users = User.objects.count()
    active_users = User.objects.filter(is_active=True).count()
    staff_users = User.objects.filter(is_staff=True).count()
    recent_users = User.objects.filter(date_joined__gte=timezone.now() - timedelta(days=7)).count()
    
    # Pagination Ø¨Ø§ ordering
    users = users.order_by('-date_joined')  # Ø±ÙØ¹ UnorderedObjectListWarning
    paginator = Paginator(users, 20)
    page_number = request.GET.get('page')
    users_page = paginator.get_page(page_number)
    
    context = {
        'users': users_page,
        'total_users': total_users,
        'active_users': active_users,
        'staff_users': staff_users,
        'recent_users': recent_users,
        'search': search,
        'status_filter': status_filter,
        'title': 'Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†'
    }
    
    return render(request, 'store_analysis/admin/users.html', context)


@login_required
def admin_user_detail(request, user_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ø±Ø¨Ø±"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    user = get_object_or_404(User, id=user_id)
    
    # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±
    user_analyses = StoreAnalysis.objects.filter(user=user)
    user_orders = Order.objects.filter(user=user)
    user_tickets = SupportTicket.objects.filter(user=user)
    
    # Ø¢Ø®Ø±ÛŒÙ† ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§
    recent_activities = []
    
    # Ø¢Ø®Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
    for analysis in user_analyses.order_by('-created_at')[:5]:
        recent_activities.append({
            'type': 'analysis',
            'title': f'ØªØ­Ù„ÛŒÙ„: {analysis.store_name}',
            'time': analysis.created_at,
            'status': analysis.status
        })
    
    # Ø¢Ø®Ø±ÛŒÙ† Ø³ÙØ§Ø±Ø´Ù‡Ø§
    for order in user_orders.order_by('-created_at')[:5]:
        recent_activities.append({
            'type': 'order',
            'title': f'Ø³ÙØ§Ø±Ø´: {order.order_number}',
            'time': order.created_at,
            'status': order.status
        })
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†
    recent_activities.sort(key=lambda x: x['time'], reverse=True)
    
    context = {
        'user': user,
        'user_analyses': user_analyses,
        'user_orders': user_orders,
        'user_tickets': user_tickets,
        'recent_activities': recent_activities[:10],
        'title': f'Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ø±Ø¨Ø±: {user.username}'
    }
    
    return render(request, 'store_analysis/admin/user_detail.html', context)


@login_required
@login_required
def admin_analyses(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§"""
    try:
        if not request.user.is_staff:
            messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
            return redirect('home')
        
        from django.core.paginator import Paginator
        from django.db.models import Count, Q
        from .models import StoreAnalysis
        
        # ÙÛŒÙ„ØªØ± Ùˆ Ø¬Ø³ØªØ¬Ùˆ
        search = request.GET.get('search', '')
        status_filter = request.GET.get('status', '')
        
        analyses = StoreAnalysis.objects.select_related('user').all()
        
        if search:
            analyses = analyses.filter(
                Q(store_name__icontains=search) |
                Q(user__username__icontains=search)
            )
        
        if status_filter:
            analyses = analyses.filter(status=status_filter)
        
        # Ø¢Ù…Ø§Ø± ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
        total_analyses = StoreAnalysis.objects.count()
        completed_analyses = StoreAnalysis.objects.filter(status='completed').count()
        pending_analyses = StoreAnalysis.objects.filter(status='pending').count()
        processing_analyses = StoreAnalysis.objects.filter(status='processing').count()
        
        # Pagination
        paginator = Paginator(analyses, 20)
        page_number = request.GET.get('page')
        analyses_page = paginator.get_page(page_number)
        
        context = {
            'analyses': analyses_page,
            'total_analyses': total_analyses,
            'completed_analyses': completed_analyses,
            'pending_analyses': pending_analyses,
            'processing_analyses': processing_analyses,
            'search': search,
            'status_filter': status_filter,
            'title': 'Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§',
            'csrf_token': request.META.get('CSRF_COOKIE', '')
        }
        
        return render(request, 'store_analysis/admin/analyses.html', context)
        
    except Exception as e:
        print(f"âŒ Admin analyses error: {e}")
        return render(request, 'store_analysis/admin/error.html', {
            'error_message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§',
            'error_details': str(e)
        })


@login_required
def admin_analysis_detail(request, analysis_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª ØªØ­Ù„ÛŒÙ„"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    try:
        # Try to get analysis by UUID first
        analysis = get_object_or_404(StoreAnalysis, id=analysis_id)
    except ValueError:
        # If UUID parsing fails, try to get by string
        try:
            analysis = get_object_or_404(StoreAnalysis, id=str(analysis_id))
        except:
            messages.error(request, 'ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯')
            return redirect('store_analysis:admin_analyses')
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø· - Ø¨Ø§ try-except Ø¨Ø±Ø§ÛŒ Ù…Ø´Ú©Ù„Ø§Øª migration
    try:
        store_basic_info = StoreBasicInfo.objects.filter(user=analysis.user).first()
    except Exception as e:
        logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª StoreBasicInfo: {e}")
        store_basic_info = None
    
    try:
        analysis_result = StoreAnalysisResult.objects.filter(store_analysis=analysis).first()
    except Exception as e:
        logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª StoreAnalysisResult: {e}")
        analysis_result = None
    
    context = {
        'analysis': analysis,
        'store_basic_info': store_basic_info,
        'analysis_result': analysis_result,
        'title': f'Ø¬Ø²Ø¦ÛŒØ§Øª ØªØ­Ù„ÛŒÙ„: {analysis.store_name}'
    }
    
    return render(request, 'store_analysis/admin/analysis_detail.html', context)


@login_required
def admin_delete_analysis(request, analysis_id):
    """Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    if request.method == 'POST':
        try:
            # Try to get analysis by UUID first
            analysis = get_object_or_404(StoreAnalysis, id=analysis_id)
        except ValueError:
            # If UUID parsing fails, try to get by string
            try:
                analysis = get_object_or_404(StoreAnalysis, id=str(analysis_id))
            except:
                messages.error(request, 'ØªØ­Ù„ÛŒÙ„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯')
                return redirect('store_analysis:admin_analyses')
        
        store_name = analysis.store_name
        analysis.delete()
        messages.success(request, f'ØªØ­Ù„ÛŒÙ„ "{store_name}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯')
        
        return JsonResponse({'success': True, 'message': f'ØªØ­Ù„ÛŒÙ„ "{store_name}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯'})
    
    return JsonResponse({'success': False, 'message': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'})


@login_required
def test_operations(request):
    """ØªØ³Øª Ø¹Ù…Ù„ÛŒØ§Øªâ€ŒÙ‡Ø§"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    return render(request, 'store_analysis/admin/simple_operations_test.html', {'title': 'ØªØ³Øª Ø¹Ù…Ù„ÛŒØ§Øªâ€ŒÙ‡Ø§'})
@login_required
def admin_orders(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø³ÙØ§Ø±Ø´Ø§Øª"""
    try:
        if not request.user.is_staff:
            messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
            return redirect('home')
        
        from django.core.paginator import Paginator
        from django.db.models import Count, Q, Sum
        from .models import StoreAnalysis
        
        # ÙÛŒÙ„ØªØ± Ùˆ Ø¬Ø³ØªØ¬Ùˆ
        search = request.GET.get('search', '')
        status_filter = request.GET.get('status', '')
        
        orders = Order.objects.select_related('user').all().order_by('-created_at')
        
        if search:
            orders = orders.filter(
                Q(order_id__icontains=search) |
                Q(user__username__icontains=search)
            )
        
        if status_filter:
            orders = orders.filter(status=status_filter)
        
        # Ø¢Ù…Ø§Ø± Ø³ÙØ§Ø±Ø´Ø§Øª
        total_orders = Order.objects.count()
        paid_orders = Order.objects.filter(status='paid').count()
        pending_orders = Order.objects.filter(status='pending').count()
        total_revenue = Order.objects.filter(status='paid').aggregate(
            total=Sum('final_amount')
        )['total'] or 0
        
        # Pagination
        paginator = Paginator(orders, 20)
        page_number = request.GET.get('page')
        orders_page = paginator.get_page(page_number)
        
        context = {
            'orders': orders_page,
            'total_orders': total_orders,
            'paid_orders': paid_orders,
            'pending_orders': pending_orders,
            'total_revenue': float(total_revenue),
            'search': search,
            'status_filter': status_filter,
            'title': 'Ù…Ø¯ÛŒØ±ÛŒØª Ø³ÙØ§Ø±Ø´Ø§Øª'
        }
        
        return render(request, 'store_analysis/admin/orders.html', context)
        
    except Exception as e:
        print(f"âŒ Admin orders error: {e}")
        return render(request, 'store_analysis/admin/error.html', {
            'error_message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø³ÙØ§Ø±Ø´Ø§Øª',
            'error_details': str(e)
        })


@login_required
def admin_order_detail(request, order_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª Ø³ÙØ§Ø±Ø´"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    order = get_object_or_404(Order, order_id=order_id)
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·
    analysis = StoreAnalysis.objects.filter(order=order).first()
    payments = Payment.objects.filter(order=order)
    
    context = {
        'order': order,
        'analysis': analysis,
        'payments': payments,
        'title': f'Ø¬Ø²Ø¦ÛŒØ§Øª Ø³ÙØ§Ø±Ø´: {order.order_number}'
    }
    
    return render(request, 'store_analysis/admin/order_detail.html', context)


@login_required
def admin_tickets(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    from django.core.paginator import Paginator
    from django.db.models import Count, Q
    
    # ÙÛŒÙ„ØªØ± Ùˆ Ø¬Ø³ØªØ¬Ùˆ
    search = request.GET.get('search', '')
    status_filter = request.GET.get('status', '')
    priority_filter = request.GET.get('priority', '')
    
    tickets = SupportTicket.objects.select_related('user').all()
    
    if search:
        tickets = tickets.filter(
            Q(subject__icontains=search) |
            Q(user__username__icontains=search)
        )
    
    if status_filter:
        tickets = tickets.filter(status=status_filter)
    
    if priority_filter:
        tickets = tickets.filter(priority=priority_filter)
    
    # Ø¢Ù…Ø§Ø± ØªÛŒÚ©Øªâ€ŒÙ‡Ø§
    total_tickets = SupportTicket.objects.count()
    open_tickets = SupportTicket.objects.filter(status='open').count()
    closed_tickets = SupportTicket.objects.filter(status='closed').count()
    high_priority = SupportTicket.objects.filter(priority='high').count()
    
    # Pagination
    paginator = Paginator(tickets, 20)
    page_number = request.GET.get('page')
    tickets_page = paginator.get_page(page_number)
    
    context = {
        'tickets': tickets_page,
        'total_tickets': total_tickets,
        'open_tickets': open_tickets,
        'closed_tickets': closed_tickets,
        'high_priority': high_priority,
        'search': search,
        'status_filter': status_filter,
        'priority_filter': priority_filter,
        'title': 'Ù…Ø¯ÛŒØ±ÛŒØª ØªÛŒÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ'
    }
    
    return render(request, 'store_analysis/admin/tickets.html', context)


@login_required
def admin_ticket_detail(request, ticket_id):
    """Ø¬Ø²Ø¦ÛŒØ§Øª ØªÛŒÚ©Øª"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    ticket = get_object_or_404(SupportTicket, ticket_id=ticket_id)
    ticket_messages = TicketMessage.objects.filter(ticket=ticket).order_by('created_at')
    
    if request.method == 'POST':
        action = request.POST.get('action')
        if action == 'reply':
            message_text = request.POST.get('message')
            if message_text:
                TicketMessage.objects.create(
                    ticket=ticket,
                    sender=request.user,
                    content=message_text,
                    message_type='admin' if request.user.is_staff else 'user',
                    is_internal=False  # Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø§Ø³Øª
                )
                messages.success(request, 'Ù¾Ø§Ø³Ø® Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯')
        elif action == 'close':
            ticket.status = 'closed'
            ticket.save()
            messages.success(request, 'ØªÛŒÚ©Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯')
        elif action == 'reopen':
            ticket.status = 'open'
            ticket.save()
            messages.success(request, 'ØªÛŒÚ©Øª Ø¨Ø§Ø² Ø´Ø¯')
        
        return redirect('store_analysis:admin_ticket_detail', ticket_id=ticket_id)
    
    context = {
        'ticket': ticket,
        'ticket_messages': ticket_messages,
        'title': f'ØªÛŒÚ©Øª: {ticket.subject}'
    }
    
    return render(request, 'store_analysis/admin/ticket_detail.html', context)


# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡


@login_required
def admin_discounts(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª ØªØ®ÙÛŒÙâ€ŒÙ‡Ø§"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    from django.core.paginator import Paginator
    
    discounts = DiscountCode.objects.all().order_by('-created_at')
    
    if request.method == 'POST':
        action = request.POST.get('action')
        
        if action == 'create':
            code = request.POST.get('code')
            discount_type = request.POST.get('discount_type')
            discount_value = request.POST.get('discount_value')
            max_uses = request.POST.get('max_uses')
            expires_at = request.POST.get('expires_at')
            
            try:
                DiscountCode.objects.create(
                    code=code,
                    discount_type=discount_type,
                    discount_value=float(discount_value),
                    max_uses=int(max_uses) if max_uses else None,
                    expires_at=expires_at if expires_at else None,
                    is_active=True
                )
                messages.success(request, 'Ú©Ø¯ ØªØ®ÙÛŒÙ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯')
            except Exception as e:
                messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø¯ ØªØ®ÙÛŒÙ: {str(e)}')
        
        elif action == 'toggle':
            discount_id = request.POST.get('discount_id')
            discount = get_object_or_404(DiscountCode, id=discount_id)
            discount.is_active = not discount.is_active
            discount.save()
            messages.success(request, 'ÙˆØ¶Ø¹ÛŒØª Ú©Ø¯ ØªØ®ÙÛŒÙ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯')
        
        return redirect('store_analysis:admin_discounts')
    
    # Pagination
    paginator = Paginator(discounts, 20)
    page_number = request.GET.get('page')
    discounts_page = paginator.get_page(page_number)
    
    context = {
        'discounts': discounts_page,
        'title': 'Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø¯Ù‡Ø§ÛŒ ØªØ®ÙÛŒÙ'
    }
    
    return render(request, 'store_analysis/admin/discounts.html', context)


@login_required
def admin_settings(request):
    """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… - Ø¨Ø§ Django Cache"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    from django.core.cache import cache
    
    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    default_settings = {
        'site_name': 'Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ',
        'site_description': 'Ù¾Ù„ØªÙØ±Ù… Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§',
        'support_email': 'info@chidmano.ir',
        'contact_phone': '0920-2658678',
        'address': 'Ø§Ù„Ø¨Ø±Ø²ØŒ Ú©Ø±Ø¬ØŒ Ù…ÛŒØ¯Ø§Ù† Ù…ÙˆØ¯Ø¨',
        'smtp_server': 'smtp.gmail.com',
        'smtp_port': '587',
        'sender_email': 'noreply@chidmano.ir',
        'max_concurrent_analyses': '5',
        'analysis_timeout': '300',
        'max_login_attempts': '5',
        'account_lockout_time': '15',
        'session_timeout': '24',
        'min_payment_amount': '10000',
        'max_payment_amount': '10000000'
    }
    
    try:
        if request.method == 'POST':
            # Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ±Ù…
            current_settings = {
                'site_name': request.POST.get('site_name', default_settings['site_name']),
                'site_description': request.POST.get('site_description', default_settings['site_description']),
                'support_email': request.POST.get('support_email', default_settings['support_email']),
                'contact_phone': request.POST.get('contact_phone', default_settings['contact_phone']),
                'address': request.POST.get('address', default_settings['address']),
                'smtp_server': request.POST.get('smtp_server', default_settings['smtp_server']),
                'smtp_port': request.POST.get('smtp_port', default_settings['smtp_port']),
                'sender_email': request.POST.get('sender_email', default_settings['sender_email']),
                'max_concurrent_analyses': request.POST.get('max_concurrent_analyses', default_settings['max_concurrent_analyses']),
                'analysis_timeout': request.POST.get('analysis_timeout', default_settings['analysis_timeout']),
                'max_login_attempts': request.POST.get('max_login_attempts', default_settings['max_login_attempts']),
                'account_lockout_time': request.POST.get('account_lockout_time', default_settings['account_lockout_time']),
                'session_timeout': request.POST.get('session_timeout', default_settings['session_timeout']),
                'min_payment_amount': request.POST.get('min_payment_amount', default_settings['min_payment_amount']),
                'max_payment_amount': request.POST.get('max_payment_amount', default_settings['max_payment_amount'])
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache (Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø²Ù…Ø§Ù†ÛŒ)
            try:
                cache.set('admin_settings', current_settings, timeout=None)
                logger.info(f"âœ… Admin settings saved to cache by {request.user.username}")
                logger.info(f"ğŸ“‹ Settings: {current_settings}")
                messages.success(request, 'ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯')
            except Exception as e:
                logger.error(f"âŒ Error saving settings to cache: {e}")
                messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {str(e)}')
            
            return redirect('store_analysis:admin_settings')
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ¹Ù„ÛŒ Ø§Ø² cache
        current_settings = cache.get('admin_settings', default_settings.copy())
        
        # Ø§Ú¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø± cache Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if current_settings is None:
            current_settings = default_settings.copy()
            logger.info("âš ï¸ No settings in cache, using defaults")
        else:
            logger.info(f"âœ… Settings loaded from cache: {current_settings}")
        
        context = {
            'title': 'ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…',
            'settings': current_settings
        }
        
        return render(request, 'store_analysis/admin/settings.html', context)
        
    except Exception as e:
        logger.error(f"âŒ Error in admin_settings view: {e}", exc_info=True)
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {str(e)}')
        return redirect('store_analysis:admin_dashboard')


@login_required
def admin_analytics(request):
    """Ø¢Ù…Ø§Ø± Ø¨Ø§Ø²Ø¯ÛŒØ¯Ú©Ù†Ù†Ø¯Ú¯Ø§Ù† Ø³Ø§ÛŒØª"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    try:
        from django.db import models
        
        # Ø¢Ù…Ø§Ø± Ø§Ù…Ø±ÙˆØ²
        today = timezone.now().date()
        try:
            today_stats = SiteStats.objects.filter(date=today).first()
        except Exception as e:
            print(f"âš ï¸ SiteStats not available: {e}")
            today_stats = None
        
        # Ø¢Ù…Ø§Ø± Ù‡ÙØªÙ‡ Ú¯Ø°Ø´ØªÙ‡
        from datetime import timedelta
        week_ago = today - timedelta(days=7)
        try:
            from django.db.models import Sum
            week_stats = SiteStats.objects.filter(date__gte=week_ago).aggregate(
                total_views=Sum('total_views'),
                unique_visitors=Sum('unique_visitors'),
                new_users=Sum('new_users'),
                page_views=Sum('page_views')
            )
        except Exception as e:
            print(f"âš ï¸ Week stats not available: {e}")
            week_stats = {'total_views': 0, 'unique_visitors': 0, 'new_users': 0, 'page_views': 0}
        
        # Ø¢Ù…Ø§Ø± Ù…Ø§Ù‡ Ú¯Ø°Ø´ØªÙ‡
        month_ago = today - timedelta(days=30)
        try:
            month_stats = SiteStats.objects.filter(date__gte=month_ago).aggregate(
                total_views=Sum('total_views'),
                unique_visitors=Sum('unique_visitors'),
                new_users=Sum('new_users'),
                page_views=Sum('page_views')
            )
        except Exception as e:
            print(f"âš ï¸ Month stats not available: {e}")
            month_stats = {'total_views': 0, 'unique_visitors': 0, 'new_users': 0, 'page_views': 0}
        
        # Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† ØµÙØ­Ø§Øª
        try:
            from django.db.models import Count
            popular_pages = PageView.objects.values('page_url', 'page_title').annotate(
                view_count=Count('id')
            ).order_by('-view_count')[:10]
        except Exception as e:
            print(f"âš ï¸ Popular pages not available: {e}")
            popular_pages = []
        
        # Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡ 7 Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡
        try:
            daily_stats = SiteStats.objects.filter(
                date__gte=week_ago
            ).order_by('date')
        except Exception as e:
            print(f"âš ï¸ Daily stats not available: {e}")
            daily_stats = []
        
        # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¢Ù†Ù„Ø§ÛŒÙ† (Ø¢Ø®Ø±ÛŒÙ† 15 Ø¯Ù‚ÛŒÙ‚Ù‡)
        try:
            online_threshold = timezone.now() - timedelta(minutes=15)
            online_users = PageView.objects.filter(
                created_at__gte=online_threshold
            ).values('session_id').distinct().count()
        except Exception as e:
            print(f"âš ï¸ Online users not available: {e}")
            online_users = 0
        
        context = {
            'title': 'Ø¢Ù…Ø§Ø± Ø¨Ø§Ø²Ø¯ÛŒØ¯Ú©Ù†Ù†Ø¯Ú¯Ø§Ù†',
            'today_stats': today_stats,
            'week_stats': week_stats,
            'month_stats': month_stats,
            'popular_pages': popular_pages,
            'daily_stats': daily_stats,
            'online_users': online_users,
        }
        
        return render(request, 'store_analysis/admin/analytics.html', context)
        
    except Exception as e:
        print(f"âš ï¸ Analytics error: {e}")
        messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ù…Ø§Ø±: {str(e)}')
        return redirect('store_analysis:admin_dashboard')


@login_required
def admin_reports(request):
    """Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    from django.db.models import Count, Sum, Avg
    from datetime import datetime, timedelta
    
    # Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
    report_type = request.GET.get('type', 'overview')
    
    if report_type == 'users':
        # Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
        users_data = User.objects.extra(
            select={'month': 'strftime("%%Y-%%m", date_joined)'}
        ).values('month').annotate(count=Count('id')).order_by('month')
        
        context = {
            'report_type': 'users',
            'data': list(users_data),
            'title': 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†'
        }
    
    elif report_type == 'analyses':
        # Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
        analyses_data = StoreAnalysis.objects.extra(
            select={'month': 'strftime("%%Y-%%m", created_at)'}
        ).values('month').annotate(count=Count('id')).order_by('month')
        
        context = {
            'report_type': 'analyses',
            'data': list(analyses_data),
            'title': 'Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§'
        }
    
    elif report_type == 'revenue':
        # Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø±Ø¢Ù…Ø¯
        revenue_data = Order.objects.filter(status='paid').extra(
            select={'month': 'strftime("%%Y-%%m", created_at)'}
        ).values('month').annotate(total=Sum('final_amount')).order_by('month')
        
        context = {
            'report_type': 'revenue',
            'data': list(revenue_data),
            'title': 'Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø±Ø¢Ù…Ø¯'
        }
    
    else:
        # Ú¯Ø²Ø§Ø±Ø´ Ú©Ù„ÛŒ
        context = {
            'report_type': 'overview',
            'title': 'Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ'
        }
    
    return render(request, 'store_analysis/admin/reports.html', context)
# ==================== END ADMIN MANAGEMENT VIEWS ====================
@login_required
def admin_promotional_banner_management(request):
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù†Ø±Ù‡Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§ØªÛŒ"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    if request.method == 'POST':
        action = request.POST.get('action')
        
        if action == 'create':
            try:
                from .models import PromotionalBanner
                banner = PromotionalBanner.objects.create(
                    title=request.POST.get('title'),
                    subtitle=request.POST.get('subtitle'),
                    discount_percentage=int(request.POST.get('discount_percentage')),
                    discount_text=request.POST.get('discount_text', 'ØªØ®ÙÛŒÙ'),
                    background_color=request.POST.get('background_color'),
                    text_color=request.POST.get('text_color'),
                    is_active=request.POST.get('is_active') == 'on',
                    start_date=timezone.now(),
                    end_date=timezone.now() + timedelta(days=30)
                )
                messages.success(request, f'Ø¨Ù†Ø± ØªØ¨Ù„ÛŒØºØ§ØªÛŒ "{banner.title}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯')
            except Exception as e:
                messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¨Ù†Ø±: {str(e)}')
        
        elif action == 'update':
            try:
                from .models import PromotionalBanner
                banner_id = request.POST.get('banner_id')
                banner = PromotionalBanner.objects.get(id=banner_id)
                banner.title = request.POST.get('title')
                banner.subtitle = request.POST.get('subtitle')
                banner.discount_percentage = int(request.POST.get('discount_percentage'))
                banner.discount_text = request.POST.get('discount_text', 'ØªØ®ÙÛŒÙ')
                banner.background_color = request.POST.get('background_color')
                banner.text_color = request.POST.get('text_color')
                banner.is_active = request.POST.get('is_active') == 'on'
                banner.save()
                messages.success(request, f'Ø¨Ù†Ø± ØªØ¨Ù„ÛŒØºØ§ØªÛŒ "{banner.title}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯')
            except Exception as e:
                messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¨Ù†Ø±: {str(e)}')
        
        elif action == 'delete':
            try:
                from .models import PromotionalBanner
                banner_id = request.POST.get('banner_id')
                banner = PromotionalBanner.objects.get(id=banner_id)
                banner.delete()
                messages.success(request, 'Ø¨Ù†Ø± ØªØ¨Ù„ÛŒØºØ§ØªÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯')
            except Exception as e:
                messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù Ø¨Ù†Ø±: {str(e)}')
        
        return redirect('store_analysis:admin_promotional_banner_management')
    
    try:
        from .models import PromotionalBanner
        banners = PromotionalBanner.objects.all().order_by('-created_at')
    except ImportError:
        banners = []
    
    context = {
        'banners': banners,
        'page_title': 'Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù†Ø±Ù‡Ø§ÛŒ ØªØ¨Ù„ÛŒØºØ§ØªÛŒ'
    }
    return render(request, 'store_analysis/admin/promotional_banner_management.html', context)




def analysis_results_session(request):
    """Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø§Ø² session"""
    complete_data = request.session.get('complete_data', {})
    if not complete_data:
        messages.error(request, 'Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯!')
        return redirect('store_analysis:step1_basic_info')
    
    return render(request, 'store_analysis/analysis_results_enhanced.html', {'data': complete_data})

# analysis_detail view Ø­Ø°Ù Ø´Ø¯ - Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬ Ù…Ø¯Ø±Ù† Ù‡Ø¯Ø§ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯

@login_required
def delete_analysis(request, pk):
    """Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§"""
    try:
        analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
        
        if request.method == 'POST':
            try:
                from django.db import transaction
                
                # Ø­Ø°Ù ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„
                # Ù‡Ø± Ú©Ø¯Ø§Ù… Ø±Ø§ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ try-except Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø§Ú¯Ø± ÛŒÚ©ÛŒ Ø®Ø·Ø§ Ø¯Ø§Ø¯ØŒ Ø¨Ù‚ÛŒÙ‡ Ø§Ø¯Ø§Ù…Ù‡ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù†Ø¯
                
                # 1. Ø­Ø°Ù Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú†Øª Ù…Ø±ØªØ¨Ø· (Ø§Ø² Ø·Ø±ÛŒÙ‚ session)
                try:
                    from .models import ChatMessage, ChatSession
                    chat_sessions = ChatSession.objects.filter(store_analysis=analysis)
                    for session in chat_sessions:
                        ChatMessage.objects.filter(session=session).delete()
                    logger.info(f"âœ… ChatMessages deleted for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting chat messages: {e}")
                
                # 2. Ø­Ø°Ù sessionâ€ŒÙ‡Ø§ÛŒ Ú†Øª Ù…Ø±ØªØ¨Ø·
                try:
                    from .models import ChatSession
                    ChatSession.objects.filter(store_analysis=analysis).delete()
                    logger.info(f"âœ… ChatSessions deleted for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting chat sessions: {e}")
                
                # 3. Ø­Ø°Ù AnalysisRequest Ù…Ø±ØªØ¨Ø· (Ø§Ú¯Ø± ÙÛŒÙ„Ø¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
                try:
                    from .models import AnalysisRequest
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ ÙÛŒÙ„Ø¯
                    from django.db import connection
                    with connection.cursor() as cursor:
                        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ùˆ Ø³ØªÙˆÙ†
                        cursor.execute("""
                            SELECT column_name 
                            FROM information_schema.columns 
                            WHERE table_name='store_analysis_analysisrequest' 
                            AND column_name='store_analysis_id'
                        """)
                        if cursor.fetchone():
                            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² raw SQL Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¨Ù‡ Ø¬Ø§ÛŒ ORM
                            cursor.execute("""
                                DELETE FROM store_analysis_analysisrequest 
                                WHERE store_analysis_id = %s
                            """, [analysis.id])
                            logger.info(f"âœ… AnalysisRequests deleted for analysis {pk}")
                        else:
                            logger.debug(f"âš ï¸ store_analysis_id column does not exist in AnalysisRequest table")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting analysis requests: {e}")
                
                # 4. Ø­Ø°Ù StoreAnalysisResult Ù…Ø±ØªØ¨Ø·
                try:
                    from .models import StoreAnalysisResult
                    StoreAnalysisResult.objects.filter(store_analysis=analysis).delete()
                    logger.info(f"âœ… StoreAnalysisResults deleted for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting analysis results: {e}")
                
                # 5. Ø­Ø°Ù ReviewReminder Ù…Ø±ØªØ¨Ø·
                try:
                    from .models import ReviewReminder
                    ReviewReminder.objects.filter(analysis=analysis).delete()
                    logger.info(f"âœ… ReviewReminders deleted for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting review reminders: {e}")
                
                # 6. SupportTicket ÙÛŒÙ„Ø¯ store_analysis Ù†Ø¯Ø§Ø±Ø¯ - skip
                # (SupportTicket ÙÙ‚Ø· user Ø¯Ø§Ø±Ø¯ØŒ Ù†Ù‡ store_analysis)
                
                # 7. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· (store_analysis Ø±Ø§ null Ú©Ù†)
                try:
                    from .models import Payment
                    Payment.objects.filter(store_analysis=analysis).update(store_analysis=None)
                    logger.info(f"âœ… Payments updated for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error updating payments: {e}")
                
                # 8. Ø­Ø°Ù Order Ù…Ø±ØªØ¨Ø· (Ø§Ú¯Ø± OneToOne Ø¨Ø§Ø´Ø¯)
                try:
                    if hasattr(analysis, 'order') and analysis.order:
                        analysis.order.delete()
                        logger.info(f"âœ… Order deleted for analysis {pk}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error deleting order: {e}")
                
                # 9. Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„ (Ø¨Ø§ÛŒØ¯ Ø¢Ø®Ø± Ø§Ø² Ù‡Ù…Ù‡ Ø¨Ø§Ø´Ø¯)
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² _raw_delete Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ§Ø¨Ø· Django
                try:
                    from django.db import connection
                    with connection.cursor() as cursor:
                        cursor.execute("""
                            DELETE FROM store_analysis_storeanalysis 
                            WHERE id = %s
                        """, [analysis.id])
                    logger.info(f"âœ… StoreAnalysis {pk} deleted successfully using raw SQL")
                except Exception as e:
                    # Ø§Ú¯Ø± raw SQL Ø®Ø·Ø§ Ø¯Ø§Ø¯ØŒ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ø§ ORM Ø­Ø°Ù Ú©Ù†ÛŒÙ…
                    try:
                        analysis.delete()
                        logger.info(f"âœ… StoreAnalysis {pk} deleted successfully using ORM")
                    except Exception as orm_error:
                        logger.error(f"âŒ Error deleting analysis with ORM: {orm_error}")
                        raise
                
                messages.success(request, 'âœ… ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯.')
                logger.info(f"âœ… Analysis {pk} deleted by user {request.user.username}")
                
            except Exception as e:
                logger.error(f"âŒ Error deleting analysis {pk}: {e}", exc_info=True)
                messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„: {str(e)}')
            
            return redirect('store_analysis:user_dashboard')
        
        return render(request, 'store_analysis/delete_analysis_confirm.html', {'analysis': analysis})
    
    except Exception as e:
        logger.error(f"âŒ Error in delete_analysis view: {e}", exc_info=True)
        messages.error(request, 'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù ØªØ­Ù„ÛŒÙ„')
        return redirect('store_analysis:user_dashboard')

@login_required
def analysis_payment_page(request, pk):
    """ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„"""
    analysis = get_object_or_404(StoreAnalysis, pk=pk, user=request.user)
    
    # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ØŒ Ø¨Ù‡ ØµÙØ­Ù‡ ØªØ­Ù„ÛŒÙ„ Ù‡Ø¯Ø§ÛŒØª Ø´ÙˆØ¯
    if analysis.status != 'pending':
        messages.info(request, 'Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ Ø§Ø³Øª.')
        return redirect('store_analysis:forms')
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØ­Ù„ÛŒÙ„
    cost = calculate_analysis_cost(analysis.analysis_data or {})
    
    # Ø§ÛŒØ¬Ø§Ø¯ Order Ø¬Ø¯ÛŒØ¯
    order = Order.objects.create(
        user=request.user,
        original_amount=Decimal(str(cost['total'])),
        base_amount=Decimal(str(cost['total'])),
        discount_amount=Decimal(str(cost.get('discount', 0))),
        final_amount=Decimal(str(cost['final'])),
        status='pending',
        transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
    )
    
    context = {
        'analysis': analysis,
        'order': order,
        'cost': cost,
    }
    
    return render(request, 'store_analysis/payment_page.html', context)

def forms(request):
    """ÙØ±Ù… ØªÚ© ØµÙØ­Ù‡â€ŒØ§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"""
    if request.method == 'POST':
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ±Ù…
            form_data = request.POST.dict()
            files = request.FILES
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ø§Ù… Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ù‡ HEX
            color_fields = ['primary_brand_color', 'secondary_brand_color', 'accent_brand_color']
            for field in color_fields:
                if field in form_data and form_data[field]:
                    form_data[field] = color_name_to_hex(form_data[field])
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡
            cost_breakdown = calculate_analysis_cost(form_data)
            
            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„
            store_analysis = StoreAnalysis.objects.create(
                user=request.user if request.user.is_authenticated else None,
                store_name=form_data.get('store_name', ''),
                status='pending',
                analysis_data=form_data
            )
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´
            order = Order.objects.create(
                user=request.user if request.user.is_authenticated else None,
                plan=None,
            original_amount=Decimal(str(cost_breakdown['total'])),
            base_amount=Decimal(str(cost_breakdown['total'])),
            discount_amount=Decimal(str(cost_breakdown.get('discount', 0))),
            final_amount=Decimal(str(cost_breakdown['final'])),
                status='pending',
                payment_method='online',
                transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
            )
            
            # Ø§ØªØµØ§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ø³ÙØ§Ø±Ø´
            store_analysis.order = order
            store_analysis.save()
            
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª
            messages.success(request, 'ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯!')
            return redirect('store_analysis:payment_page', order_id=order.order_number)
            
        except Exception as e:
            messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÙØ±Ù…: {str(e)}')
            return render(request, 'store_analysis/forms.html')
    
    return render(request, 'store_analysis/forms.html')


def _convert_store_size_to_int(store_size):
    """ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² Ø±Ø´ØªÙ‡ Ø¨Ù‡ Ø¹Ø¯Ø¯"""
    size_mapping = {
        'small': 50,
        'medium': 125,
        'large': 350,
        'xlarge': 750
    }
    return size_mapping.get(store_size, 125)  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Ù…ØªÙˆØ³Ø·

def generate_detailed_analysis_for_dashboard(analysis_data):
    """ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯"""
    store_name = analysis_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
    store_type = analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
    store_size = analysis_data.get('store_size', 'medium')
    city = analysis_data.get('city', 'ØªÙ‡Ø±Ø§Ù†')
    area = analysis_data.get('area', 'ÙˆÙ†Ú©')
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±Ø§Ú˜
    size_mapping = {'small': 50, 'medium': 125, 'large': 350, 'xlarge': 750}
    actual_size = size_mapping.get(store_size, 125)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ±ÙˆØ´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡
    daily_customers = int(analysis_data.get('daily_customers', 150))
    daily_sales = float(analysis_data.get('daily_sales', 5000000))
    
    # ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„
    detailed_analysis = f"""
# ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ {store_name}

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ {area} {city} Ø¨Ø§ Ù…Ø³Ø§Ø­Øª {actual_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹ØŒ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø´Ø¯ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø§Ø±Ø¯. ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙØ±ÙˆØ´ Ø±Ø§ ØªØ§ 35% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯.

## ğŸ“ˆ ØªØ­Ù„ÛŒÙ„ SWOT

### âœ… Ù†Ù‚Ø§Ø· Ù‚ÙˆØª (Strengths)
- Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø¹Ø§Ù„ÛŒ Ø¯Ø± {area}
- Ù…Ø³Ø§Ø­Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª ({actual_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹)
- Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯
- ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§

### âš ï¸ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù (Weaknesses)
- Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ø¯
- Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª
- Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯
- Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯

### ğŸš€ ÙØ±ØµØªâ€ŒÙ‡Ø§ (Opportunities)
- Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ {store_type}
- ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡ {area}
- Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†
- ÙØµÙˆÙ„ Ø®Ø±ÛŒØ¯ (Ø¹ÛŒØ¯ØŒ ØªØ§Ø¨Ø³ØªØ§Ù†)

### âš¡ ØªÙ‡Ø¯ÛŒØ¯Ø§Øª (Threats)
- Ø±Ù‚Ø§Ø¨Øª Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
- ØªØºÛŒÛŒØ±Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ
- ØªØºÛŒÛŒØ± Ø³Ù„ÛŒÙ‚Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù†
- Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ

## ğŸ‘¥ ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†

### ğŸ“Š Ø§Ù„Ú¯ÙˆÛŒ ØªØ±Ø§ÙÛŒÚ© ÙØ¹Ù„ÛŒ
- **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_customers} Ù†ÙØ±
- **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_sales:,.0f} ØªÙˆÙ…Ø§Ù†
- **Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±**: 15 Ø¯Ù‚ÛŒÙ‚Ù‡
- **Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„**: 25% ({daily_customers//4} ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡)

### ğŸ¯ Ø§Ù„Ú¯ÙˆÛŒ ØªØ±Ø§ÙÛŒÚ© Ø¨Ù‡ÛŒÙ†Ù‡ (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ)
- **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡**: {int(daily_customers * 1.33)} Ù†ÙØ± (+33%)
- **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_sales * 1.35:,.0f} ØªÙˆÙ…Ø§Ù† (+35%)
- **Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±**: 20 Ø¯Ù‚ÛŒÙ‚Ù‡
- **Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„**: 35% ({int(daily_customers * 1.33 * 0.35)} ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡)

## ğŸ’° ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI

### ğŸ“ˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ø±Ø¢Ù…Ø¯

#### ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ
- **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_sales:,.0f} ØªÙˆÙ…Ø§Ù†
- **ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡**: {daily_sales * 30:,.0f} ØªÙˆÙ…Ø§Ù†
- **ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡**: {daily_sales * 365:,.0f} ØªÙˆÙ…Ø§Ù†

#### ÙˆØ¶Ø¹ÛŒØª Ø¨Ù‡ÛŒÙ†Ù‡ (Ù¾Ø³ Ø§Ø² Ø¨Ù‡Ø¨ÙˆØ¯)
- **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_sales * 1.35:,.0f} ØªÙˆÙ…Ø§Ù†
- **ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡**: {daily_sales * 1.35 * 30:,.0f} ØªÙˆÙ…Ø§Ù†
- **ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡**: {daily_sales * 1.35 * 365:,.0f} ØªÙˆÙ…Ø§Ù†

### ğŸ’ Ù…Ø­Ø§Ø³Ø¨Ù‡ ROI
- **Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯**: 180,000,000 ØªÙˆÙ…Ø§Ù†
- **Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡**: {daily_sales * 0.35 * 365:,.0f} ØªÙˆÙ…Ø§Ù†
- **ROI**: 13,100%
- **Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª**: 2.7 Ù…Ø§Ù‡

## ğŸ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªØ®ØµØµÛŒ

### 1ï¸âƒ£ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†
- Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡
- Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ø¨Ø§ Ø¬Ù‡Øªâ€ŒÛŒØ§Ø¨ÛŒ Ø¢Ø³Ø§Ù†
- Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ

### 2ï¸âƒ£ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
- LED Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø±
- Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
- Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ¶Ø§ÛŒ Ú©Ù„ÛŒ

### 3ï¸âƒ£ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ
- Ø³ÛŒØ³ØªÙ… RFID Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
- Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ø§Ø¶Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
- Ù…Ø¯ÛŒØ±ÛŒØª ÙØµÙˆÙ„ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

### 4ï¸âƒ£ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
- Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ø¨Ø§ Ù¾Ø±Ø³Ù†Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
- Ø®Ø¯Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø´Ø§Ù…Ù„ ØªØ¹Ù…ÛŒØ± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ
- Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙˆÙØ§Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ

## ğŸ“Š Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI)

### ğŸ¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
- **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡**: {daily_sales * 1.35:,.0f} ØªÙˆÙ…Ø§Ù†
- **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡**: {int(daily_customers * 1.33)} Ù†ÙØ±
- **Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„**: 35%
- **Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ**: 90%
- **Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±**: Ú©Ù…ØªØ± Ø§Ø² 3 Ø¯Ù‚ÛŒÙ‚Ù‡

## ğŸš€ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:

âœ… **ÙØ±ÙˆØ´ Ø±Ø§ 35% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯**
âœ… **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ 33% Ø¨ÛŒØ´ØªØ± Ø¬Ø°Ø¨ Ú©Ù†Ø¯**
âœ… **Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø±Ø§ 40% Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯**
âœ… **ROI 13,100% Ú©Ø³Ø¨ Ú©Ù†Ø¯**
âœ… **Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª 2.7 Ù…Ø§Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯**

---
*Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ AI ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.*
"""
    
    return detailed_analysis

def generate_comprehensive_implementation_plan(analysis_data):
    """ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ PDF"""
    store_name = analysis_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡')
    store_type = analysis_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ')
    store_size = analysis_data.get('store_size', 'medium')
    city = analysis_data.get('city', 'ØªÙ‡Ø±Ø§Ù†')
    area = analysis_data.get('area', 'ÙˆÙ†Ú©')
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØªØ±Ø§Ú˜
    size_mapping = {'small': 50, 'medium': 125, 'large': 350, 'xlarge': 750}
    actual_size = size_mapping.get(store_size, 125)
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ±ÙˆØ´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ø¯Ù‡
    daily_customers = int(analysis_data.get('daily_customers', 150))
    daily_sales = float(analysis_data.get('daily_sales', 5000000))
    
    # ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
    if jdatetime:
        from django.utils import timezone
        now = timezone.now()
        persian_date = jdatetime.datetime.fromgregorian(datetime=now)
        persian_date_str = persian_date.strftime("%Y/%m/%d")
    else:
        from django.utils import timezone
        persian_date_str = timezone.now().strftime("%Y/%m/%d")
    
    implementation_plan = f"""
# ğŸ“‹ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ
## ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} - Ù…Ù†Ø·Ù‚Ù‡ {area} {city}

**ØªØ§Ø±ÛŒØ® ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´:** {persian_date_str}

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ

Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø§Ø² ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù‡Ø¯Ù Ø§ØµÙ„ÛŒØŒ Ø§ÙØ²Ø§ÛŒØ´ 35% ÙØ±ÙˆØ´ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†ØŒ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒØŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ø§Ø³Øª.

**Ù…Ø´Ø®ØµØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:**
- Ù†Ø§Ù…: {store_name}
- Ù†ÙˆØ¹: {store_type}
- Ù…Ø³Ø§Ø­Øª: {actual_size} Ù…ØªØ± Ù…Ø±Ø¨Ø¹
- Ù…ÙˆÙ‚Ø¹ÛŒØª: {area}ØŒ {city}
- Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: {daily_customers} Ù†ÙØ±
- ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡: {daily_sales:,.0f} ØªÙˆÙ…Ø§Ù†

---

## ğŸ” ØªØ­Ù„ÛŒÙ„ Ù…Ø´Ú©Ù„Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡

### âš ï¸ Ù…Ø´Ú©Ù„ 1: Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ø¯

**ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:**
- Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ Ø¯Ø± Ø§Ø±ØªÙØ§Ø¹ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
- Ø¹Ø¯Ù… Ø±Ø¹Ø§ÛŒØª Ø§ØµÙˆÙ„ "Ú†Ø´Ù…â€ŒØ§Ù†Ø¯Ø§Ø²" Ùˆ "Ø¯Ø³ØªØ±Ø³ÛŒ" Ø¯Ø± Ú†ÛŒØ¯Ù…Ø§Ù†
- Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ú©Ù…Ù„ Ø¯Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ Ø§Ø² ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
- Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø² ÙØ¶Ø§ÛŒ Ø¹Ù…ÙˆØ¯ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡

**ØªØ£Ø«ÛŒØ± Ø¨Ø± ÙØ±ÙˆØ´:**
- Ú©Ø§Ù‡Ø´ 25% ÙØ±ÙˆØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´
- Ø§ÙØ²Ø§ÛŒØ´ 40% Ø²Ù…Ø§Ù† Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø´ØªØ±ÛŒ
- Ú©Ø§Ù‡Ø´ 30% Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ø¨Ù‡ Ø®Ø±ÛŒØ¯
- ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª
- ØªØ±ØªÛŒØ¨ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù†Ø·Ù‚ÛŒ Ù†ÛŒØ³Øª
- Ù…Ù†Ø§Ø·Ù‚ Ù…Ø±Ø¯Ù‡ (Dead Zones) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„ ØªÙØµÛŒÙ„ÛŒ:**

#### Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ù‡ÙØªÙ‡ 1)
1. **Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ±ÙˆØ´:**
   - Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³ØªØ§Ø±Ù‡ (20% Ù…Ø­ØµÙˆÙ„Ø§ØªØŒ 80% ÙØ±ÙˆØ´)
   - Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³ÙˆØ§Ù„ÛŒ (Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§)
   - Ù…Ø­ØµÙˆÙ„Ø§Øª Ú¯Ø§Ùˆ Ù†Ù‚Ø¯ÛŒ (Ø³ÙˆØ¯ Ø¨Ø§Ù„Ø§ØŒ ÙØ±ÙˆØ´ Ù…ØªÙˆØ³Ø·)
   - Ù…Ø­ØµÙˆÙ„Ø§Øª Ø³Ú¯ (ÙØ±ÙˆØ´ Ùˆ Ø³ÙˆØ¯ Ù¾Ø§ÛŒÛŒÙ†)

2. **ØªØ¹ÛŒÛŒÙ† Ø§Ø±ØªÙØ§Ø¹ Ø¨Ù‡ÛŒÙ†Ù‡:**
   - Ø§Ø±ØªÙØ§Ø¹ 1.2-1.6 Ù…ØªØ±: Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´
   - Ø§Ø±ØªÙØ§Ø¹ 0.8-1.2 Ù…ØªØ±: Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØªÙˆØ³Ø·
   - Ø§Ø±ØªÙØ§Ø¹ 0.4-0.8 Ù…ØªØ±: Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ù…â€ŒÙØ±ÙˆØ´
   - Ø§Ø±ØªÙØ§Ø¹ 1.6-2.0 Ù…ØªØ±: Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ù…Ø§ÛŒØ´ÛŒ

3. **Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§:**
   - ÙØ§ØµÙ„Ù‡ Ø§ØµÙ„ÛŒ: 1.2 Ù…ØªØ± (Ø¨Ø±Ø§ÛŒ Ø¹Ø¨ÙˆØ± Ø±Ø§Ø­Øª)
   - ÙØ§ØµÙ„Ù‡ ÙØ±Ø¹ÛŒ: 0.9 Ù…ØªØ± (Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù†)
   - ÙØ§ØµÙ„Ù‡ Ø¯ÛŒÙˆØ§Ø±: 0.6 Ù…ØªØ± (Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª)

#### Ù…Ø±Ø­Ù„Ù‡ 2: Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ø¬Ø¯ÛŒØ¯ (Ù‡ÙØªÙ‡ 2)
1. **Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù‚Ø´Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†:**
   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø± SketchUp ÛŒØ§ AutoCAD
   - ØªØ¹ÛŒÛŒÙ† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
   - Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ Ø¯Ø± Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ

2. **Ø·Ø±Ø§Ø­ÛŒ Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´:**
   - Ù…Ù†Ø·Ù‚Ù‡ ÙˆØ±ÙˆØ¯ÛŒ: Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø°Ø§Ø¨ Ùˆ Ø¬Ø¯ÛŒØ¯
   - Ù…Ù†Ø·Ù‚Ù‡ Ø§ØµÙ„ÛŒ: Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´
   - Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ: Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©Ù…ÛŒÙ„ÛŒ
   - Ù…Ù†Ø·Ù‚Ù‡ ØµÙ†Ø¯ÙˆÙ‚: Ù…Ø­ØµÙˆÙ„Ø§Øª ØªÚ©â€ŒØ®Ø±ÛŒØ¯

#### Ù…Ø±Ø­Ù„Ù‡ 3: Ø§Ø¬Ø±Ø§ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† (Ù‡ÙØªÙ‡ 3-4)
1. **ØªÙ‡ÛŒÙ‡ ØªØ¬Ù‡ÛŒØ²Ø§Øª:**
   - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…: 15,000,000 ØªÙˆÙ…Ø§Ù†
   - ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ÛŒ Ø±Ø§Ù‡Ù†Ù…Ø§: 3,000,000 ØªÙˆÙ…Ø§Ù†
   - Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª: 1,000,000 ØªÙˆÙ…Ø§Ù†

2. **Ù†ØµØ¨ Ùˆ ØªÙ†Ø¸ÛŒÙ…:**
   - Ø±ÙˆØ² 1-2: Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§
   - Ø±ÙˆØ² 3-4: Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª
   - Ø±ÙˆØ² 5-6: Ù†ØµØ¨ ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
   - Ø±ÙˆØ² 7: ØªØ³Øª Ùˆ ØªÙ†Ø¸ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ

### âš ï¸ Ù…Ø´Ú©Ù„ 2: Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª

**ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„:**
- Ù…Ø´ØªØ±ÛŒØ§Ù† Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ùˆ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø·ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
- Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
- ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± Ø¨Ø±Ø®ÛŒ Ù†Ù‚Ø§Ø· Ù…ØªØ±Ø§Ú©Ù… Ø§Ø³Øª
- Ù…Ø´ØªØ±ÛŒØ§Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù‡Ù… Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ù†Ø¯

**Ø±Ø§Ù‡â€ŒØ­Ù„ ØªÙØµÛŒÙ„ÛŒ:**

#### Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© (Ù‡ÙØªÙ‡ 1)
1. **Ù†Ù‚Ø´Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ ØªØ±Ø§ÙÛŒÚ©:**
   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÙˆØ±Ø¨ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯
   - Ø«Ø¨Øª Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
   - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· ØªØ±Ø§Ú©Ù… Ùˆ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡

2. **ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:**
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø¯Ø± Ù‡Ø± Ù…Ù†Ø·Ù‚Ù‡
   - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡
   - ØªØ¹ÛŒÛŒÙ† Ù†Ù‚Ø§Ø· ØªÙˆÙ‚Ù Ùˆ Ø®Ø±ÛŒØ¯

#### Ù…Ø±Ø­Ù„Ù‡ 2: Ø·Ø±Ø§Ø­ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ (Ù‡ÙØªÙ‡ 2)
1. **Ù…Ø³ÛŒØ± Ø§ØµÙ„ÛŒ (80% Ù…Ø´ØªØ±ÛŒØ§Ù†):**
   - ÙˆØ±ÙˆØ¯ÛŒ â†’ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±ÙØ±ÙˆØ´ â†’ ØµÙ†Ø¯ÙˆÙ‚ â†’ Ø®Ø±ÙˆØ¬
   - Ø·ÙˆÙ„: Ø­Ø¯Ø§Ú©Ø«Ø± 30 Ù…ØªØ±
   - Ø²Ù…Ø§Ù†: 5-8 Ø¯Ù‚ÛŒÙ‚Ù‡

2. **Ù…Ø³ÛŒØ± ØªÙØ±ÛŒØ­ÛŒ (15% Ù…Ø´ØªØ±ÛŒØ§Ù†):**
   - ÙˆØ±ÙˆØ¯ÛŒ â†’ ØªÙ…Ø§Ù… Ù…Ù†Ø§Ø·Ù‚ â†’ ØµÙ†Ø¯ÙˆÙ‚ â†’ Ø®Ø±ÙˆØ¬
   - Ø·ÙˆÙ„: 50-70 Ù…ØªØ±
   - Ø²Ù…Ø§Ù†: 15-25 Ø¯Ù‚ÛŒÙ‚Ù‡

3. **Ù…Ø³ÛŒØ± ØªØ®ØµØµÛŒ (5% Ù…Ø´ØªØ±ÛŒØ§Ù†):**
   - ÙˆØ±ÙˆØ¯ÛŒ â†’ Ù…Ù†Ø·Ù‚Ù‡ ØªØ®ØµØµÛŒ â†’ Ù…Ø´Ø§ÙˆØ±Ù‡ â†’ ØµÙ†Ø¯ÙˆÙ‚ â†’ Ø®Ø±ÙˆØ¬
   - Ø·ÙˆÙ„: 40-60 Ù…ØªØ±
   - Ø²Ù…Ø§Ù†: 20-35 Ø¯Ù‚ÛŒÙ‚Ù‡

#### Ù…Ø±Ø­Ù„Ù‡ 3: Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ (Ù‡ÙØªÙ‡ 3)
1. **Ù†ØµØ¨ Ø±Ø§Ù‡Ù†Ù…Ø§Ù‡Ø§:**
   - ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ÛŒ Ø¬Ù‡Øªâ€ŒÛŒØ§Ø¨ÛŒ: 2,000,000 ØªÙˆÙ…Ø§Ù†
   - Ø®Ø·ÙˆØ· Ø±Ø§Ù‡Ù†Ù…Ø§ Ø±ÙˆÛŒ Ø²Ù…ÛŒÙ†: 1,500,000 ØªÙˆÙ…Ø§Ù†
   - ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ: 1,000,000 ØªÙˆÙ…Ø§Ù†

2. **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¶Ø§:**
   - Ø­Ø°Ù Ù…ÙˆØ§Ù†Ø¹ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ
   - ØªÙ†Ø¸ÛŒÙ… Ø¹Ø±Ø¶ Ù…Ø³ÛŒØ±Ù‡Ø§
   - Ø§ÛŒØ¬Ø§Ø¯ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù†ØªØ¸Ø§Ø±

### âš ï¸ Ù…Ø´Ú©Ù„ 3: Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯

**ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„:**
- Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ÛŒÚ©Ù†ÙˆØ§Ø®Øª Ùˆ Ø®Ø³ØªÙ‡â€ŒÚ©Ù†Ù†Ø¯Ù‡
- Ø³Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
- Ù…ØµØ±Ù Ø§Ù†Ø±Ú˜ÛŒ Ø¨Ø§Ù„Ø§
- Ø¹Ø¯Ù… ØªØ£Ú©ÛŒØ¯ Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…Ù‡Ù…

**Ø±Ø§Ù‡â€ŒØ­Ù„ ØªÙØµÛŒÙ„ÛŒ:**

#### Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ­Ù„ÛŒÙ„ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ÙØ¹Ù„ÛŒ (Ù‡ÙØªÙ‡ 1)
1. **Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†ÙˆØ±:**
   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†ÙˆØ±Ø³Ù†Ø¬ (Lux Meter)
   - Ø«Ø¨Øª Ø´Ø¯Øª Ù†ÙˆØ± Ø¯Ø± Ù†Ù‚Ø§Ø· Ù…Ø®ØªÙ„Ù
   - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ù†Ø§Ø·Ù‚ ØªØ§Ø±ÛŒÚ© Ùˆ Ø±ÙˆØ´Ù†

2. **Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§:**
   - Ù†ÙˆØ± Ø¹Ù…ÙˆÙ…ÛŒ: 300 Ù„ÙˆÚ©Ø³
   - Ù†ÙˆØ± Ù…Ø­ØµÙˆÙ„Ø§Øª: 500 Ù„ÙˆÚ©Ø³
   - Ù†ÙˆØ± ØµÙ†Ø¯ÙˆÙ‚: 600 Ù„ÙˆÚ©Ø³
   - Ù†ÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ: 400 Ù„ÙˆÚ©Ø³
#### Ù…Ø±Ø­Ù„Ù‡ 2: Ø·Ø±Ø§Ø­ÛŒ Ø³ÛŒØ³ØªÙ… Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ (Ù‡ÙØªÙ‡ 2)
1. **Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ:**
   - LED Ù¾Ù†Ù„â€ŒÙ‡Ø§ÛŒ 36 ÙˆØ§Øª: 20 Ø¹Ø¯Ø¯
   - ÙØ§ØµÙ„Ù‡ Ù†ØµØ¨: 3Ã—3 Ù…ØªØ±
   - Ø±Ù†Ú¯ Ù†ÙˆØ±: 4000K (Ø³ÙÛŒØ¯ Ø®Ù†Ø«ÛŒ)

2. **Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª:**
   - LED Ø§Ø³Ù¾Ø§Øªâ€ŒÙ‡Ø§ÛŒ 12 ÙˆØ§Øª: 30 Ø¹Ø¯Ø¯
   - Ø²Ø§ÙˆÛŒÙ‡ Ù†ÙˆØ±: 30 Ø¯Ø±Ø¬Ù‡
   - Ø±Ù†Ú¯ Ù†ÙˆØ±: 3000K (Ø³ÙÛŒØ¯ Ú¯Ø±Ù…)

3. **Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ ØªØ²Ø¦ÛŒÙ†ÛŒ:**
   - LED Ù†ÙˆØ§Ø±Ù‡Ø§ÛŒ RGB: 50 Ù…ØªØ±
   - Ú©Ù†ØªØ±Ù„Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯: 1 Ø¹Ø¯Ø¯
   - Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±

#### Ù…Ø±Ø­Ù„Ù‡ 3: Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ (Ù‡ÙØªÙ‡ 3)
1. **ØªÙ‡ÛŒÙ‡ ØªØ¬Ù‡ÛŒØ²Ø§Øª:**
   - LED Ù¾Ù†Ù„â€ŒÙ‡Ø§: 25,000,000 ØªÙˆÙ…Ø§Ù†
   - LED Ø§Ø³Ù¾Ø§Øªâ€ŒÙ‡Ø§: 15,000,000 ØªÙˆÙ…Ø§Ù†
   - Ù†ÙˆØ§Ø±Ù‡Ø§ÛŒ RGB: 5,000,000 ØªÙˆÙ…Ø§Ù†
   - Ú©Ù†ØªØ±Ù„Ø± Ùˆ Ø³ÛŒÙ…â€ŒÚ©Ø´ÛŒ: 10,000,000 ØªÙˆÙ…Ø§Ù†

2. **Ù†ØµØ¨:**
   - Ø±ÙˆØ² 1-2: Ù†ØµØ¨ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
   - Ø±ÙˆØ² 3-4: Ù†ØµØ¨ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
   - Ø±ÙˆØ² 5: Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… Ú©Ù†ØªØ±Ù„
   - Ø±ÙˆØ² 6: ØªØ³Øª Ùˆ ØªÙ†Ø¸ÛŒÙ…

### âš ï¸ Ù…Ø´Ú©Ù„ 4: Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯

**ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„:**
- ÙØ¶Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¯Ø± Ú¯ÙˆØ´Ù‡â€ŒÙ‡Ø§
- Ù…Ù†Ø§Ø·Ù‚ Ú©Ù…â€ŒØªØ±Ø¯Ø¯
- ÙØ¶Ø§Ù‡Ø§ÛŒ Ù¾Ø´Øª Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§
- Ù…Ù†Ø§Ø·Ù‚ ÙˆØ±ÙˆØ¯ÛŒ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ

**Ø±Ø§Ù‡â€ŒØ­Ù„ ØªÙØµÛŒÙ„ÛŒ:**

#### Ù…Ø±Ø­Ù„Ù‡ 1: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ (Ù‡ÙØªÙ‡ 1)
1. **Ù†Ù‚Ø´Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ ÙØ¶Ø§:**
   - Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ù‚ÛŒÙ‚ ØªÙ…Ø§Ù… ÙØ¶Ø§Ù‡Ø§
   - Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…Ù†Ø§Ø·Ù‚ Ú©Ù…â€ŒØªØ±Ø¯Ø¯
   - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø±ØµØ¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ¶Ø§

2. **ØªØ­Ù„ÛŒÙ„ Ù¾ØªØ§Ù†Ø³ÛŒÙ„:**
   - Ø§Ù…Ú©Ø§Ù† ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…Ù†Ø·Ù‚Ù‡ Ù†Ù…Ø§ÛŒØ´
   - Ø§Ù…Ú©Ø§Ù† Ø§ÛŒØ¬Ø§Ø¯ Ø®Ø¯Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ
   - Ø§Ù…Ú©Ø§Ù† Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ

#### Ù…Ø±Ø­Ù„Ù‡ 2: Ø·Ø±Ø§Ø­ÛŒ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¬Ø¯ÛŒØ¯ (Ù‡ÙØªÙ‡ 2)
1. **Ù…Ù†Ø·Ù‚Ù‡ Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒ:**
   - Ù…ÛŒØ² Ù…Ø´Ø§ÙˆØ±Ù‡: 2Ã—1 Ù…ØªØ±
   - ØµÙ†Ø¯Ù„ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ¸Ø§Ø±: 4 Ø¹Ø¯Ø¯
   - Ú©Ø§ØªØ§Ù„ÙˆÚ¯â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±ÙˆØ´ÙˆØ±Ù‡Ø§

2. **Ù…Ù†Ø·Ù‚Ù‡ Ù†Ù…Ø§ÛŒØ´ ÙˆÛŒÚ˜Ù‡:**
   - ÙˆÛŒØªØ±ÛŒÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¬Ø¯ÛŒØ¯
   - Ù†Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡ Ù…ÙˆÙ‚Øª
   - Ù…Ù†Ø·Ù‚Ù‡ ØªØ³Øª Ù…Ø­ØµÙˆÙ„Ø§Øª

3. **Ù…Ù†Ø·Ù‚Ù‡ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ:**
   - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ØªÙ‡
   - Ø§Ù†Ø¨Ø§Ø± Ú©ÙˆÚ†Ú©
   - Ù…Ù†Ø·Ù‚Ù‡ Ø¨Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ

#### Ù…Ø±Ø­Ù„Ù‡ 3: Ø§Ø¬Ø±Ø§ÛŒ ØªØºÛŒÛŒØ±Ø§Øª (Ù‡ÙØªÙ‡ 3)
1. **ØªÙ‡ÛŒÙ‡ ØªØ¬Ù‡ÛŒØ²Ø§Øª:**
   - Ù…ÛŒØ² Ù…Ø´Ø§ÙˆØ±Ù‡: 3,000,000 ØªÙˆÙ…Ø§Ù†
   - ØµÙ†Ø¯Ù„ÛŒâ€ŒÙ‡Ø§: 2,000,000 ØªÙˆÙ…Ø§Ù†
   - ÙˆÛŒØªØ±ÛŒÙ†: 8,000,000 ØªÙˆÙ…Ø§Ù†
   - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ØªÙ‡: 5,000,000 ØªÙˆÙ…Ø§Ù†

2. **Ù†ØµØ¨ Ùˆ Ú†ÛŒØ¯Ù…Ø§Ù†:**
   - Ø±ÙˆØ² 1-2: Ù†ØµØ¨ ØªØ¬Ù‡ÛŒØ²Ø§Øª
   - Ø±ÙˆØ² 3: Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ ØªÙ†Ø¸ÛŒÙ…
   - Ø±ÙˆØ² 4: ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯

---

## ğŸ“… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø¬Ø±Ø§

**ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:** {persian_date_str}

### ÙØ§Ø² 1: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ (Ù‡ÙØªÙ‡ 1-2)
- **Ø±ÙˆØ² 1-3**: ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
- **Ø±ÙˆØ² 4-7**: Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ
- **Ø±ÙˆØ² 8-14**: Ø³ÙØ§Ø±Ø´ Ùˆ ØªÙ‡ÛŒÙ‡ ØªØ¬Ù‡ÛŒØ²Ø§Øª

### ÙØ§Ø² 2: Ø§Ø¬Ø±Ø§ (Ù‡ÙØªÙ‡ 3-4)
- **Ø±ÙˆØ² 15-18**: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†
- **Ø±ÙˆØ² 19-22**: Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ
- **Ø±ÙˆØ² 23-26**: Ù†ØµØ¨ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ
- **Ø±ÙˆØ² 27-28**: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ¶Ø§Ù‡Ø§

### ÙØ§Ø² 3: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ (Ù‡ÙØªÙ‡ 5)
- **Ø±ÙˆØ² 29-31**: ØªØ³Øª Ùˆ ØªÙ†Ø¸ÛŒÙ…
- **Ø±ÙˆØ² 32-33**: Ø¢Ù…ÙˆØ²Ø´ Ù¾Ø±Ø³Ù†Ù„
- **Ø±ÙˆØ² 34-35**: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø³Ù…ÛŒ

**ØªØ§Ø±ÛŒØ® ØªÚ©Ù…ÛŒÙ„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:** {persian_date.strftime("%Y/%m/%d")} (35 Ø±ÙˆØ² Ø¨Ø¹Ø¯)

---

## ğŸ’° Ø¨ÙˆØ¯Ø¬Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªÙØµÛŒÙ„ÛŒ

### ğŸ“Š Ù…Ù†Ø§Ø¨Ø¹ Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ
ğŸ’¡ **Ø´ÙØ§ÙÛŒØª Ø¯Ø± Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§**: ØªÙ…Ø§Ù… Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø¹ØªØ¨Ø± Ø²ÛŒØ± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯:

â€¢ **Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§**: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ØªØ¬Ù‡ÛŒØ²Ø§Øª Ùˆ Ù„ÙˆØ§Ø²Ù…
â€¢ **ØªØ±Ø¨**: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ§Ø¯ Ùˆ Ù…ØµØ§Ù„Ø­
â€¢ **Ø¨Ø§Ø²Ø§Ø± ØªÙ‡Ø±Ø§Ù†**: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ùˆ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ
â€¢ **Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø±**: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
â€¢ **ØªØ­Ù‚ÛŒÙ‚Ø§Øª Ø¨Ø§Ø²Ø§Ø±**: Ø¢Ù…Ø§Ø±Ù‡Ø§ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§

âš ï¸ **Ù†Ú©ØªÙ‡ Ù…Ù‡Ù…**: Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ ØªÙ‚Ø±ÛŒØ¨ÛŒ Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø±Ø§ÛŒØ· ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± Ù‡Ø³ØªÙ†Ø¯. Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ØŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨Ø§ ØªØ§Ù…ÛŒÙ†â€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù† Ù…Ø­Ù„ÛŒ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

### Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ¬Ù‡ÛŒØ²Ø§Øª:
- **Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…**: 15,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§)*
- **Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ LED**: 55,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: ØªØ±Ø¨ + Ø¨Ø§Ø²Ø§Ø± ØªÙ‡Ø±Ø§Ù†)*
- **ØªØ§Ø¨Ù„ÙˆÙ‡Ø§ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§Ù‡Ø§**: 7,500,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ)*
- **ØªØ¬Ù‡ÛŒØ²Ø§Øª Ø®Ø¯Ù…Ø§Øª**: 18,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ø¯ÛŒØ¬ÛŒâ€ŒÚ©Ø§Ù„Ø§ + ØªØ±Ø¨)*
- **Ù…Ø¬Ù…ÙˆØ¹ ØªØ¬Ù‡ÛŒØ²Ø§Øª**: 95,500,000 ØªÙˆÙ…Ø§Ù†

### Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§:
- **Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ**: 25,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ù†ØµØ¨)*
- **Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ù…Ø´Ø§ÙˆØ±Ù‡**: 15,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ù…Ø´Ø§ÙˆØ±Ø§Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)*
- **Ø¢Ù…ÙˆØ²Ø´ Ù¾Ø±Ø³Ù†Ù„**: 5,000,000 ØªÙˆÙ…Ø§Ù† *(Ù…Ù†Ø¨Ø¹: Ù…Ø±Ø§Ú©Ø² Ø¢Ù…ÙˆØ²Ø´ÛŒ)*
- **Ù…Ø¬Ù…ÙˆØ¹ Ø§Ø¬Ø±Ø§**: 45,000,000 ØªÙˆÙ…Ø§Ù†

### **Ù…Ø¬Ù…ÙˆØ¹ Ú©Ù„ Ù¾Ø±ÙˆÚ˜Ù‡**: 140,500,000 ØªÙˆÙ…Ø§Ù†

### ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù‡Ø²ÛŒÙ†Ù‡:
â€¢ **Ø®Ø±ÛŒØ¯ Ø¹Ù…Ø¯Ù‡**: 15% ØªØ®ÙÛŒÙ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø±ÛŒØ¯ ÛŒÚ©Ø¬Ø§
â€¢ **Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ù‚Ø¯ÛŒ**: 10% ØªØ®ÙÛŒÙ Ø§Ø¶Ø§ÙÛŒ
â€¢ **Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ**: Ú©Ø§Ù‡Ø´ ÙØ´Ø§Ø± Ù…Ø§Ù„ÛŒ
â€¢ **Ù…Ø°Ø§Ú©Ø±Ù‡ Ø¨Ø§ ØªØ§Ù…ÛŒÙ†â€ŒÚ©Ù†Ù†Ø¯Ú¯Ø§Ù†**: Ø§Ù…Ú©Ø§Ù† Ú©Ø§Ù‡Ø´ 5-10% Ù‚ÛŒÙ…Øª

---

## ğŸ“Š Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª

### Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (1-3 Ù…Ø§Ù‡):
- Ø§ÙØ²Ø§ÛŒØ´ 15% ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡
- Ú©Ø§Ù‡Ø´ 20% Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
- Ø§ÙØ²Ø§ÛŒØ´ 25% Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ

### Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª (3-6 Ù…Ø§Ù‡):
- Ø§ÙØ²Ø§ÛŒØ´ 25% ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡
- Ø§ÙØ²Ø§ÛŒØ´ 30% Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡
- Ú©Ø§Ù‡Ø´ 30% Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ

### Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (6-12 Ù…Ø§Ù‡):
- Ø§ÙØ²Ø§ÛŒØ´ 35% ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡
- Ø§ÙØ²Ø§ÛŒØ´ 40% Ø³ÙˆØ¯ Ø®Ø§Ù„Øµ
- Ø¨Ø§Ø²Ú¯Ø´Øª Ú©Ø§Ù…Ù„ Ø³Ø±Ù…Ø§ÛŒÙ‡

---

## ğŸ¯ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ø§ Ù‡Ø¯Ù Ø§ÙØ²Ø§ÛŒØ´ 35% ÙØ±ÙˆØ´ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:

âœ… **ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ Ø§Ø² {daily_sales:,.0f} Ø¨Ù‡ {daily_sales * 1.35:,.0f} ØªÙˆÙ…Ø§Ù† Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯**
âœ… **Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø±Ø§ Ø§Ø² {daily_customers} Ø¨Ù‡ {int(daily_customers * 1.33)} Ù†ÙØ± Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯**
âœ… **Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø±Ø§ Ø§Ø² 25% Ø¨Ù‡ 35% Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯**
âœ… **ROI 13,100% Ú©Ø³Ø¨ Ú©Ù†Ø¯**
âœ… **Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª 2.7 Ù…Ø§Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯**

**ØªÙˆØµÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ:** Ø§Ø¬Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ¹Ù‡Ø¯ Ú©Ø§Ù…Ù„ Ùˆ Ù‡Ù…Ú©Ø§Ø±ÛŒ ØªÛŒÙ… Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ø¬Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ùˆ Ø¨Ø§ Ù†Ø¸Ø§Ø±Øª Ù…Ø³ØªÙ…Ø± Ø§Ù†Ø¬Ø§Ù… Ø´ÙˆØ¯.

---
*Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.*
"""
    
    return implementation_plan

@csrf_exempt
@login_required
def forms_submit(request):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ù… ØªÚ© ØµÙØ­Ù‡â€ŒØ§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡"""
    if request.method == 'POST':
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² session ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            session_analysis_id = request.session.get('analysis_id')
            store_analysis = None
            
            if session_analysis_id:
                try:
                    store_analysis = StoreAnalysis.objects.get(
                        pk=session_analysis_id,
                        user=request.user
                    )
                    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª
                    is_free_analysis = (
                        getattr(store_analysis, 'package_type', None) == 'basic' and
                        getattr(store_analysis, 'final_amount', None) == 0
                    )
                    
                    if is_free_analysis:
                        # Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù†ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ update Ú©Ù† Ùˆ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†
                        form_data = request.POST.dict()
                        files_data = request.FILES
                        
                        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡
                        uploaded_files = {}
                        has_actual_files = False
                        if files_data:
                            for field_name, file_obj in files_data.items():
                                try:
                                    from django.core.files.storage import default_storage
                                    file_path = default_storage.save(f'uploads/{file_obj.name}', file_obj)
                                    uploaded_files[field_name] = {
                                        'name': file_obj.name,
                                        'path': file_path,
                                        'size': file_obj.size,
                                        'type': file_obj.content_type
                                    }
                                    has_actual_files = True
                                    logger.info(f"File uploaded: {field_name} -> {file_path}")
                                except Exception as e:
                                    logger.error(f"Error saving file {field_name}: {e}")
                                    uploaded_files[field_name] = {'error': str(e)}
                        
                        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ analysis_data
                        current_data = store_analysis.analysis_data or {}
                        if isinstance(current_data, str):
                            import json
                            try:
                                current_data = json.loads(current_data)
                            except:
                                current_data = {}
                        current_data.update(form_data)
                        current_data['uploaded_files'] = uploaded_files
                        
                        store_analysis.analysis_data = current_data
                        store_analysis.store_name = form_data.get('store_name', store_analysis.store_name)
                        
                        # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ØŒ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†
                        if has_actual_files:
                            store_analysis.status = 'processing'
                            logger.info(f"âœ… ÙØ±Ù… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø´Ø±ÙˆØ¹ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡: {list(uploaded_files.keys())}")
                            store_analysis.save()
                            logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ {store_analysis.id} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¨Ø§ status='processing' Ùˆ {len(uploaded_files)} ÙØ§ÛŒÙ„")
                            
                            # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± background
                            try:
                                import threading
                                
                                def start_free_analysis():
                                    """Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± background"""
                                    try:
                                        logger.info(f"ğŸ†“ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                        
                                        from .ai_services.free_analysis_service import FreeAnalysisService
                                        free_service = FreeAnalysisService()
                                        
                                        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
                                        store_data = {
                                            'store_name': store_analysis.store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                                            'store_type': current_data.get('store_type', 'Ø¹Ù…ÙˆÙ…ÛŒ'),
                                            'store_size': str(current_data.get('store_size', 0)),
                                            'store_address': current_data.get('store_address', ''),
                                            'description': current_data.get('description', ''),
                                            **current_data
                                        }
                                        
                                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµØ§ÙˆÛŒØ± Ø§Ø² uploaded_files
                                        images = []
                                        if 'uploaded_files' in current_data:
                                            uploaded_files_dict = current_data['uploaded_files']
                                            image_fields = ['store_photos', 'store_layout', 'shelf_photos', 
                                                          'window_display_photos', 'entrance_photos', 'checkout_photos']
                                            for field in image_fields:
                                                if field in uploaded_files_dict:
                                                    file_info = uploaded_files_dict[field]
                                                    if isinstance(file_info, dict) and 'path' in file_info:
                                                        images.append(file_info['path'])
                                        
                                        # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ FreeAnalysisService
                                        logger.info(f"ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø§ {len(images)} ØªØµÙˆÛŒØ±...")
                                        free_analysis_result = free_service.analyze_store(store_data)
                                        
                                        if free_analysis_result and free_analysis_result.get('status') == 'completed':
                                            logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                            
                                            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ results
                                            analysis_results = free_analysis_result.get('analysis_results', {})
                                            report_content = free_analysis_result.get('report', '')
                                            
                                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ analysis_text
                                            analysis_text = None
                                            if isinstance(analysis_results, dict):
                                                analysis_text = (
                                                    analysis_results.get('analysis_text') or 
                                                    analysis_results.get('summary') or
                                                    analysis_results.get('executive_summary', {}).get('summary') if isinstance(analysis_results.get('executive_summary'), dict) else None
                                                )
                                            
                                            if not analysis_text and report_content:
                                                analysis_text = report_content
                                            
                                            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
                                            store_analysis.results = {
                                                'analysis_text': analysis_text or 'ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯',
                                                'report': report_content,
                                                'analysis_results': analysis_results,
                                                'free_analysis': True,
                                                'completed_at': timezone.now().isoformat()
                                            }
                                            store_analysis.status = 'completed'
                                            store_analysis.save()
                                            logger.info(f"âœ… Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                        else:
                                            logger.warning(f"âš ï¸ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}")
                                            store_analysis.status = 'failed'
                                            store_analysis.error_message = free_analysis_result.get('error', 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„') if isinstance(free_analysis_result, dict) else 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„'
                                            store_analysis.save()
                                    except Exception as e:
                                        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id}: {e}", exc_info=True)
                                        store_analysis.status = 'failed'
                                        store_analysis.error_message = str(e)
                                        store_analysis.save()
                                
                                # Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± background thread
                                analysis_thread = threading.Thread(target=start_free_analysis, daemon=True)
                                analysis_thread.start()
                                logger.info(f"ğŸš€ Thread ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ {store_analysis.id} Ø´Ø±ÙˆØ¹ Ø´Ø¯")
                                
                            except Exception as e:
                                logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù†: {e}", exc_info=True)
                            
                            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø§ Ù¾ÛŒØºØ§Ù… Ù…ÙˆÙÙ‚ÛŒØª
                            return JsonResponse({
                                'success': True,
                                'message': 'âœ… ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø´Ø±ÙˆØ¹ Ø´Ø¯! Ù†ØªØ§ÛŒØ¬ Ù¾Ø³ Ø§Ø² Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.',
                                'redirect_url': f'/store/dashboard/',
                                'payment_required': False
                            })
                        else:
                            # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ØŒ ÙÙ‚Ø· ÙØ±Ù… Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
                            store_analysis.save()
                            return JsonResponse({
                                'success': True,
                                'message': 'âš ï¸ ÙØ±Ù… Ø«Ø¨Øª Ø´Ø¯ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.',
                                'redirect_url': f'/store/forms/{store_analysis.id}/',
                                'payment_required': False
                            })
                except StoreAnalysis.DoesNotExist:
                    pass
            
            # Ø§Ú¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ù†ÛŒØ³Øª ÛŒØ§ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¹Ø§Ø¯ÛŒ Ø±Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
            # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù… Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ø§Ø¯Ù‡
            form_data = request.POST.dict()
            files_data = request.FILES
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡
            uploaded_files = {}
            if files_data:
                for field_name, file_obj in files_data.items():
                    try:
                        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¯Ø± media
                        from django.core.files.storage import default_storage
                        file_path = default_storage.save(f'uploads/{file_obj.name}', file_obj)
                        uploaded_files[field_name] = {
                            'name': file_obj.name,
                            'path': file_path,
                            'size': file_obj.size,
                            'type': file_obj.content_type
                        }
                        logger.info(f"File uploaded: {field_name} -> {file_path}")
                    except Exception as e:
                        logger.error(f"Error saving file {field_name}: {e}")
                        uploaded_files[field_name] = {'error': str(e)}
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ form_data
            form_data['uploaded_files'] = uploaded_files
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„
            analysis_type = form_data.get('analysis_type', 'preliminary')
            
            # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ (Ø³Ø§Ø¯Ù‡) - Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² safe_create_store_analysis
            from store_analysis.utils.safe_db import safe_create_store_analysis
            store_analysis = safe_create_store_analysis(
                user=request.user,
                store_name=form_data.get('store_name', 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡'),
                status='pending',
                analysis_type='comprehensive',
                analysis_data=form_data
            )
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ (2,000,000 ØªÙˆÙ…Ø§Ù† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ - Ø¨Ø§ 100% ØªØ®ÙÛŒÙ ØªØ§ Ù¾Ø§ÛŒØ§Ù† Ø³Ø§Ù„)
            cost_breakdown = calculate_analysis_cost(form_data)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´
            generated_order_number = f"ORD-{uuid.uuid4().hex[:12].upper()}"
            order = Order.objects.create(
                user=request.user,
                order_number=generated_order_number,
                plan=None,
                original_amount=Decimal(str(cost_breakdown['total'])),
                base_amount=Decimal(str(cost_breakdown['total'])),
                discount_amount=Decimal(str(cost_breakdown.get('discount', 0))),
                final_amount=Decimal(str(cost_breakdown['final'])),
                status='pending',
                transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
            )
            
            # Ø§ØªØµØ§Ù„ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ Ø³ÙØ§Ø±Ø´
            store_analysis.order = order
            # ØªÙ†Ø¸ÛŒÙ… ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ database
            store_analysis.ai_insights = ""
            store_analysis.recommendations = ""
            store_analysis.save()
            
            # Ø°Ø®ÛŒØ±Ù‡ analysis_id Ø¯Ø± session Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª
            request.session['analysis_id'] = store_analysis.id
            
            logger.info(f"âœ… Analysis {store_analysis.id} created for order {order.order_number}")
            
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ù¾ÛŒØºØ§Ù… Ù…Ù†Ø§Ø³Ø¨
            return JsonResponse({
                'success': True,
                'message': 'âœ… ÙØ±Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯! Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø®ØªØŒ ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Liara AI Ùˆ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø´Ø±ÙˆØ¹ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ù¾Ø³ Ø§Ø² Ø­Ø¯ÙˆØ¯ 30 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.',
                'redirect_url': f'/store/payment/{order.order_number}/',
                'payment_required': True
            })
            
        except Exception as e:
            logger.error(f"Error in forms_submit: {e}")
            return JsonResponse({
                'success': False,
                'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÙØ±Ù…: {str(e)}'
            })
    
    return JsonResponse({
        'success': False,
        'message': 'Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'
    })


def products_page(request):
    """ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø®Ø¯Ù…Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù„Ø§Ú¯ÛŒÙ†"""
    products = [
        {
            'name': 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'original_price': '500000',
            'price': 'Ø±Ø§ÛŒÚ¯Ø§Ù†',
            'discount_percent': '100',
            'currency': 'ØªÙˆÙ…Ø§Ù†',
            'delivery_time': '24 Ø³Ø§Ø¹Øª',
            'features': [
                'ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                'Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù',
                '5 Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¹Ù…Ù„ÛŒ',
                'Ú¯Ø²Ø§Ø±Ø´ 10 ØµÙØ­Ù‡â€ŒØ§ÛŒ',
                'Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§ÛŒÙ…ÛŒÙ„'
            ],
            'buy_url': '/store/buy/basic/',
            'popular': False,
            'is_free': True
        },
        {
            'name': 'ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'original_price': '1500000',
            'price': '750000',
            'discount_percent': '50',
            'currency': 'ØªÙˆÙ…Ø§Ù†',
            'delivery_time': '48 Ø³Ø§Ø¹Øª',
            'features': [
                'ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
                'Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ùˆ Ù‚ÙˆØª',
                '15 Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¹Ù…Ù„ÛŒ',
                'Ú¯Ø²Ø§Ø±Ø´ 25 ØµÙØ­Ù‡â€ŒØ§ÛŒ',
                'Ù…Ø´Ø§ÙˆØ±Ù‡ ØªÙ„ÙÙ†ÛŒ 30 Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ',
                'Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ„ÙÙ†ÛŒ'
            ],
            'buy_url': '/store/buy/complete/',
            'popular': True,
            'is_free': False
        },
        {
            'name': 'ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
            'original_price': '3000000',
            'price': '1500000',
            'discount_percent': '50',
            'currency': 'ØªÙˆÙ…Ø§Ù†',
            'delivery_time': '72 Ø³Ø§Ø¹Øª',
            'features': [
                'ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ + Ù¾ÛŒÚ¯ÛŒØ±ÛŒ',
                'Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø§Ù…Ù„ Ù…Ø´Ú©Ù„Ø§Øª',
                '25 Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¹Ù…Ù„ÛŒ',
                'Ú¯Ø²Ø§Ø±Ø´ 50 ØµÙØ­Ù‡â€ŒØ§ÛŒ',
                'Ù…Ø´Ø§ÙˆØ±Ù‡ ØªÙ„ÙÙ†ÛŒ 60 Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ',
                'Ù¾ÛŒÚ¯ÛŒØ±ÛŒ 30 Ø±ÙˆØ²Ù‡',
                'Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ'
            ],
            'buy_url': '/store/buy/advanced/',
            'popular': False,
            'is_free': False
        }
    ]
    
    payment_methods = [
        {
            'name': 'Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù†Ù„Ø§ÛŒÙ†',
            'description': 'Ø¯Ø±Ú¯Ø§Ù‡ PayPing - Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ù…Ù† Ùˆ Ø³Ø±ÛŒØ¹',
            'features': ['Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªÙ…Ø§Ù… Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§', 'Ù¾Ø±Ø¯Ø§Ø®Øª ÙÙˆØ±ÛŒ', 'ØªØ£ÛŒÛŒØ¯ ÙÙˆØ±ÛŒ']
        }
    ]
    
    guarantees = [
        {
            'name': 'Ø¶Ù…Ø§Ù†Øª Ú©ÛŒÙÛŒØª',
            'description': 'ØªØ­Ù„ÛŒÙ„ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ØªÙˆØ³Ø· Ù…ØªØ®ØµØµØ§Ù†',
            'details': ['Ù†ØªÛŒØ¬Ù‡ Ø¹Ù…Ù„ÛŒ', 'Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ ØªØ§ 30 Ø±ÙˆØ²']
        }
    ]
    
    context = {
        'products': products,
        'payment_methods': payment_methods,
        'guarantees': guarantees,
        'page_title': 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø®Ø¯Ù…Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
        'meta_description': 'Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ø®Ø¯Ù…Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ. ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ØŒ Ú©Ø§Ù…Ù„ Ùˆ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø´ÙØ§Ù.',
        'meta_keywords': 'Ù…Ø­ØµÙˆÙ„Ø§Øª ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ØŒ Ø®Ø¯Ù…Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù†ØŒ ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ØŒ Ù…Ø´Ø§ÙˆØ±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'
    }
    
    return render(request, 'store_analysis/products.html', context)


def buy_basic(request):
    """Ø®Ø±ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ø§ Ù…Ø­Ø§ÙØ¸Øª Ø¶Ø¯ Ø³ÙˆØ¡ Ø§Ø³ØªÙØ§Ø¯Ù‡"""
    if request.method == 'POST':
        # ğŸ›¡ï¸ IMPORTANT: Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… FreeUsageChecker
        from .services.free_usage_checker import FreeUsageChecker
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ù… Ø®Ø±ÛŒØ¯
        store_name = request.POST.get('store_name')
        store_type = request.POST.get('store_type')
        store_size = request.POST.get('store_size')
        phone = request.POST.get('phone')
        email = request.POST.get('email')
        
        # Ø§ÛŒØ¬Ø§Ø¯ username Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØºÛŒØ±Ù„Ø§Ú¯ÛŒÙ†
        username = request.user.username if request.user.is_authenticated else f'guest_{phone}'
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù†
        check_result = FreeUsageChecker.check_multiple_identifiers(
            request=request,
            username=username,
            email=email,
            phone=phone
        )
        
        # ğŸš« Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù‡ - Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ
        if not check_result['can_use']:
            messages.warning(
                request,
                f"ğŸš« {check_result.get('message', check_result['reason'])} "
                f"Ù„Ø·ÙØ§Ù‹ Ø§Ø² Ù¾Ù„Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            )
            # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾ÙˆÙ„ÛŒ
            return redirect('store_analysis:products')
        
        # âœ… Ù…Ø¬Ø§Ø² Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª - Ø§Ø¯Ø§Ù…Ù‡ ÙØ±Ø¢ÛŒÙ†Ø¯
        # Ø¯Ø±ÛŒØ§ÙØª ServicePackage
        from .models import ServicePackage
        service_package = ServicePackage.objects.get(package_type='basic')
        
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª
        original_amount = 500000
        discount_amount = 500000  # 100% ØªØ®ÙÛŒÙ
        final_amount = 0  # Ø±Ø§ÛŒÚ¯Ø§Ù†
        
        # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ (Ø¨Ø¯ÙˆÙ† Order)
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ù†ÛŒØ³ØªØŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if request.user.is_authenticated:
            user = request.user
        else:
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØºÛŒØ±Ù„Ø§Ú¯ÛŒÙ†
            from django.contrib.auth.models import User
            user, created = User.objects.get_or_create(
                username=username,
                defaults={
                    'email': email,
                    'first_name': store_name,
                    'is_active': False
                }
            )
        
        # Safe create Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ missing
        from .utils.safe_db import safe_create_store_analysis
        store_analysis = safe_create_store_analysis(
            user=user,
            store_name=store_name,
            store_type=store_type,
            store_size=store_size,
            contact_phone=phone,
            contact_email=email,
            status='paid',  # Ø±Ø§ÛŒÚ¯Ø§Ù† - Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡
            package_type='basic',
            analysis_type='comprehensive_7step',
            final_amount=0
        )
        
        # ğŸ“ Ø«Ø¨Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ø³ÛŒØ³ØªÙ…
        FreeUsageChecker.track_free_usage(
            username=username,
            analysis_id=store_analysis.id,
            store_name=store_name,
            email=email,
            phone=phone,
            request=request,
            analysis_type='basic_free'
        )
        
        # ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª - Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ÙØ±Ù… Ø¨Ø±Ø§ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        request.session['analysis_id'] = store_analysis.id
        messages.success(request, 'âœ… ØªØ­Ù„ÛŒÙ„ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø´Ù…Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯! Ù„Ø·ÙØ§Ù‹ ÙØ±Ù… Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:forms', analysis_id=store_analysis.id)
    
    # ğŸ›¡ï¸ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ Ø¯Ø± ØµÙØ­Ù‡ ÙØ±Ù…
    from .services.free_usage_checker import FreeUsageChecker
    username = request.user.username if request.user.is_authenticated else None
    check_result = FreeUsageChecker.check_multiple_identifiers(
        request=request,
        username=username
    )
    
    context = {
        'product_name': 'ØªØ­Ù„ÛŒÙ„ Ø§ÙˆÙ„ÛŒÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
        'original_price': '500000',
        'price': 'Ø±Ø§ÛŒÚ¯Ø§Ù†',
        'discount_percent': '100',
        'currency': 'ØªÙˆÙ…Ø§Ù†',
        'delivery_time': '24 Ø³Ø§Ø¹Øª',
        'is_free': True,
        'is_used_before': not check_result['can_use'],
        'usage_info': check_result
    }
    
    return render(request, 'store_analysis/buy_form.html', context)
@login_required
def buy_complete(request):
    """ğŸ’ Ø®Ø±ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ - Ù¾Ù„Ù† Ù¾ÙˆÙ„ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ GPT-4o"""
    # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø¯ ØªØ®ÙÛŒÙ Ø§Ø² query string
    discount_code_str = request.GET.get('discount_code', '').strip().upper()
    discount_code_obj = None
    discount_percentage = 0
    discount_amount = Decimal('0')
    
    if discount_code_str:
        try:
            from .models import DiscountCode
            discount_code_obj = DiscountCode.objects.get(
                code=discount_code_str,
                is_active=True
            )
            if discount_code_obj.is_valid():
                discount_percentage = discount_code_obj.discount_percentage
                discount_code_obj.use_discount()
                # Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
                from .models import ReviewReminder
                ReviewReminder.objects.filter(
                    discount_code=discount_code_obj,
                    status='sent'
                ).update(status='used')
            else:
                messages.warning(request, 'Ú©Ø¯ ØªØ®ÙÛŒÙ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª ÛŒØ§ Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.')
                discount_code_obj = None
        except DiscountCode.DoesNotExist:
            messages.warning(request, 'Ú©Ø¯ ØªØ®ÙÛŒÙ ÛŒØ§ÙØª Ù†Ø´Ø¯.')
        except Exception as e:
            logger.error(f"Error applying discount code: {e}")
    
    if request.method == 'POST':
        store_name = request.POST.get('store_name', '').strip()
        store_type = request.POST.get('store_type', '').strip()
        store_size = request.POST.get('store_size', '').strip()
        store_address = request.POST.get('store_address', '').strip()
        phone = request.POST.get('phone', '').strip()
        email = request.POST.get('email', '').strip()
        additional_info = request.POST.get('additional_info', '').strip()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø¯ ØªØ®ÙÛŒÙ Ø§Ø² POST Ù‡Ù…
        if not discount_code_obj:
            discount_code_str = request.POST.get('discount_code', '').strip().upper()
            if discount_code_str:
                try:
                    from .models import DiscountCode
                    discount_code_obj = DiscountCode.objects.get(
                        code=discount_code_str,
                        is_active=True
                    )
                    if discount_code_obj.is_valid():
                        discount_percentage = discount_code_obj.discount_percentage
                        discount_code_obj.use_discount()
                    else:
                        discount_code_obj = None
                except DiscountCode.DoesNotExist:
                    pass

        try:
            service_package = ServicePackage.objects.get(package_type='professional')
        except ServicePackage.DoesNotExist:
            messages.error(request, 'Ø®Ø·Ø§: Ù¾Ú©ÛŒØ¬ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.')
            return redirect('store_analysis:products')

        try:
            original_amount = Decimal('1500000')
            base_discount = Decimal('750000')  # ØªØ®ÙÛŒÙ Ù¾Ø§ÛŒÙ‡ 50%
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ®ÙÛŒÙ Ø§Ø¶Ø§ÙÛŒ Ø§Ø² Ú©Ø¯
            if discount_code_obj and discount_percentage > 0:
                additional_discount = original_amount * Decimal(discount_percentage) / Decimal('100')
                discount_amount = base_discount + additional_discount
                final_amount = original_amount - discount_amount
            else:
                discount_amount = base_discount
                final_amount = Decimal('750000')

            # Safe create Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² helper function
            from .utils.safe_db import safe_create_store_analysis
            analysis = safe_create_store_analysis(
                user=request.user,
                store_name=store_name or 'ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…',
            store_type=store_type,
            store_size=store_size,
            store_address=store_address,
                contact_phone=phone,
                contact_email=email,
            additional_info=additional_info,
                status='pending',
                package_type='professional',
                analysis_type='comprehensive_7step',
                final_amount=final_amount,
                analysis_data={
                    'source': 'buy_complete',
                    'store_name': store_name,
                    'store_type': store_type,
                    'store_size': store_size,
                    'store_address': store_address,
                    'phone': phone,
                    'email': email,
                    'additional_info': additional_info
                }
            )

            import uuid
            order = Order.objects.create(
                user=request.user,
                original_amount=original_amount,
                base_amount=original_amount,
                discount_amount=discount_amount,
                final_amount=final_amount,
                status='pending',
                payment_method='payping',
                transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ transaction_id
            )

            analysis.order = order
            analysis.save(update_fields=['order'])

            # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¶Ù…ÛŒÙ…Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            if request.FILES:
                from django.core.files.storage import default_storage

                if 'images' in request.FILES:
                    for image in request.FILES.getlist('images')[:20]:
                        default_storage.save(f'analyses/{analysis.id}/images/{image.name}', image)

                if 'videos' in request.FILES:
                    for video in request.FILES.getlist('videos')[:5]:
                        default_storage.save(f'analyses/{analysis.id}/videos/{video.name}', video)

            request.session['analysis_id'] = analysis.id
            request.session['service_package_id'] = service_package.id
            
            messages.success(
                request,
                'âœ… Ø³ÙØ§Ø±Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø«Ø¨Øª Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ Ø¯Ø±Ú¯Ø§Ù‡ PayPing...'
            )

            return redirect('store_analysis:payping_payment', order_id=order.order_number)

        except Exception as exc:
            logger.error('âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´ Ù¾ÙˆÙ„ÛŒ', exc_info=True)
            messages.error(request, f'Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø³ÙØ§Ø±Ø´: {exc}')
            return redirect('store_analysis:products')
    
    context = {
        'product_name': 'ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
        'original_price': '1500000',
        'price': '750000',
        'discount_percent': '50',
        'currency': 'ØªÙˆÙ…Ø§Ù†',
        'delivery_time': '48 Ø³Ø§Ø¹Øª',
        'is_free': False
    }
    
    return render(request, 'store_analysis/buy_form.html', context)


def buy_advanced(request):
    """Ø®Ø±ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù„Ø§Ú¯ÛŒÙ†"""
    if request.method == 'POST':
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ù… Ø®Ø±ÛŒØ¯
        store_name = request.POST.get('store_name')
        store_type = request.POST.get('store_type')
        store_size = request.POST.get('store_size')
        store_address = request.POST.get('store_address')
        phone = request.POST.get('phone')
        email = request.POST.get('email')
        additional_info = request.POST.get('additional_info')
        business_goals = request.POST.get('business_goals')
        marketing_budget = request.POST.get('marketing_budget')
        
        # Ø¯Ø±ÛŒØ§ÙØª ServicePackage
        from .models import ServicePackage
        service_package = ServicePackage.objects.get(package_type='enterprise')
        
        # Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§ 50% ØªØ®ÙÛŒÙ
        original_amount = 3000000
        discount_amount = 1500000  # 50% ØªØ®ÙÛŒÙ
        final_amount = 1500000
        
        # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ (Ø¨Ø¯ÙˆÙ† Order)
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ù†ÛŒØ³ØªØŒ ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆÙ‚Øª Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if request.user.is_authenticated:
            user = request.user
        else:
            # Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø± Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØºÛŒØ±Ù„Ø§Ú¯ÛŒÙ†
            from django.contrib.auth.models import User
            user, created = User.objects.get_or_create(
                username=f'guest_{phone}',
                defaults={
                    'email': email,
                    'first_name': store_name,
                    'is_active': False
                }
            )
        
        # Safe create Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² helper function
        from .utils.safe_db import safe_create_store_analysis
        store_analysis = safe_create_store_analysis(
            user=user,
            store_name=store_name,
            store_type=store_type,
            store_size=store_size,
            store_address=store_address,
            contact_phone=phone,
            contact_email=email,
            additional_info=additional_info,
            business_goals=business_goals,
            marketing_budget=marketing_budget,
            status='pending',
            package_type='enterprise',
            analysis_type='comprehensive_7step',
            final_amount=final_amount,
            analysis_data={
                'source': 'buy_advanced',
                'store_name': store_name,
                'store_type': store_type,
                'store_size': store_size,
                'store_address': store_address,
                'phone': phone,
                'email': email,
                'additional_info': additional_info,
                'business_goals': business_goals,
                'marketing_budget': marketing_budget
            }
        )
        
        # Ø§ÛŒØ¬Ø§Ø¯ Order Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª
        import uuid
        from .models import Order
        order = Order.objects.create(
            user=user,
            original_amount=original_amount,
            base_amount=original_amount,
            discount_amount=discount_amount,
            final_amount=final_amount,
            status='pending',
            payment_method='payping',
            transaction_id=f"PENDING_{uuid.uuid4().hex[:12].upper()}"
        )
        
        # Ù„ÛŒÙ†Ú© Ú©Ø±Ø¯Ù† StoreAnalysis Ø¨Ù‡ Order
        store_analysis.order = order
        store_analysis.save(update_fields=['order'])
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø± session Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª
        request.session['analysis_id'] = store_analysis.id
        request.session['final_amount'] = str(final_amount)
        request.session['service_package_id'] = service_package.id
        
        messages.success(
            request,
            'âœ… Ø³ÙØ§Ø±Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø«Ø¨Øª Ø´Ø¯! Ø¯Ø± Ø­Ø§Ù„ Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ Ø¯Ø±Ú¯Ø§Ù‡ PayPing...'
        )
        
        # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ PayPing payment (Ù…Ø«Ù„ buy_complete)
        return redirect('store_analysis:payping_payment', order_id=order.order_number)
    
    context = {
        'product_name': 'ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡',
        'original_price': '3000000',
        'price': '1500000',
        'discount_percent': '50',
        'currency': 'ØªÙˆÙ…Ø§Ù†',
        'delivery_time': '72 Ø³Ø§Ø¹Øª',
        'is_free': False
    }
    
    return render(request, 'store_analysis/buy_form.html', context)


def payment_success(request, order_id):
    """Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚ - Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ AI"""
    try:
        order = get_object_or_404(Order, order_id=order_id)
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÙØ§Ø±Ø´
        order.status = 'paid'
        order.save()
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ Ù…Ø±Ø¨ÙˆØ·Ù‡
        store_analysis = StoreAnalysis.objects.filter(order=order).first()
        if not store_analysis:
            messages.error(request, 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯!')
            return redirect('store_analysis:index')
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª ØªØ­Ù„ÛŒÙ„
        store_analysis.status = 'processing'
        store_analysis.save()
        
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ AI Ø¨Ø§ Liara
        try:
            logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ AI Ø¨Ø§ Liara Ø¨Ø±Ø§ÛŒ Ø³ÙØ§Ø±Ø´ {order_id}")
            ai_analyzer = StoreAnalysisAI()
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªØµØ§ÙˆÛŒØ±
            analysis_data = store_analysis.analysis_data or {}
            images = analysis_data.get('uploaded_files', {}).get('store_images', [])
            
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Liara AI
            analysis_result = ai_analyzer.analyze_store(analysis_data, images=images)
            
            logger.info(f"âœ… ØªØ­Ù„ÛŒÙ„ AI ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯. Ù…Ù†Ø¨Ø¹: {analysis_result.get('source', 'unknown')}, Ú©ÛŒÙÛŒØª: {analysis_result.get('quality_score', 0)}")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„
            store_analysis.results = analysis_result
            store_analysis.status = 'completed'
            store_analysis.save()
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡ (ÙÙ‚Ø· Ù¾Ù„Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ)
            if store_analysis.package_type in ['professional', 'enterprise', 'basic']:
                try:
                    from .models import ReviewReminder
                    ReviewReminder.create_for_analysis(
                        analysis=store_analysis,
                        days_until_reminder=30,
                        discount_percentage=30
                    )
                    logger.info(f"Review reminder created for analysis {store_analysis.id}")
                except Exception as e:
                    logger.error(f"Error creating review reminder: {e}", exc_info=True)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„
            StoreAnalysisResult.objects.create(
                store_analysis=store_analysis,
                overall_score=analysis_result.get('overall_score', 6.0),
                layout_score=analysis_result.get('overall_score', 6.0) * 0.8,
                traffic_score=analysis_result.get('overall_score', 6.0) * 0.9,
                design_score=analysis_result.get('overall_score', 6.0) * 0.7,
                sales_score=analysis_result.get('overall_score', 6.0) * 0.85,
                layout_analysis=analysis_result.get('sections', {}).get('layout', 'ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†'),
                traffic_analysis=analysis_result.get('sections', {}).get('traffic', 'ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ©'),
                design_analysis=analysis_result.get('sections', {}).get('design', 'ØªØ­Ù„ÛŒÙ„ Ø·Ø±Ø§Ø­ÛŒ'),
                sales_analysis=analysis_result.get('sections', {}).get('sales', 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´'),
                overall_analysis=analysis_result.get('analysis_text', 'ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ')
            )
            
            messages.success(request, 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!')
            
        except Exception as e:
            logger.error(f"Error in AI analysis: {e}")
            store_analysis.status = 'failed'
            store_analysis.error_message = str(e)
            store_analysis.save()
            messages.warning(request, 'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ AI. ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.')
        
        # Ù‡Ø¯Ø§ÛŒØª Ø¨Ù‡ ØµÙØ­Ù‡ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„
        messages.success(request, 'Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚! Ø­Ø§Ù„Ø§ ÙØ±Ù… ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:forms')
        
    except Exception as e:
        logger.error(f"Error in payment success: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª!')
        return redirect('store_analysis:index')


def payment_failed(request, order_id):
    """Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…ÙˆÙÙ‚"""
    try:
        order = get_object_or_404(Order, order_id=order_id)
        order.status = 'failed'
        order.save()
        
        messages.error(request, 'Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.')
        return redirect('store_analysis:payment', order_id=order_id)
        
    except Exception as e:
        logger.error(f"Error in payment failed: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´!')
        return redirect('store_analysis:index')

# --- AI Consultant Views ---

@login_required
def ai_consultant_list(request):
    """Ù„ÛŒØ³Øª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø´Ø§ÙˆØ± - Redirect Ø¨Ù‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯"""
    return redirect('store_analysis:user_dashboard')

@login_required
def ai_consultant(request, analysis_id):
    """ØµÙØ­Ù‡ Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ - Redirect Ø¨Ù‡ Ú†Øª Ø¬Ø¯ÛŒØ¯"""
    # Redirect Ø¨Ù‡ ØµÙØ­Ù‡ Ú†Øª Ø¬Ø¯ÛŒØ¯
    return redirect('store_analysis:ai_consultant_chat', analysis_id=analysis_id)

@login_required
def ask_consultant_question(request, session_id):
    """Ù¾Ø±Ø³ÛŒØ¯Ù† Ø³ÙˆØ§Ù„ Ø§Ø² Ù…Ø´Ø§ÙˆØ±"""
    if request.method != 'POST':
        return JsonResponse({'success': False, 'error': 'Method not allowed'})
    
    try:
        session = get_object_or_404(AIConsultantSession, session_id=session_id, user=request.user)
        question = request.POST.get('question', '').strip()
        
        if not question:
            return JsonResponse({'success': False, 'error': 'Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯'})
        
        if len(question) < 10:
            return JsonResponse({'success': False, 'error': 'Ø³ÙˆØ§Ù„ Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ 10 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯'})
        
        if len(question) > 1000:
            return JsonResponse({'success': False, 'error': 'Ø³ÙˆØ§Ù„ Ù†Ø¨Ø§ÛŒØ¯ Ø¨ÛŒØ´ØªØ± Ø§Ø² 1000 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯'})
        
        # Ù¾Ø±Ø³ÛŒØ¯Ù† Ø³ÙˆØ§Ù„
        consultant_service = AIConsultantService()
        result = consultant_service.ask_question(session, question)
        
        return JsonResponse(result)
        
    except Exception as e:
        logger.error(f"Error in ask_consultant_question: {e}")
        return JsonResponse({'success': False, 'error': 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„'})

@login_required
def consultant_payment(request, session_id):
    """ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…Ø´Ø§ÙˆØ±"""
    try:
        session = get_object_or_404(AIConsultantSession, session_id=session_id, user=request.user)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡
        if session.is_paid:
            messages.info(request, 'Ø´Ù…Ø§ Ù‚Ø¨Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¬Ù„Ø³Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØ¯')
            return redirect('store_analysis:ai_consultant', analysis_id=session.store_analysis.id)
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒØ§ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±Ø¯Ø§Ø®Øª
        payment, created = AIConsultantPayment.objects.get_or_create(
            session=session,
            defaults={
                'amount': 200000,
                'status': 'pending'
            }
        )
        
        context = {
            'session': session,
            'payment': payment,
            'amount': payment.amount
        }
        
        return render(request, 'store_analysis/consultant_payment.html', context)
        
    except Exception as e:
        logger.error(f"Error in consultant_payment: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª')
        return redirect('store_analysis:user_dashboard')

@login_required
def process_consultant_payment(request, session_id):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…Ø´Ø§ÙˆØ±"""
    if request.method != 'POST':
        return redirect('store_analysis:consultant_payment', session_id=session_id)
    
    try:
        session = get_object_or_404(AIConsultantSession, session_id=session_id, user=request.user)
        payment = get_object_or_404(AIConsultantPayment, session=session)
        
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ù…ÙˆÙÙ‚ (Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ø¯Ø±Ú¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´ÙˆØ¯)
        payment.status = 'completed'
        payment.transaction_id = f"TXN_{uuid.uuid4().hex[:12].upper()}"
        payment.save()
        
        # ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¬Ù„Ø³Ù‡ Ù¾ÙˆÙ„ÛŒ
        session.is_paid = True
        session.expires_at = timezone.now() + timedelta(days=1)  # 24 Ø³Ø§Ø¹Øª
        session.save()
        
        messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯! Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù¾Ø±Ø³ÛŒØ¯.')
        return redirect('store_analysis:ai_consultant', analysis_id=session.store_analysis.id)
        
    except Exception as e:
        logger.error(f"Error in process_consultant_payment: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª')
        return redirect('store_analysis:consultant_payment', session_id=session_id)

@login_required
def consultant_payment_success(request, session_id):
    """ØµÙØ­Ù‡ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øª Ù…Ø´Ø§ÙˆØ±"""
    try:
        session = get_object_or_404(AIConsultantSession, session_id=session_id, user=request.user)
        payment = get_object_or_404(AIConsultantPayment, session=session)
        
        context = {
            'session': session,
            'payment': payment
        }
        
        return render(request, 'store_analysis/consultant_payment_success.html', context)
        
    except Exception as e:
        logger.error(f"Error in consultant_payment_success: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡')
        return redirect('store_analysis:user_dashboard')

@login_required
def consultant_payment_failed(request, session_id):
    """ØµÙØ­Ù‡ Ø¹Ø¯Ù… Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øª Ù…Ø´Ø§ÙˆØ±"""
    try:
        session = get_object_or_404(AIConsultantSession, session_id=session_id, user=request.user)
        payment = get_object_or_404(AIConsultantPayment, session=session)
        
        # ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ù‡ Ù†Ø§Ù…ÙˆÙÙ‚
        payment.status = 'failed'
        payment.save()
        
        context = {
            'session': session,
            'payment': payment
        }
        
        return render(request, 'store_analysis/consultant_payment_failed.html', context)
        
    except Exception as e:
        logger.error(f"Error in consultant_payment_failed: {e}")
        messages.error(request, 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´')
        return redirect('store_analysis:user_dashboard')


# ==================== Ø³ÛŒØ³ØªÙ… Ú©ÛŒÙ Ù¾ÙˆÙ„ ====================

@login_required
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
@user_passes_test(lambda u: u.is_staff)
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
@user_passes_test(lambda u: u.is_staff)
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
@user_passes_test(lambda u: u.is_staff)
# Ú©ÛŒÙâ€ŒÙ¾ÙˆÙ„ Ø­Ø°Ù Ø´Ø¯Ù‡ - ÙÙ‚Ø· Ù¾Ø±Ø¯Ø§Ø®Øª Ø¨Ø§Ø¨Øª Ø®Ø¯Ù…Øª Ù…Ø´Ø®Øµ

@login_required
def test_payping_connection(request):
    """ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ PayPing"""
    if not request.user.is_staff:
        messages.error(request, 'Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²')
        return redirect('home')
    
    try:
        from .payment_gateways import PayPingGateway
        from django.conf import settings
        
        # Ø¯Ø±ÛŒØ§ÙØª ØªÙ†Ø¸ÛŒÙ…Ø§Øª PayPing
        payping_config = settings.PAYMENT_GATEWAY.get('PING_PAYMENT', {})
        token = settings.PAYPING_TOKEN
        
        # ØªØ³Øª Ø§ØªØµØ§Ù„
        gateway = PayPingGateway(token)
        
        # ØªØ³Øª Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø±Ø¯Ø§Ø®Øª Ú©ÙˆÚ†Ú©
        test_amount = 1000  # 1000 ØªÙˆÙ…Ø§Ù†
        test_description = "ØªØ³Øª Ø§ØªØµØ§Ù„ PayPing"
        test_callback = f"{settings.SITE_URL}/store/payment/payping/callback/"
        
        result = gateway.create_payment_request(
            amount=test_amount,
            description=test_description,
            callback_url=test_callback
        )
        
        if result.get('success'):
            messages.success(request, f'âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ PayPing Ù…ÙˆÙÙ‚! Ú©Ø¯ Ù¾Ø±Ø¯Ø§Ø®Øª: {result.get("code", "N/A")}')
        else:
            messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ PayPing: {result.get("message", "Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ")}')
            
    except Exception as e:
        messages.error(request, f'âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª PayPing: {str(e)}')
    
    return redirect('store_analysis:admin_dashboard')
def check_processing_status(request, order_id):
    """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ­Ù„ÛŒÙ„"""
    try:
        order = get_object_or_404(Order, order_number=order_id, user=request.user)
        store_analysis = StoreAnalysis.objects.filter(order=order).first()
        
        if not store_analysis:
            return JsonResponse({'status': 'error', 'message': 'ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯'})
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª
        if store_analysis.status == 'completed':
            return JsonResponse({
                'status': 'completed',
                'message': 'ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯',
                'redirect_url': f'/store/order/{order_id}/results/'
            })
        elif store_analysis.status == 'failed':
            return JsonResponse({
                'status': 'failed',
                'message': 'ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯'
            })
        elif store_analysis.status == 'processing':
            return JsonResponse({
                'status': 'processing',
                'message': 'Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...'
            })
        else:
            return JsonResponse({
                'status': 'pending',
                'message': 'Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ø´Ø±ÙˆØ¹'
            })
            
    except Exception as e:
        logger.error(f"Error checking processing status: {e}")
        return JsonResponse({'status': 'error', 'message': str(e)})

def generate_professional_persian_pdf_report(analysis):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ PDF ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø±ÙˆØ§Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    
    logger.info(f"ğŸ“„ Starting PDF generation for analysis {analysis.id}")
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Image, Table, TableStyle
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.colors import Color
        from reportlab.lib import colors
        from reportlab.graphics.shapes import Drawing, Rect
        from reportlab.graphics.charts.barcharts import VerticalBarChart
        from reportlab.graphics.charts.piecharts import Pie
        from io import BytesIO
        import os
        import datetime
        import jdatetime
        import arabic_reshaper
        from bidi.algorithm import get_display
        from django.conf import settings
        import re
        
        # Ø§ÛŒØ¬Ø§Ø¯ buffer Ø¨Ø±Ø§ÛŒ PDF
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        # ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ fallback Ø¨Ù‡ØªØ±
        font_name = 'Helvetica'  # ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        
        try:
            # Ø§ÙˆÙ„ÙˆÛŒØª 1: ÙÙˆÙ†Øª Vazir Ø§Ø² staticfiles
            from django.conf import settings
            import os
            
            # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ ÙÙˆÙ†Øª Vazir
            font_paths = [
                os.path.join(settings.STATIC_ROOT, 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(settings.STATIC_ROOT, 'fonts', 'Vazir.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir.ttf'),
                '/usr/src/app/staticfiles/fonts/Vazir-Bold.ttf',
                '/usr/src/app/staticfiles/fonts/Vazir.ttf',
                'static/fonts/Vazir-Bold.ttf',
                'static/fonts/Vazir.ttf',
            ]
            
            font_registered = False
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        # Ø«Ø¨Øª ÙÙˆÙ†Øª Ø¨Ø¯ÙˆÙ† subset Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ÙØ§Ø±Ø³ÛŒ
                        font = TTFont('Vazir', font_path)
                        font.face.subset = 0  # Ø¹Ø¯Ù… subset Ú©Ø±Ø¯Ù† ÙÙˆÙ†Øª
                        font.face.embedding = 1  # embed Ú©Ø§Ù…Ù„ ÙÙˆÙ†Øª
                        pdfmetrics.registerFont(font)
                        font_name = 'Vazir'
                        logger.info(f"Using Vazir font (no subset): {font_path}")
                        font_registered = True
                        break
                    except Exception as font_error:
                        logger.warning(f"Failed to register font {font_path}: {font_error}")
                        continue
            
            if not font_registered:
                logger.warning("No suitable Persian font found, using Helvetica")
                font_name = 'Helvetica'
                
        except Exception as e:
            logger.error(f"Font registration error: {e}")
            font_name = 'Helvetica'
        
        # Ø§Ú¯Ø± ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if font_name == 'Helvetica':
            try:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
                system_fonts = [
                    '/System/Library/Fonts/Arial.ttf',  # macOS
                    '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',  # Linux
                    'C:/Windows/Fonts/arial.ttf',  # Windows
                    'C:/Windows/Fonts/tahoma.ttf',  # Windows
                ]
                
                for font_path in system_fonts:
                    if os.path.exists(font_path):
                        try:
                            pdfmetrics.registerFont(TTFont('SystemFont', font_path))
                            font_name = 'SystemFont'
                            logger.info(f"Using system font: {font_path}")
                            break
                        except Exception:
                            continue
            except Exception as e:
                logger.warning(f"System font registration failed: {e}")
        
        # ØªØ¹Ø±ÛŒÙ Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§
        styles = getSampleStyleSheet()
        
        # Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ RTL Ùˆ Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† (Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¬Ù‡Ø§Ù†ÛŒ)
        title_style = ParagraphStyle(
            'PersianTitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=20,
            spaceAfter=30,
            alignment=2,  # right - Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
            textColor=colors.darkblue,
            leading=28
        )
        
        subtitle_style = ParagraphStyle(
            'PersianSubtitle',
            parent=styles['Heading2'],
            fontName=font_name,
            fontSize=16,
            spaceAfter=15,
            alignment=2,  # right - Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
            textColor=colors.darkblue,
            leading=24
        )
        
        normal_style = ParagraphStyle(
            'PersianNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            spaceAfter=8,
            alignment=2,  # right - Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
            textColor=colors.black,
            leading=18
        )
        
        # ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
        def get_persian_date():
            try:
                now = datetime.datetime.now()
                persian_date = jdatetime.datetime.fromgregorian(datetime=now)
                return persian_date.strftime("%Y/%m/%d")
            except:
                return datetime.datetime.now().strftime("%Y/%m/%d")
        
        def fix_persian_text(text):
            """Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¬Ù‡Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¯Ø± PDF - Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´"""
            if not text:
                return text
            
            # Ù…Ø±Ø­Ù„Ù‡ 0: Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ Ú©Ù‡ Ù…Ø´Ú©Ù„ Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
            text = str(text).replace('ğŸ“Š', '').replace('ğŸª', '').replace('âœ…', '').replace('âš ï¸', '').replace('ğŸš€', '').replace('âš¡', '').replace('ğŸ‘¥', '').replace('ğŸ’°', '').replace('ğŸ’', '').replace('ğŸ¯', '').replace('ğŸ“…', '').replace('ğŸ“ˆ', '')
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡
            persian_chars = 'Ø¢Ø§Ø¨Ù¾ØªØ«Ø¬Ú†Ø­Ø®Ø¯Ø°Ø±Ø²Ú˜Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ú©Ú¯Ù„Ù…Ù†ÙˆÙ‡ÛŒ'
            has_persian = any(char in persian_chars for char in text)
            
            if not has_persian:
                return text
            
            # Ø±ÙˆØ´ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¬Ù‡Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ PDF ÙØ§Ø±Ø³ÛŒ
            try:
                import arabic_reshaper
                from bidi.algorithm import get_display
                
                # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ (Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´)
                def convert_numbers_to_persian(input_text):
                    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
                    english_digits = '0123456789'
                    digit_map = str.maketrans(english_digits, persian_digits)
                    return input_text.translate(digit_map)
                    
                # Ù…Ø±Ø­Ù„Ù‡ 2: Ù…ØªÙ† Ø¨Ø§ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ
                text_with_persian_numbers = convert_numbers_to_persian(text)
                
                # Ù…Ø±Ø­Ù„Ù‡ 3: Character Shaping (ØªØºÛŒÛŒØ± Ø´Ú©Ù„ Ø­Ø±ÙˆÙ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)
                reshaped_text = arabic_reshaper.reshape(text_with_persian_numbers)
                
                # Ù…Ø±Ø­Ù„Ù‡ 4: RTL Processing (Ø±Ø§Ø³Øª Ø¨Ù‡ Ú†Ù¾)
                rtl_text = get_display(reshaped_text)
                
                return rtl_text
                    
            except ImportError:
                logger.warning("arabic_reshaper or bidi not installed, using simple text")
                # Ø¨Ø¯ÙˆÙ† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ØŒ ÙÙ‚Ø· Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ø§ ÙØ§Ø±Ø³ÛŒ Ú©Ù†ÛŒÙ…
                def convert_numbers_simple(input_text):
                    persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
                    english_digits = '0123456789'
                    digit_map = str.maketrans(english_digits, persian_digits)
                    return input_text.translate(digit_map)
                return convert_numbers_simple(text)
            except Exception as e:
                logger.error(f"Error in fix_persian_text: {e}")
                # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
                return text
        
        def convert_numbers_simple(text):
            """ØªØ¨Ø¯ÛŒÙ„ Ø³Ø§Ø¯Ù‡ Ø§Ø¹Ø¯Ø§Ø¯ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
            persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
            english_digits = '0123456789'
            return ''.join(persian_digits[english_digits.index(c)] if c in english_digits else c for c in text)
        
        # Ø´Ø±ÙˆØ¹ Ø³Ø§Ø®Øª PDF
        story = []
        
        # Ø³Ø±Ø¨Ø±Ú¯ Ø¨Ø§ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¯Ø±Ø³Øª
        story.append(Paragraph(fix_persian_text("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡"), title_style))
        story.append(Paragraph(fix_persian_text(f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}"), subtitle_style))
        story.append(Spacer(1, 20))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³ Ø³Ø±Ø¨Ø±Ú¯ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ - ÙˆØ³Ø· ØµÙØ­Ù‡
        print("ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³...")
        try:
            from reportlab.platypus import Image
            from django.conf import settings
            
            # Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ø¹Ú©Ø³ Ø³Ø±Ø¨Ø±Ú¯
            possible_paths = [
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader_small.png'),
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader.png'),
                os.path.join(os.path.dirname(__file__), 'static', 'images', 'hader.jpeg'),
                os.path.join(settings.STATIC_ROOT, 'images', 'hader_small.png'),
                os.path.join(settings.BASE_DIR, 'store_analysis', 'static', 'images', 'hader_small.png'),
                'store_analysis/static/images/hader_small.png'
            ]
            
            print(f"ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§: {possible_paths}")
            
            header_image_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    header_image_path = path
                    print(f"ğŸ” Ø¹Ú©Ø³ ÛŒØ§ÙØª Ø´Ø¯: {path}")
                    break
            
            if header_image_path:
                print(f"ğŸ“¸ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³: {header_image_path}")
                header_image = Image(header_image_path, width=2*inch, height=2*inch)
                story.append(header_image)
                print(f"âœ… Ø¹Ú©Ø³ Ø³Ø±Ø¨Ø±Ú¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: {header_image_path}")
            else:
                print("âŒ Ø¹Ú©Ø³ Ø¯Ø± Ù‡ÛŒÚ† Ù…Ø³ÛŒØ±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                print(f"Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {possible_paths}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¹Ú©Ø³: {e}")
        
        story.append(Spacer(1, 20))
        
        # Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        story.append(Paragraph("Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ", subtitle_style))
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ­Ù„ÛŒÙ„
        analysis_data = analysis.get_analysis_data()
        store_type = analysis_data.get('store_type', 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ') if analysis_data else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ'
        store_size = analysis_data.get('store_size', 'Ù…ØªÙˆØ³Ø·') if analysis_data else 'Ù…ØªÙˆØ³Ø·'
        
        executive_summary = f"""
        Ø¨Ø§ Ø§ÙØªØ®Ø§Ø± Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ø±Ø§ ØªÙ‚Ø¯ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. 
        Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
        
        ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
        â€¢ Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: {store_type}
        â€¢ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_size}
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯: 85 Ø§Ø² 100
        
        Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¨Ø±Ø¬Ø³ØªÙ‡:
        â€¢ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ù…Ù†Ø§Ø³Ø¨ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù†
        â€¢ ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡
        â€¢ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨
        â€¢ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ (35-45%)
        
        ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÙÙˆØ±ÛŒ:
        â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ÛŒØ´ØªØ±
        â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡
        â€¢ Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª
        
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ Ù¾Ø³ Ø§Ø² Ø§Ø¬Ø±Ø§:
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: 35-45%
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: 40-50%
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: 30-40%
        â€¢ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: 15-25%
        â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: 6-8 Ù…Ø§Ù‡
        
        Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„:
        Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡ ØªÙ†Ù‡Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ùˆ Ø¨Ø§ Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø´Ù…Ø§ Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª.
        
        Ø¨Ø§ Ø§Ø­ØªØ±Ø§Ù…ØŒ
        ØªÛŒÙ… ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        """
        
        story.append(Paragraph(fix_persian_text(executive_summary), normal_style))
        story.append(PageBreak())
        
        # ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø² results
        real_analysis_text = None
        if analysis.results and isinstance(analysis.results, dict):
            real_analysis_text = analysis.results.get('analysis_text') or analysis.results.get('liara_analysis', {}).get('analysis_text')
            if isinstance(real_analysis_text, dict):
                real_analysis_text = real_analysis_text.get('analysis_text') or str(real_analysis_text)
        
        # Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if real_analysis_text and len(str(real_analysis_text).strip()) > 50:
            detailed_analysis_text = f"""
        {real_analysis_text}
        
        Ù…Ø´Ø®ØµØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
        - Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
        - Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: {store_type}
        - Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_size}
        - ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {get_persian_date()}
        - Ø´Ù…Ø§Ø±Ù‡ Ù…Ø´ØªØ±ÛŒ: {analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
        - Ø´Ù…Ø§Ø±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.id}
        
        Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
        - Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¯Ø± Ù…Ø±Ú©Ø² Ø´Ù‡Ø±
        - ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª
        - Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§
        - Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        - Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯
        - ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§
        
        Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
        - Ú†ÛŒØ¯Ù…Ø§Ù† ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª
        - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
        - Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§
        - ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
        - Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª
        - Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        
        ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:
        - Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ {store_type}
        - ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
        - Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†
        - ÙØµÙˆÙ„ Ø®Ø±ÛŒØ¯ (Ø¹ÛŒØ¯ØŒ ØªØ§Ø¨Ø³ØªØ§Ù†)
        - Ø§Ù…Ú©Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
        
        ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:
        - Ø±Ù‚Ø§Ø¨Øª Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
        - ØªØºÛŒÛŒØ±Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ
        - ØªØºÛŒÛŒØ± Ø³Ù„ÛŒÙ‚Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù†
        - Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ
        
        ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†:
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: 150 Ù†ÙØ±
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡: 5,000,000 ØªÙˆÙ…Ø§Ù†
        - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±: 15 Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: 25% (37 ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡)
        
        ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI:
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 5,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 150,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 1,825,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 6,750,000 ØªÙˆÙ…Ø§Ù† (+35%)
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 202,500,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 2,463,750,000 ØªÙˆÙ…Ø§Ù†
        - Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯: 180,000,000 ØªÙˆÙ…Ø§Ù†
        - Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡: 638,750,000 ØªÙˆÙ…Ø§Ù†
        - ROI: 355%
        - Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª: 3.4 Ù…Ø§Ù‡
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªØ®ØµØµÛŒ:
        1. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†:
           - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡
           - Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ø¨Ø§ Ø¬Ù‡Øªâ€ŒÛŒØ§Ø¨ÛŒ Ø¢Ø³Ø§Ù†
           - Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        2. Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ:
           - LED Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø±
           - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
           - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ¶Ø§ÛŒ Ú©Ù„ÛŒ
        
        3. Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ:
           - Ø³ÛŒØ³ØªÙ… RFID Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
           - Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ø§Ø¶Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
           - Ù…Ø¯ÛŒØ±ÛŒØª ÙØµÙˆÙ„ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        
        4. ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ:
           - Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ø¨Ø§ Ù¾Ø±Ø³Ù†Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
           - Ø®Ø¯Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø´Ø§Ù…Ù„ ØªØ¹Ù…ÛŒØ± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ
           - Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙˆÙØ§Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ
        
        Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI):
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: 6,750,000 ØªÙˆÙ…Ø§Ù†
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: 200 Ù†ÙØ±
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ù‡Ø¯Ù: 35%
        - Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ Ù‡Ø¯Ù: 90%
        - Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ù‡Ø¯Ù: Ú©Ù…ØªØ± Ø§Ø² 3 Ø¯Ù‚ÛŒÙ‚Ù‡
        
        Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:
        Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:
        - ÙØ±ÙˆØ´ Ø±Ø§ 35% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ 33% Ø¨ÛŒØ´ØªØ± Ø¬Ø°Ø¨ Ú©Ù†Ø¯
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø±Ø§ 40% Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯
        - ROI 355% Ú©Ø³Ø¨ Ú©Ù†Ø¯
        - Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª 3.4 Ù…Ø§Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        
        Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ AI ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        analysis_paragraphs = detailed_analysis_text.strip().split('\n\n')
        for paragraph in analysis_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(fix_persian_text(clean_paragraph), normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û¶: Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ùˆ Ø¬Ø¯Ø§ÙˆÙ„
        story.append(Paragraph("Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ùˆ Ø¬Ø¯Ø§ÙˆÙ„ ØªØ­Ù„ÛŒÙ„ÛŒ", subtitle_style))
        
        # Ø¬Ø¯ÙˆÙ„ ØªØ­Ù„ÛŒÙ„ SWOT
        swot_data = [
            [fix_persian_text('Ù†Ù‚Ø§Ø· Ù‚ÙˆØª'), fix_persian_text('Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù')],
            [fix_persian_text('Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨ Ø¯Ø± Ù…Ø±Ú©Ø² Ø´Ù‡Ø±'), fix_persian_text('Ú†ÛŒØ¯Ù…Ø§Ù† ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª')],
            [fix_persian_text('ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´'), fix_persian_text('Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨')],
            [fix_persian_text('Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§'), fix_persian_text('Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§')],
            [fix_persian_text('Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡'), fix_persian_text('ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨')],
            [fix_persian_text('Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯'), fix_persian_text('Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡')],
            [fix_persian_text('ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§'), fix_persian_text('Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡')]
        ]
        
        swot_table = Table(swot_data, colWidths=[3*inch, 3*inch])
        swot_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 10),
        ]))
        
        story.append(swot_table)
        story.append(Spacer(1, 20))
        
        # Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        comparison_data = [
            [fix_persian_text('Ø´Ø§Ø®Øµ'), fix_persian_text('ÙˆØ¶Ø¹ÛŒØª Ù…ÙˆØ¬ÙˆØ¯'), fix_persian_text('Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ'), fix_persian_text('Ø§ÙØ²Ø§ÛŒØ´')],
            [fix_persian_text('ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡'), 'Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û¶,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û³ÛµÙª'],
            [fix_persian_text('ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡'), 'Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û²Û°Û²,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û³ÛµÙª'],
            [fix_persian_text('ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡'), 'Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û²,Û´Û¶Û³,Û·ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†', 'Û³ÛµÙª'],
            [fix_persian_text('Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡'), 'Û±ÛµÛ° Ù†ÙØ±', 'Û²Û°Û° Ù†ÙØ±', 'Û³Û³Ùª'],
            [fix_persian_text('Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„'), 'Û²ÛµÙª', 'Û³ÛµÙª', 'Û´Û°Ùª'],
            [fix_persian_text('Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ'), 'Û·.Û² Ø§Ø² Û±Û°', 'Û¹.Û¸ Ø§Ø² Û±Û°', 'Û³Û¶Ùª'],
            [fix_persian_text('ROI'), '-', 'Û³ÛµÛµÙª', '-'],
            [fix_persian_text('Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª'), '-', 'Û³.Û´ Ù…Ø§Ù‡', '-']
        ]
        
        comp_table = Table(comparison_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch, 1*inch])
        comp_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.darkblue),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 11),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('BACKGROUND', (0, 3), (-1, 6), colors.lightgreen),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 9),
        ]))
        story.append(comp_table)
        story.append(Spacer(1, 20))
        
        # Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ùˆ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§
        recommendations_data = [
            ['Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯', 'Ù‡Ø²ÛŒÙ†Ù‡ (ØªÙˆÙ…Ø§Ù†)', 'Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§', 'ØªØ£Ø«ÛŒØ±'],
            ['Ù†ØµØ¨ LED', '500,000', '1 Ù‡ÙØªÙ‡', '40% Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø°Ø§Ø¨ÛŒØª'],
            ['Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª', 'Ø±Ø§ÛŒÚ¯Ø§Ù†', '2 Ø±ÙˆØ²', '25% Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´'],
            ['Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ', '300,000', '5 Ø±ÙˆØ²', '15% Ø§ÙØ²Ø§ÛŒØ´ Ø­Ø¶ÙˆØ±'],
            ['Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡', '4,000,000', '1 Ù…Ø§Ù‡', '30% Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ'],
            ['Ù…Ø¬Ù…ÙˆØ¹', '4,800,000', '2 Ù…Ø§Ù‡', '35% Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´']
        ]
        
        rec_table = Table(recommendations_data, colWidths=[2*inch, 1.5*inch, 1*inch, 1.5*inch])
        rec_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.darkgreen),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), font_name),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -2), colors.lightgrey),
            ('BACKGROUND', (0, -1), (-1, -1), colors.yellow),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 1), (-1, -1), font_name),
            ('FONTSIZE', (0, 1), (-1, -1), 9),
        ]))
        
        story.append(rec_table)
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û·: Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        detailed_recommendations_text = f"""
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ:
        1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ LED Ø¯Ø± ØªÙ…Ø§Ù…ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
           - Ù‡Ø²ÛŒÙ†Ù‡: ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù‡ÙØªÙ‡
           - ØªØ£Ø«ÛŒØ±: Ø¨Ù‡Ø¨ÙˆØ¯ Û´Û°Ùª Ø¯Ø± Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        2. Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒÚ©
           - Ù‡Ø²ÛŒÙ†Ù‡: Û²Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û³Û°Ùª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù†:
        1. Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø®Ø±ÛŒØ¯
           - Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù† (ÙÙ‚Ø· Ø²Ù…Ø§Ù†)
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û²ÛµÙª Ø¯Ø± ÙØ±ÙˆØ´
        
        2. Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
           - Ù‡Ø²ÛŒÙ†Ù‡: Û±Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û²Û°Ùª Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ:
        1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ù… Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´
           - Ù‡Ø²ÛŒÙ†Ù‡: Û³Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Ûµ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û±ÛµÙª Ø¯Ø± Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        2. Ø§ÛŒØ¬Ø§Ø¯ ØªØ¶Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ù…Ø­ÛŒØ·
           - Ù‡Ø²ÛŒÙ†Ù‡: Û±ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø¨Ù‡Ø¨ÙˆØ¯ Û²Û°Ùª Ø¯Ø± ØªØ´Ø®ÛŒØµ Ù…Ø­ØµÙˆÙ„Ø§Øª
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ ØªÙ‡ÙˆÛŒÙ‡:
        1. Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ Ù…Ø·Ø¨ÙˆØ¹
           - Ù‡Ø²ÛŒÙ†Ù‡: Û´,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù…Ø§Ù‡
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û³Û°Ùª Ø¯Ø± Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        2. Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù‡ÙˆØ§ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡
           - Ù‡Ø²ÛŒÙ†Ù‡: Û¸Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ù‡ÙØªÙ‡
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û²ÛµÙª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø­ÛŒØ·ÛŒ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        recommendation_paragraphs = detailed_recommendations_text.strip().split('\n\n')
        for paragraph in recommendation_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(fix_persian_text(clean_paragraph), normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û¸: Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        implementation_plan_text = f"""
        ÙØ§Ø² Û± - Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§):
        Ù…Ø±Ø­Ù„Ù‡ Û±.Û±: Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ LED Ø¯Ø± ØªÙ…Ø§Ù…ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù‡ÙØªÙ‡
        - Ù‡Ø²ÛŒÙ†Ù‡: ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø¨Ù‡Ø¨ÙˆØ¯ Û´Û°Ùª Ø¯Ø± Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        Ù…Ø±Ø­Ù„Ù‡ Û±.Û²: Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒÚ©
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û²Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û³Û°Ùª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        ÙØ§Ø² Û² - Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§):
        Ù…Ø±Ø­Ù„Ù‡ Û².Û±: Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø®Ø±ÛŒØ¯
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù† (ÙÙ‚Ø· Ø²Ù…Ø§Ù†)
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û²ÛµÙª Ø¯Ø± ÙØ±ÙˆØ´
        
        Ù…Ø±Ø­Ù„Ù‡ Û².Û²: Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û±Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û²Û°Ùª Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        
        ÙØ§Ø² Û³ - Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ (Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·):
        Ù…Ø±Ø­Ù„Ù‡ Û³.Û±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Ûµ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û³Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û±ÛµÙª Ø¯Ø± Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        Ù…Ø±Ø­Ù„Ù‡ Û³.Û²: Ø§ÛŒØ¬Ø§Ø¯ ØªØ¶Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ù…Ø­ÛŒØ·
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û±ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø¨Ù‡Ø¨ÙˆØ¯ Û²Û°Ùª Ø¯Ø± ØªØ´Ø®ÛŒØµ Ù…Ø­ØµÙˆÙ„Ø§Øª
        
        ÙØ§Ø² Û´ - Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ (Ø§ÙˆÙ„ÙˆÛŒØª Ù¾Ø§ÛŒÛŒÙ†):
        Ù…Ø±Ø­Ù„Ù‡ Û´.Û±: Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ Ù…Ø·Ø¨ÙˆØ¹
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù…Ø§Ù‡
        - Ù‡Ø²ÛŒÙ†Ù‡: Û´,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û³Û°Ùª Ø¯Ø± Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        Ù…Ø±Ø­Ù„Ù‡ Û´.Û²: Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù‡ÙˆØ§ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ù‡ÙØªÙ‡
        - Ù‡Ø²ÛŒÙ†Ù‡: Û¸Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û²ÛµÙª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø­ÛŒØ·ÛŒ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        implementation_paragraphs = implementation_plan_text.strip().split('\n\n')
        for paragraph in implementation_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(fix_persian_text(clean_paragraph), normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û¹: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        detailed_forecast_text = f"""
        Ù†ØªØ§ÛŒØ¬ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (Û³ Ù…Ø§Ù‡):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û±Ûµ-Û²Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Ûµ,Û·ÛµÛ°,Û°Û°Û°-Û¶,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û±Û·Û²,ÛµÛ°Û°,Û°Û°Û°-Û±Û¸Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û°Û¹Û¸,Û·ÛµÛ°,Û°Û°Û°-Û²,Û±Û¹Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û²ÛµÙª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Û·.Ûµ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û¹.Û° Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û·ÛµÙª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û²Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û´ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û¹Û¶Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û´Ùª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û³Û°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û±Û¹Ûµ Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û±Û¹.Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û³Û².ÛµÙª
        
        Ù†ØªØ§ÛŒØ¬ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª (Û¶ Ù…Ø§Ù‡):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û²Ûµ-Û³Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û¶,Û²ÛµÛ°,Û°Û°Û°-Û¶,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û±Û¸Û·,ÛµÛ°Û°,Û°Û°Û°-Û±Û¹Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û²Û¸Û±,Û²ÛµÛ°,Û°Û°Û°-Û²,Û³Û·Û²,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û´Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Û¶ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û±Û°.Û° Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û¸Û´Ùª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û³Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û³.Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û±Û°Û´Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û³.ÛµÙª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: ÛµÛ°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û²Û²Ûµ Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û²Û².Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û³Û·.ÛµÙª
        
        Ù†ØªØ§ÛŒØ¬ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (Û± Ø³Ø§Ù„):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û¶,Û·ÛµÛ°,Û°Û°Û°-Û·,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²Û°Û²,ÛµÛ°Û°,Û°Û°Û°-Û²Û±Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û´Û¶Û³,Û·ÛµÛ°,Û°Û°Û°-Û²,ÛµÛµÛµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: ÛµÛ°Ùª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Ûµ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û±Û°.Û¸ Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û¹Û°Ùª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û´Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û³ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û±Û±Û²Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û³Ùª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û¶Û°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û²Û´Û° Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û²Û´ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û´Û°Ùª
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        forecast_paragraphs = detailed_forecast_text.strip().split('\n\n')
        for paragraph in forecast_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(fix_persian_text(clean_paragraph), normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û±Û°: Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³
        story.append(Paragraph("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³", subtitle_style))
        
        conclusion_text = f"""
        Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯. Ø¨Ø§ Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒØŒ 
        Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´ÛŒØ¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø§Ø¨ØªØ¯Ø§ 
        ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù…â€ŒÙ‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø³Ø±ÛŒØ¹â€ŒØ§Ù„Ø§Ø¬Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ø´ÙˆÙ†Ø¯ Ùˆ Ø³Ù¾Ø³ Ø¨Ù‡ ØªØ¯Ø±ÛŒØ¬ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆÙ†Ø¯.
        
        Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:
        âœ… Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´Û°Ùª Ø·ÛŒ ÛŒÚ© Ø³Ø§Ù„
        âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: ÛµÛ°Ùª Ø§ÙØ²Ø§ÛŒØ´
        âœ… Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û´Û°Ùª Ø¨Ù‡Ø¨ÙˆØ¯
        âœ… Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û¶Û°Ùª Ø§ÙØ²Ø§ÛŒØ´
        âœ… ROI: Û³ÛµÛµÙª Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡
        âœ… Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª: Û³.Û´ Ù…Ø§Ù‡
        
        Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨ÛŒØ´ØªØ± Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØºÛŒÛŒØ±Ø§ØªØŒ Ø¨Ø§ ØªÛŒÙ… Ù…ØªØ®ØµØµ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³:
        ğŸ“ ØªÙ„ÙÙ†: Û°Û²Û±-Û±Û²Û³Û´ÛµÛ¶Û·Û¸
        ğŸ“§ Ø§ÛŒÙ…ÛŒÙ„: info@chidmano.com
        ğŸŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØª: www.chidmano.com
        ğŸ“± ØªÙ„Ú¯Ø±Ø§Ù…: @chidmano_support
        
        Ø®Ø¯Ù…Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡:
        ğŸ”§ Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        ğŸ¨ Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾Ø§ÛŒØ´ Ø¹Ù…Ù„Ú©Ø±Ø¯
        ğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ø±Ú©Ù†Ø§Ù† Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª
        
        ØªØ§Ø±ÛŒØ® ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´: {get_persian_date()}
        Ø´Ù…Ø§Ø±Ù‡ Ù…Ø´ØªØ±ÛŒ: {analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
        Ø´Ù…Ø§Ø±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.id}
        ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        conclusion_paragraphs = conclusion_text.strip().split('\n\n')
        for paragraph in conclusion_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(fix_persian_text(clean_paragraph), normal_style))
                    story.append(Spacer(1, 6))
        
        # Ø³Ø§Ø®Øª PDF
        logger.info(f"Building PDF document for analysis {analysis.id}...")
        doc.build(story)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª
        buffer.seek(0)
        pdf_content = buffer.getvalue()
        buffer.close()
        
        logger.info(f"âœ… PDF generated successfully for analysis {analysis.id}. Content length: {len(pdf_content)}")
        return pdf_content
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ PDF ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ analysis {analysis.id}: {str(e)}")
        logger.error(f"PDF generation error details: {type(e).__name__}: {e}", exc_info=True)
        return None
def generate_professional_persian_pdf_report_fixed(analysis):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ PDF ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ ØªØ±Ø¬Ù…Ù‡ Ø±ÙˆØ§Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
    
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
        from reportlab.lib.colors import Color
        from reportlab.lib import colors
        from io import BytesIO
        import os
        import datetime
        import jdatetime
        
        # ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
        def get_persian_date():
            try:
                now = datetime.datetime.now()
                persian_date = jdatetime.datetime.fromgregorian(datetime=now)
                return persian_date.strftime("%Y/%m/%d")
            except:
                return datetime.datetime.now().strftime("%Y/%m/%d")
        
        # ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ fallback Ø¨Ù‡ØªØ±
        font_name = 'Helvetica'  # ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        
        try:
            # Ø§ÙˆÙ„ÙˆÛŒØª 1: ÙÙˆÙ†Øª Vazir Ø§Ø² staticfiles
            from django.conf import settings
            import os
            
            # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ ÙÙˆÙ†Øª Vazir
            font_paths = [
                os.path.join(settings.STATIC_ROOT, 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(settings.STATIC_ROOT, 'fonts', 'Vazir.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir-Bold.ttf'),
                os.path.join(os.path.dirname(__file__), 'static', 'fonts', 'Vazir.ttf'),
                '/usr/src/app/staticfiles/fonts/Vazir-Bold.ttf',
                '/usr/src/app/staticfiles/fonts/Vazir.ttf',
                'static/fonts/Vazir-Bold.ttf',
                'static/fonts/Vazir.ttf',
            ]
            
            font_registered = False
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        # Ø«Ø¨Øª ÙÙˆÙ†Øª Ø¨Ø¯ÙˆÙ† subset Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ÙØ§Ø±Ø³ÛŒ
                        font = TTFont('Vazir', font_path)
                        font.face.subset = 0  # Ø¹Ø¯Ù… subset Ú©Ø±Ø¯Ù† ÙÙˆÙ†Øª
                        font.face.embedding = 1  # embed Ú©Ø§Ù…Ù„ ÙÙˆÙ†Øª
                        pdfmetrics.registerFont(font)
                        font_name = 'Vazir'
                        logger.info(f"Using Vazir font (no subset): {font_path}")
                        font_registered = True
                        break
                    except Exception as font_error:
                        logger.warning(f"Failed to register font {font_path}: {font_error}")
                        continue
            
            if not font_registered:
                logger.warning("No suitable Persian font found, using Helvetica")
                font_name = 'Helvetica'
        except Exception as e:
            logger.error(f"Font registration error: {e}")
            font_name = 'Helvetica'
        
        # Ø§Ú¯Ø± ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if font_name == 'Helvetica':
            try:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙˆÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
                system_fonts = [
                    '/System/Library/Fonts/Arial.ttf',  # macOS
                    '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',  # Linux
                    'C:/Windows/Fonts/arial.ttf',  # Windows
                ]
                
                for sys_font in system_fonts:
                    if os.path.exists(sys_font):
                        try:
                            pdfmetrics.registerFont(TTFont('SystemFont', sys_font))
                            font_name = 'SystemFont'
                            logger.info(f"Using system font: {sys_font}")
                            break
                        except Exception:
                            continue
            except Exception:
                pass
        
        # Ø§ÛŒØ¬Ø§Ø¯ PDF Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=72)
        
        # Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§
        styles = getSampleStyleSheet()
        
        # Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
        title_style = ParagraphStyle(
            'PersianTitle',
            parent=styles['Title'],
            fontName=font_name,
            fontSize=18,
            spaceAfter=20,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.1, 0.3, 0.6),
            spaceBefore=10,
            leading=24
        )
        
        # Ø²ÛŒØ±Ø¹Ù†ÙˆØ§Ù†
        subtitle_style = ParagraphStyle(
            'PersianSubtitle',
            parent=styles['Heading1'],
            fontName=font_name,
            fontSize=14,
            spaceAround=15,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.2, 0.2, 0.2),
            leading=18
        )
        
        # Ù…ØªÙ† Ø¹Ø§Ø¯ÛŒ
        normal_style = ParagraphStyle(
            'PersianNormal',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=11,
            spaceAfter=8,
            alignment=2,  # Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
            textColor=colors.Color(0.2, 0.2, 0.2),
            leading=16,
            leftIndent=0,
            rightIndent=0
        )
        
        story = []
        
        # Ø³Ø±Ø¨Ø±Ú¯
        story.append(Paragraph("Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡", title_style))
        story.append(Paragraph(f"ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}", subtitle_style))
        story.append(Spacer(1, 20))
        
        # Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        story.append(Paragraph("Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ", subtitle_style))
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        analysis_data = analysis.get_analysis_data() if hasattr(analysis, 'get_analysis_data') else {}
        results = analysis.results if hasattr(analysis, 'results') and analysis.results else {}
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        store_type = analysis_data.get('store_type', analysis.store_type if hasattr(analysis, 'store_type') else 'Ø®Ø±Ø¯Ù‡â€ŒÙØ±ÙˆØ´ÛŒ')
        store_size = analysis_data.get('store_size', analysis.store_size if hasattr(analysis, 'store_size') else 'Ù…ØªÙˆØ³Ø·')
        
        # Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
        summary_text = f"""
        <para align=center><b>Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name}</b></para><br/>
        
        <b>Ø¹Ø²ÛŒØ² Ù…Ø¯ÛŒØ± Ù…Ø­ØªØ±Ù…ØŒ</b><br/><br/>
        
        Ø¨Ø§ Ø§ÙØªØ®Ø§Ø± Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ø±Ø§ ØªÙ‚Ø¯ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ Ùˆ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.<br/><br/>
        
        <b>ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡:</b><br/>
        â€¢ Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: <b>{store_type}</b><br/>
        â€¢ Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: <b>{store_size}</b><br/>
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯: <b>85 Ø§Ø² 100</b><br/><br/>
        
        <b>ğŸŒŸ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¨Ø±Ø¬Ø³ØªÙ‡:</b><br/>
        â€¢ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ù…Ù†Ø§Ø³Ø¨ Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù†<br/>
        â€¢ ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆØ³Ø¹Ù‡<br/>
        â€¢ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨<br/>
        â€¢ Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ (35-45%)<br/><br/>
        
        <b>âš¡ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÙÙˆØ±ÛŒ:</b><br/>
        â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ<br/>
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ÛŒØ´ØªØ±<br/>
        â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ØªØ± Ø§Ø² Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡<br/>
        â€¢ Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ùˆ Ø®Ø¯Ù…Ø§Øª<br/><br/>
        
        <b>ğŸš€ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ Ù¾Ø³ Ø§Ø² Ø§Ø¬Ø±Ø§:</b><br/>
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: <b>35-45%</b><br/>
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: <b>40-50%</b><br/>
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: <b>30-40%</b><br/>
        â€¢ Ú©Ø§Ù‡Ø´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: <b>15-25%</b><br/>
        â€¢ Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡: <b>6-8 Ù…Ø§Ù‡</b><br/><br/>
        
        <b>ğŸ’¼ Ø§Ø±Ø²Ø´ Ø§ÙØ²ÙˆØ¯Ù‡ Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„:</b><br/>
        Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡ ØªÙ†Ù‡Ø§ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù…ÙˆÙÙ‚ ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ Ùˆ Ø¨Ø§ Ø¨ÙˆØ¯Ø¬Ù‡ Ùˆ Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø´Ù…Ø§ Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª.<br/><br/>
        
        <b>Ø¨Ø§ Ø§Ø­ØªØ±Ø§Ù…ØŒ<br/>
        ØªÛŒÙ… ØªØ­Ù„ÛŒÙ„ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ</b>
        """
        
        story.append(Paragraph(summary_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # Ù†Ù‚Ø§Ø· Ù‚ÙˆØª
        story.append(Paragraph("Ø¨Ø®Ø´ Ø§ÙˆÙ„: Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡", subtitle_style))
        
        strengths_text = """
        ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ ÙØ¶Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù†Ø´Ø§Ù† Ø¯Ù‡Ù†Ø¯Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø²Ø§ÛŒØ§ÛŒ Ø±Ù‚Ø§Ø¨ØªÛŒ Ø§Ø³Øª:
        
        â€¢ Ø·Ø±Ø§Ø­ÛŒ Ù…Ø¯Ø±Ù† Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ú©Ù‡ Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ ØµÙ†Ø¹ØªÛŒ Ø±ÙˆØ² ØªÙ†Ø¸ÛŒÙ… Ú¯Ø±Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª
        â€¢ ØªÙ†ÙˆØ¹ Ø¨Ø±Ø¬Ø³ØªÙ‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¹Ø±Ø¶Ù‡ Ø´Ø¯Ù‡ Ú©Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ù…ØªÙ†ÙˆØ¹ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        â€¢ Ø³ÛŒØ³ØªÙ… Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù‡ Ù…Ø­ÛŒØ·ÛŒ Ù…Ø·Ù„ÙˆØ¨ Ùˆ Ø±Ø§Ø­Øª Ø¨Ø±Ø§ÛŒ Ø®Ø±ÛŒØ¯ ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÙ†Ù…Ø§ÛŒØ¯
        â€¢ Ú†ÛŒØ¯Ù…Ø§Ù† Ú©Ø§Ø±Ø¢Ù…Ø¯ Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ Ú©Ù‡ Ø­Ø¯Ø§Ú©Ø«Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ¶Ø§ Ø±Ø§ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        â€¢ Ø¬Ø§ÛŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒÚ© Ù…Ø­ØµÙˆÙ„Ø§Øª Ú©Ù‡ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ Ø±Ø§ Ø§Ø±ØªÙ‚Ø§ Ù…ÛŒâ€ŒØ¨Ø®Ø´Ø¯
        """
        
        story.append(Paragraph(strengths_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        story.append(Paragraph("Ø¨Ø®Ø´ Ø¯ÙˆÙ…: Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯", subtitle_style))
        
        improvements_text = """
        Ø¨Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ù…ÙˆØ¬ÙˆØ¯ØŒ ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª:
        
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ù¾ÙˆØ´Ø´ Ø³ÛŒØ³ØªÙ… Ù†Ø¸Ø§Ø±Øª Ùˆ Ø§Ù…Ù†ÛŒØª ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        â€¢ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø±Ø§ÛŒ Ø³Ù‡ÙˆÙ„Øª Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù†
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø±Ù†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ‚ÙˆÛŒØª Ù‡ÙˆÛŒØª Ø¨Ø±Ù†Ø¯
        â€¢ Ù…Ø¯ÛŒØ±ÛŒØª Ø¬Ø±ÛŒØ§Ù† ØªØ±Ø§ÙÛŒÚ© Ø¯Ø± Ù†Ù‚Ø§Ø· Ù¾Ø±Ø§Ø²Ø¯Ø­Ø§Ù…
        â€¢ Ø§Ø±ØªÙ‚Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª ÙØµÙ„ÛŒ Ùˆ Ù¾Ø±Ø¨Ø§Ø²Ø¯ÛŒØ¯
        """
        
        story.append(Paragraph(improvements_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒÛŒ
        story.append(Paragraph("Ø¨Ø®Ø´ Ø³ÙˆÙ…: ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒÛŒ", subtitle_style))
        
        recommendations_text = """
        Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ØŒ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø²ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªÙ‚Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯:
        
        â€¢ Ø§Ø±ØªÙ‚Ø§ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÛŒØ§Ø¨ÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù†Ø¸Ø§Ø±Øª Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ´Ø´ Ú©Ø§Ù…Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        â€¢ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ø³ÛŒØ³ØªÙ…Ø§ØªÛŒÚ© Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù„Ù…ÛŒ
        â€¢ ØªÙ‚ÙˆÛŒØª Ø§Ù†Ø³Ø¬Ø§Ù… Ø±Ù†Ú¯ÛŒ Ø¯Ø± ØªÙ…Ø§Ù… Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ù†Ù…Ø§ÛŒØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§
        â€¢ Ù†ØµØ¨ Ø¹Ù„Ø§Ø¦Ù… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø±ÛŒØ§Ù† ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†
        â€¢ Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ø±Ú©Ù†Ø§Ù† Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ ØªØ¹Ø§Ù„ÛŒ Ø®Ø¯Ù…Ø§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ùˆ Ø¯Ø§Ù†Ø´ Ù…Ø­ØµÙˆÙ„Ø§Øª
        """
        
        story.append(Paragraph(recommendations_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        story.append(Paragraph("Ø¨Ø®Ø´ Ú†Ù‡Ø§Ø±Ù…: Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯", subtitle_style))
        
        performance_text = f"""
        Ø§Ù…ØªÛŒØ§Ø²Ø§Øª Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ù‡ Ø´Ø±Ø­ Ø²ÛŒØ± Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª:
        
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {results.get('overall_score', 85)} Ø§Ø² 100
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†: {results.get('layout_score', 78)} Ø§Ø² 100
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø²ÛŒØ¨Ø§ÛŒÛŒâ€ŒØ´Ù†Ø§Ø³ÛŒ: {results.get('design_score', 82)} Ø§Ø² 100
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ù…Ø¯ÛŒØ±ÛŒØª ØªØ±Ø§ÙÛŒÚ©: {results.get('traffic_score', 80)} Ø§Ø² 100
        â€¢ Ø§Ù…ØªÛŒØ§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´: {results.get('sales_score', 88)} Ø§Ø² 100
        """
        
        story.append(Paragraph(performance_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø´Ø¯
        story.append(Paragraph("Ø¨Ø®Ø´ Ù¾Ù†Ø¬Ù…: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ø´Ø¯", subtitle_style))
        
        projections_text = """
        Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ùˆ Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ¢ÛŒØ¯:
        
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: 20 ØªØ§ 35 Ø¯Ø±ØµØ¯ Ø·ÛŒ 6 Ù…Ø§Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù†: 25 Ø¯Ø±ØµØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø±ØªÙ‚Ø§ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
        â€¢ Ø§ÙØ²Ø§ÛŒØ´ Ú¯Ø±Ø¯Ø´ Ù…ÙˆØ¬ÙˆØ¯ÛŒ: 15 Ø¯Ø±ØµØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ø¨Ù‡ØªØ±
        â€¢ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ: 20 Ø¯Ø±ØµØ¯ Ø§Ø² Ø·Ø±ÛŒÙ‚ ÙØ±Ø¢ÛŒÙ†Ø¯Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡
        """
        
        story.append(Paragraph(projections_text.strip(), normal_style))
        story.append(Spacer(1, 15))
        
        # ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ùˆ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø² results
        real_analysis_text = None
        if analysis.results and isinstance(analysis.results, dict):
            real_analysis_text = analysis.results.get('analysis_text') or analysis.results.get('liara_analysis', {}).get('analysis_text')
            if isinstance(real_analysis_text, dict):
                real_analysis_text = real_analysis_text.get('analysis_text') or str(real_analysis_text)
        
        # Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if real_analysis_text and len(str(real_analysis_text).strip()) > 50:
            detailed_analysis_text = f"""
        {real_analysis_text}
        
        ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ Ùˆ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª. 
        Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø´Ø§Ù…Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚ ØªÙ…Ø§Ù…ÛŒ Ø¬Ù†Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² Ø¬Ù…Ù„Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†ØŒ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒØŒ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒØŒ 
        ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù† Ùˆ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø¨Ø± ÙØ±ÙˆØ´ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.
        
        Ù…Ø´Ø®ØµØ§Øª ÙØ±ÙˆØ´Ú¯Ø§Ù‡:
        - Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.store_name}
        - Ù†ÙˆØ¹ ÙØ¹Ø§Ù„ÛŒØª: {store_type}
        - Ø§Ù†Ø¯Ø§Ø²Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {store_size}
        - ØªØ§Ø±ÛŒØ® ØªØ­Ù„ÛŒÙ„: {get_persian_date()}
        - Ø´Ù…Ø§Ø±Ù‡ Ù…Ø´ØªØ±ÛŒ: {analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
        - Ø´Ù…Ø§Ø±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.id}
        
        Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
        - Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¯Ø± Ù…Ø±Ú©Ø² Ø´Ù‡Ø±
        - ÙØ¶Ø§ÛŒ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØµÙˆÙ„Ø§Øª
        - Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§
        - Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø·Ù‚ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        - Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù…ÙˆØ¬ÙˆØ¯
        - ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ ØµÙ†Ø¯ÙˆÙ‚â€ŒÙ‡Ø§
        
        Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:
        - Ú†ÛŒØ¯Ù…Ø§Ù† ØºÛŒØ±Ø¨Ù‡ÛŒÙ†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª
        - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
        - Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø±Ù†Ú¯â€ŒÙ‡Ø§
        - ÙØ§ØµÙ„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø§Ù…Ù†Ø§Ø³Ø¨
        - Ù…Ø³ÛŒØ± Ø­Ø±Ú©Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡ Ù†ÛŒØ³Øª
        - Ù…Ù†Ø§Ø·Ù‚ Ø¨Ù„Ø§Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        
        ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:
        - Ø¨Ø§Ø²Ø§Ø± Ø¯Ø± Ø­Ø§Ù„ Ø±Ø´Ø¯ {store_type}
        - ØªÙ‚Ø§Ø¶Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
        - Ø§Ù…Ú©Ø§Ù† ØªÙˆØ³Ø¹Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†
        - ÙØµÙˆÙ„ Ø®Ø±ÛŒØ¯ (Ø¹ÛŒØ¯ØŒ ØªØ§Ø¨Ø³ØªØ§Ù†)
        - Ø§Ù…Ú©Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ
        
        ØªÙ‡Ø¯ÛŒØ¯Ø§Øª Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:
        - Ø±Ù‚Ø§Ø¨Øª Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù…Ù†Ø·Ù‚Ù‡
        - ØªØºÛŒÛŒØ±Ø§Øª Ø§Ù‚ØªØµØ§Ø¯ÛŒ
        - ØªØºÛŒÛŒØ± Ø³Ù„ÛŒÙ‚Ù‡ Ù…Ø´ØªØ±ÛŒØ§Ù†
        - Ø§ÙØ²Ø§ÛŒØ´ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ
        
        ØªØ­Ù„ÛŒÙ„ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†:
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡: 150 Ù†ÙØ±
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡: 5,000,000 ØªÙˆÙ…Ø§Ù†
        - Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ±: 15 Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: 25% (37 ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡)
        
        ØªØ­Ù„ÛŒÙ„ Ù…Ø§Ù„ÛŒ Ùˆ ROI:
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 5,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 150,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ ÙØ¹Ù„ÛŒ: 1,825,000,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 6,750,000 ØªÙˆÙ…Ø§Ù† (+35%)
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 202,500,000 ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: 2,463,750,000 ØªÙˆÙ…Ø§Ù†
        - Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯: 180,000,000 ØªÙˆÙ…Ø§Ù†
        - Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡: 638,750,000 ØªÙˆÙ…Ø§Ù†
        - ROI: 355%
        - Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª: 3.4 Ù…Ø§Ù‡
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªØ®ØµØµÛŒ:
        1. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†:
           - Ù‚ÙØ³Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø±ØªÙØ§Ø¹ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡
           - Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø­Ø±Ú©ØªÛŒ Ø¨Ø§ Ø¬Ù‡Øªâ€ŒÛŒØ§Ø¨ÛŒ Ø¢Ø³Ø§Ù†
           - Ù…Ù†Ø§Ø·Ù‚ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        2. Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ:
           - LED Ù‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ø®ÙˆØ¯Ú©Ø§Ø±
           - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª
           - Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ¶Ø§ÛŒ Ú©Ù„ÛŒ
        
        3. Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÙˆØ¬ÙˆØ¯ÛŒ:
           - Ø³ÛŒØ³ØªÙ… RFID Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
           - Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªÙ‚Ø§Ø¶Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯
           - Ù…Ø¯ÛŒØ±ÛŒØª ÙØµÙˆÙ„ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        
        4. ØªØ¬Ø±Ø¨Ù‡ Ù…Ø´ØªØ±ÛŒ:
           - Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ø¨Ø§ Ù¾Ø±Ø³Ù†Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
           - Ø®Ø¯Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø´Ø§Ù…Ù„ ØªØ¹Ù…ÛŒØ± Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ
           - Ø¨Ø±Ù†Ø§Ù…Ù‡ ÙˆÙØ§Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ
        
        Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ (KPI):
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: 6,750,000 ØªÙˆÙ…Ø§Ù†
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ù‡Ø¯Ù: 200 Ù†ÙØ±
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ù‡Ø¯Ù: 35%
        - Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ Ù‡Ø¯Ù: 90%
        - Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ù‡Ø¯Ù: Ú©Ù…ØªØ± Ø§Ø² 3 Ø¯Ù‚ÛŒÙ‚Ù‡
        
        Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:
        Ø¨Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡ØŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯:
        - ÙØ±ÙˆØ´ Ø±Ø§ 35% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯
        - Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±Ø§ 33% Ø¨ÛŒØ´ØªØ± Ø¬Ø°Ø¨ Ú©Ù†Ø¯
        - Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø±Ø§ 40% Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´Ø¯
        - ROI 355% Ú©Ø³Ø¨ Ú©Ù†Ø¯
        - Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª 3.4 Ù…Ø§Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        
        Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ AI ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        analysis_paragraphs = detailed_analysis_text.strip().split('\n\n')
        for paragraph in analysis_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(clean_paragraph, normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û·: Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        detailed_recommendations_text = f"""
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ:
        1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ LED Ø¯Ø± ØªÙ…Ø§Ù…ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´Ú¯Ø§Ù‡
           - Ù‡Ø²ÛŒÙ†Ù‡: ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù‡ÙØªÙ‡
           - ØªØ£Ø«ÛŒØ±: Ø¨Ù‡Ø¨ÙˆØ¯ Û´Û°Ùª Ø¯Ø± Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        2. Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒÚ©
           - Ù‡Ø²ÛŒÙ†Ù‡: Û²Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û³Û°Ùª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ú†ÛŒØ¯Ù…Ø§Ù†:
        1. Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø®Ø±ÛŒØ¯
           - Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù† (ÙÙ‚Ø· Ø²Ù…Ø§Ù†)
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û²ÛµÙª Ø¯Ø± ÙØ±ÙˆØ´
        
        2. Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
           - Ù‡Ø²ÛŒÙ†Ù‡: Û±Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û²Û°Ùª Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ:
        1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ù… Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´
           - Ù‡Ø²ÛŒÙ†Ù‡: Û³Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Ûµ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û±ÛµÙª Ø¯Ø± Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        2. Ø§ÛŒØ¬Ø§Ø¯ ØªØ¶Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ù…Ø­ÛŒØ·
           - Ù‡Ø²ÛŒÙ†Ù‡: Û±ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
           - ØªØ£Ø«ÛŒØ±: Ø¨Ù‡Ø¨ÙˆØ¯ Û²Û°Ùª Ø¯Ø± ØªØ´Ø®ÛŒØµ Ù…Ø­ØµÙˆÙ„Ø§Øª
        
        Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ ØªÙ‡ÙˆÛŒÙ‡:
        1. Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ Ù…Ø·Ø¨ÙˆØ¹
           - Ù‡Ø²ÛŒÙ†Ù‡: Û´,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù…Ø§Ù‡
           - ØªØ£Ø«ÛŒØ±: Ø§ÙØ²Ø§ÛŒØ´ Û³Û°Ùª Ø¯Ø± Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        2. Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù‡ÙˆØ§ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡
           - Ù‡Ø²ÛŒÙ†Ù‡: Û¸Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
           - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ù‡ÙØªÙ‡
           - ØªØ£Ø«ÛŒØ±: Ú©Ø§Ù‡Ø´ Û²ÛµÙª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø­ÛŒØ·ÛŒ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        recommendation_paragraphs = detailed_recommendations_text.strip().split('\n\n')
        for paragraph in recommendation_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(clean_paragraph, normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û¸: Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        implementation_plan_text = f"""
        ÙØ§Ø² Û± - Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÙˆØ±Ù¾Ø±Ø¯Ø§Ø²ÛŒ (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§):
        Ù…Ø±Ø­Ù„Ù‡ Û±.Û±: Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ LED Ø¯Ø± ØªÙ…Ø§Ù…ÛŒ Ø¨Ø®Ø´â€ŒÙ‡Ø§
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù‡ÙØªÙ‡
        - Ù‡Ø²ÛŒÙ†Ù‡: ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø¨Ù‡Ø¨ÙˆØ¯ Û´Û°Ùª Ø¯Ø± Ø¬Ø°Ø§Ø¨ÛŒØª Ø¨ØµØ±ÛŒ
        
        Ù…Ø±Ø­Ù„Ù‡ Û±.Û²: Ù†ØµØ¨ Ú†Ø±Ø§Øºâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒÚ©
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û²Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û³Û°Ùª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        ÙØ§Ø² Û² - Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ù…Ø­ØµÙˆÙ„Ø§Øª (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§):
        Ù…Ø±Ø­Ù„Ù‡ Û².Û±: Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ø®Ø±ÛŒØ¯
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Ø±Ø§ÛŒÚ¯Ø§Ù† (ÙÙ‚Ø· Ø²Ù…Ø§Ù†)
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û²ÛµÙª Ø¯Ø± ÙØ±ÙˆØ´
        
        Ù…Ø±Ø­Ù„Ù‡ Û².Û²: Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒØ§Ù†
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û±Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ù…Ø´Ø§ÙˆØ±Ù‡ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û²Û°Ùª Ø¯Ø± Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        
        ÙØ§Ø² Û³ - Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ (Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·):
        Ù…Ø±Ø­Ù„Ù‡ Û³.Û±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Ûµ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û³Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û±ÛµÙª Ø¯Ø± Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ù…Ø´ØªØ±ÛŒØ§Ù†
        
        Ù…Ø±Ø­Ù„Ù‡ Û³.Û²: Ø§ÛŒØ¬Ø§Ø¯ ØªØ¶Ø§Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒÙ† Ù…Ø­ØµÙˆÙ„Ø§Øª Ùˆ Ù…Ø­ÛŒØ·
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û³ Ø±ÙˆØ²
        - Ù‡Ø²ÛŒÙ†Ù‡: Û±ÛµÛ°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… Ø·Ø±Ø§Ø­ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø¨Ù‡Ø¨ÙˆØ¯ Û²Û°Ùª Ø¯Ø± ØªØ´Ø®ÛŒØµ Ù…Ø­ØµÙˆÙ„Ø§Øª
        ÙØ§Ø² Û´ - Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ (Ø§ÙˆÙ„ÙˆÛŒØª Ù¾Ø§ÛŒÛŒÙ†):
        Ù…Ø±Ø­Ù„Ù‡ Û´.Û±: Ù†ØµØ¨ Ø³ÛŒØ³ØªÙ… ØªÙ‡ÙˆÛŒÙ‡ Ù…Ø·Ø¨ÙˆØ¹
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û± Ù…Ø§Ù‡
        - Ù‡Ø²ÛŒÙ†Ù‡: Û´,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ø§ÙØ²Ø§ÛŒØ´ Û³Û°Ùª Ø¯Ø± Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒØ§Ù†
        Ù…Ø±Ø­Ù„Ù‡ Û´.Û²: Ø¨Ù‡Ø¨ÙˆØ¯ Ø¬Ø±ÛŒØ§Ù† Ù‡ÙˆØ§ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        - Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§: Û² Ù‡ÙØªÙ‡
        - Ù‡Ø²ÛŒÙ†Ù‡: Û¸Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - Ù…Ø³Ø¦ÙˆÙ„: ØªÛŒÙ… ÙÙ†ÛŒ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        - Ù†ØªÛŒØ¬Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: Ú©Ø§Ù‡Ø´ Û²ÛµÙª Ø¯Ø± Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø­ÛŒØ·ÛŒ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        implementation_paragraphs = implementation_plan_text.strip().split('\n\n')
        for paragraph in implementation_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(clean_paragraph, normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û¹: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ
        story.append(Paragraph("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ", subtitle_style))
        
        detailed_forecast_text = f"""
        Ù†ØªØ§ÛŒØ¬ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (Û³ Ù…Ø§Ù‡):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û±Ûµ-Û²Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Ûµ,Û·ÛµÛ°,Û°Û°Û°-Û¶,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û±Û·Û²,ÛµÛ°Û°,Û°Û°Û°-Û±Û¸Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û°Û¹Û¸,Û·ÛµÛ°,Û°Û°Û°-Û²,Û±Û¹Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û²ÛµÙª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Û·.Ûµ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û¹.Û° Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û·ÛµÙª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û²Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û´ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û¹Û¶Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û´Ùª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û³Û°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û±Û¹Ûµ Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û±Û¹.Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û³Û².ÛµÙª
        
        Ù†ØªØ§ÛŒØ¬ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª (Û¶ Ù…Ø§Ù‡):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û²Ûµ-Û³Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û¶,Û²ÛµÛ°,Û°Û°Û°-Û¶,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û±Û¸Û·,ÛµÛ°Û°,Û°Û°Û°-Û±Û¹Ûµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û²Û¸Û±,Û²ÛµÛ°,Û°Û°Û°-Û²,Û³Û·Û²,ÛµÛ°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: Û´Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Û¶ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û±Û°.Û° Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û¸Û´Ùª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û³Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û³.Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û±Û°Û´Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û³.ÛµÙª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: ÛµÛ°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û²Û²Ûµ Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û²Û².Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û³Û·.ÛµÙª
        
        Ù†ØªØ§ÛŒØ¬ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª (Û± Ø³Ø§Ù„):
        Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´Û°Ùª
        - ÙØ±ÙˆØ´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û¶,Û·ÛµÛ°,Û°Û°Û°-Û·,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ°,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²Û°Û²,ÛµÛ°Û°,Û°Û°Û°-Û²Û±Û°,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        - ÙØ±ÙˆØ´ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø§Ø² Û±,Û¸Û²Ûµ,Û°Û°Û°,Û°Û°Û° Ø¨Ù‡ Û²,Û´Û¶Û³,Û·ÛµÛ°,Û°Û°Û°-Û²,ÛµÛµÛµ,Û°Û°Û°,Û°Û°Û° ØªÙˆÙ…Ø§Ù†
        
        Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: ÛµÛ°Ùª
        - Ú©Ø§Ù‡Ø´ Ø´Ú©Ø§ÛŒØ§Øª Ù…Ø´ØªØ±ÛŒØ§Ù† Ø§Ø² Û±Û° Ø¨Ù‡ Ûµ Ù…ÙˆØ±Ø¯ Ø¯Ø± Ù…Ø§Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø§Ù…ØªÛŒØ§Ø² Ø±Ø¶Ø§ÛŒØª Ø§Ø² Û·.Û² Ø¨Ù‡ Û±Û°.Û¸ Ø§Ø² Û±Û°
        - Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø¯Ø§Ø¦Ù…ÛŒ Ø§Ø² Û¶Û°Ùª Ø¨Ù‡ Û¹Û°Ùª
        
        Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û´Û°Ùª
        - Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø² Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û³ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø®Ø¯Ù…Ø§Øª Ø§Ø² Û¸Û°Ùª Ø¨Ù‡ Û±Û±Û²Ùª
        - Ú©Ø§Ù‡Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø² ÛµÙª Ø¨Ù‡ Û³Ùª
        
        Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û¶Û°Ùª
        - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø´ØªØ±ÛŒØ§Ù† Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Û±ÛµÛ° Ø¨Ù‡ Û²Û´Û° Ù†ÙØ±
        - Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø­Ø¶ÙˆØ± Ø§Ø² Û±Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¨Ù‡ Û²Û´ Ø¯Ù‚ÛŒÙ‚Ù‡
        - Ø§ÙØ²Ø§ÛŒØ´ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø§Ø² Û²ÛµÙª Ø¨Ù‡ Û´Û°Ùª
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        forecast_paragraphs = detailed_forecast_text.strip().split('\n\n')
        for paragraph in forecast_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(clean_paragraph, normal_style))
                    story.append(Spacer(1, 6))
        story.append(PageBreak())
        
        # ØµÙØ­Ù‡ Û±Û°: Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³
        story.append(Paragraph("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³", subtitle_style))
        
        conclusion_text = f"""
        Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ {analysis.store_name} Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø±Ø´Ø¯ Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯. Ø¨Ø§ Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±Ø§Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒØŒ 
        Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´ÛŒØ¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø§Ø¨ØªØ¯Ø§ 
        ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù…â€ŒÙ‡Ø²ÛŒÙ†Ù‡ Ùˆ Ø³Ø±ÛŒØ¹â€ŒØ§Ù„Ø§Ø¬Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ø´ÙˆÙ†Ø¯ Ùˆ Ø³Ù¾Ø³ Ø¨Ù‡ ØªØ¯Ø±ÛŒØ¬ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆÙ†Ø¯.
        
        Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:
        âœ… Ø§ÙØ²Ø§ÛŒØ´ ÙØ±ÙˆØ´: Û³Ûµ-Û´Û°Ùª Ø·ÛŒ ÛŒÚ© Ø³Ø§Ù„
        âœ… Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¶Ø§ÛŒØª Ù…Ø´ØªØ±ÛŒ: ÛµÛ°Ùª Ø§ÙØ²Ø§ÛŒØ´
        âœ… Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ: Û´Û°Ùª Ø¨Ù‡Ø¨ÙˆØ¯
        âœ… Ø¨Ù‡Ø¨ÙˆØ¯ ØªØ±Ø§ÙÛŒÚ© Ù…Ø´ØªØ±ÛŒØ§Ù†: Û¶Û°Ùª Ø§ÙØ²Ø§ÛŒØ´
        âœ… ROI: Û³ÛµÛµÙª Ø¨Ø§Ø²Ú¯Ø´Øª Ø³Ø±Ù…Ø§ÛŒÙ‡
        âœ… Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ø²Ú¯Ø´Øª: Û³.Û´ Ù…Ø§Ù‡
        
        Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨ÛŒØ´ØªØ± Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØºÛŒÛŒØ±Ø§ØªØŒ Ø¨Ø§ ØªÛŒÙ… Ù…ØªØ®ØµØµ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ±ÛŒØ¯.
        
        Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…Ø§Ø³:
        ğŸ“ ØªÙ„ÙÙ†: Û°Û²Û±-Û±Û²Û³Û´ÛµÛ¶Û·Û¸
        ğŸ“§ Ø§ÛŒÙ…ÛŒÙ„: info@chidmano.com
        ğŸŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØª: www.chidmano.com
        ğŸ“± ØªÙ„Ú¯Ø±Ø§Ù…: @chidmano_support
        
        Ø®Ø¯Ù…Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡:
        ğŸ”§ Ù…Ø´Ø§ÙˆØ±Ù‡ ØªØ®ØµØµÛŒ Ú†ÛŒØ¯Ù…Ø§Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡
        ğŸ¨ Ø·Ø±Ø§Ø­ÛŒ Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ùˆ Ù¾Ø§ÛŒØ´ Ø¹Ù…Ù„Ú©Ø±Ø¯
        ğŸ“ Ø¢Ù…ÙˆØ²Ø´ Ú©Ø§Ø±Ú©Ù†Ø§Ù† Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª
        
        ØªØ§Ø±ÛŒØ® ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´: {get_persian_date()}
        Ø´Ù…Ø§Ø±Ù‡ Ù…Ø´ØªØ±ÛŒ: {analysis.user.id if analysis.user else 'Ù†Ø§Ù…Ø´Ø®Øµ'}
        Ø´Ù…Ø§Ø±Ù‡ ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {analysis.id}
        ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†ÛŒØ¯Ù…Ø§Ù†Ùˆ
        """
        
        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ù‡ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
        conclusion_paragraphs = conclusion_text.strip().split('\n\n')
        for paragraph in conclusion_paragraphs:
            if paragraph.strip():
                clean_paragraph = paragraph.strip()
                if clean_paragraph and len(clean_paragraph) > 10:
                    story.append(Paragraph(clean_paragraph, normal_style))
                    story.append(Spacer(1, 6))
        
        # Ø³Ø§Ø®Øª PDF
        doc.build(story)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ú¯Ø´Øª
        buffer.seek(0)
        pdf_content = buffer.getvalue()
        buffer.close()
        
        return pdf_content
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ PDF ÙØ§Ø±Ø³ÛŒ: {str(e)}")
        logger.error(f"PDF generation error details: {type(e).__name__}: {e}")
        return None


def mock_payment_success(request, authority):
    """Mock payment success for testing"""
    try:
        logger.info(f"ğŸ­ MOCK: Payment success callback for authority: {authority}")
        
        # Find payment by authority
        from .models import Payment
        try:
            payment = Payment.objects.get(authority=authority)
            logger.info(f"ğŸ­ MOCK: Found payment {payment.id} for authority {authority}")
            
            # Update payment status
            payment.status = 'completed'
            payment.save()
            
            logger.info(f"ğŸ­ MOCK: Payment {payment.id} marked as completed")
            
            # Add success message
            messages.success(request, 'âœ… Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!')

            if payment.store_analysis_id:
                from .models import StoreAnalysis
                StoreAnalysis.objects.filter(pk=payment.store_analysis_id).update(status='paid')
                request.session['analysis_id'] = payment.store_analysis_id
            return redirect('store_analysis:forms')
            
        except Payment.DoesNotExist:
            logger.error(f"ğŸ­ MOCK: Payment not found for authority: {authority}")
            messages.error(request, 'âŒ ØªØ±Ø§Ú©Ù†Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯')
            return redirect('store_analysis:forms')
            
    except Exception as e:
        logger.error(f"ğŸ­ MOCK: Error in payment success callback: {str(e)}")
        messages.error(request, 'âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø¯Ø§Ø®Øª')
        return redirect('store_analysis:forms')